[2025-02-16 11:43:37,717] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
2025-02-16 11:43:39.053164: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:39.066741: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677419.084213  104530 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739677419.089609  104530 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-16 11:43:39.106988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
W0216 11:43:40.821000 104530 site-packages/torch/distributed/run.py:793] 
W0216 11:43:40.821000 104530 site-packages/torch/distributed/run.py:793] *****************************************
W0216 11:43:40.821000 104530 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0216 11:43:40.821000 104530 site-packages/torch/distributed/run.py:793] *****************************************
2025-02-16 11:43:45.223668: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:45.237329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.255220  105563 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739677425.260561  105563 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-16 11:43:45.277777: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-16 11:43:45.578854: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:45.592477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.610557  105565 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739677425.615908  105565 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-16 11:43:45.616489: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:45.616491: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:45.620593: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-16 11:43:45.630021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-16 11:43:45.630022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-16 11:43:45.633057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-16 11:43:45.633871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-16 11:43:45.643610: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.647976  105564 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.647992  105566 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.651817  105562 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739677425.653270  105564 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1739677425.653288  105566 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E0000 00:00:1739677425.657099  105562 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-16 11:43:45.657128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-16 11:43:45.670257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-16 11:43:45.670279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-16 11:43:45.674101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739677425.675091  105567 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739677425.680421  105567 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-16 11:43:45.697474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2025-02-16 11:43:47,414] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-16 11:43:47,815] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-16 11:43:47,826] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-16 11:43:47,838] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-16 11:43:47,867] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-16 11:43:47,929] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
INFO 02-16 11:43:48 __init__.py:183] Automatically detected platform cuda.
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.
Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.
  warnings.warn(
INFO 02-16 11:43:49 __init__.py:183] Automatically detected platform cuda.
INFO 02-16 11:43:49 __init__.py:183] Automatically detected platform cuda.
INFO 02-16 11:43:49 __init__.py:183] Automatically detected platform cuda.
INFO 02-16 11:43:49 __init__.py:183] Automatically detected platform cuda.
INFO 02-16 11:43:49 __init__.py:183] Automatically detected platform cuda.
[2025-02-16 11:43:49,327] [INFO] [comm.py:652:init_distributed] cdb=None
[32m2025-02-16 11:43:49,603 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:49,603 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:49,604 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=1,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[2025-02-16 11:43:49,778] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-16 11:43:49,779] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-16 11:43:49,779] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-16 11:43:49,779] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-02-16 11:43:49,948] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-16 11:43:49,981] [INFO] [comm.py:652:init_distributed] cdb=None
[32m2025-02-16 11:43:50,201 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:50,201 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:50,202 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[32m2025-02-16 11:43:50,397 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:50,397 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:50,397 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=2,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[32m2025-02-16 11:43:50,420 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:50,421 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:50,422 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=4,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[32m2025-02-16 11:43:50,480 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:50,480 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:50,480 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=5,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[32m2025-02-16 11:43:50,491 - INFO - Using default logging tool from transformers: {training_args.report_to}[0m
[32m2025-02-16 11:43:50,491 - INFO - Model parameters ModelConfig(model_name_or_path='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)[0m
[32m2025-02-16 11:43:50,492 - INFO - Training/evaluation parameters GRPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
beta=0.001,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': False},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-07,
length_column_name=length,
load_best_model_at_end=False,
local_rank=3,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=model_weights/grpo-4096/runs/Feb16_11-43-49_gpu-a100-0010.host.hh-d.brainpp.cn,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=cosine,
max_completion_length=4096,
max_grad_norm=1.0,
max_prompt_length=1024,
max_steps=2000,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_generations=8,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=model_weights/grpo-4096,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=True,
run_name=model_weights/grpo-4096,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=4,
seed=2025,
skip_memory_metrics=True,
split_batches=None,
temperature=1.0,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_vllm=True,
vllm_device=cuda:6,
vllm_gpu_memory_utilization=0.5,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)[0m
[32m2025-02-16 11:43:51,077 - INFO - *** Initializing model kwargs ***[0m
[2025-02-16 11:43:51,100] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[32m2025-02-16 11:43:51,725 - INFO - *** Initializing model kwargs ***[0m
[2025-02-16 11:43:51,753] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[32m2025-02-16 11:43:51,869 - INFO - *** Initializing model kwargs ***[0m
[2025-02-16 11:43:51,892] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[32m2025-02-16 11:43:51,951 - INFO - *** Initializing model kwargs ***[0m
[2025-02-16 11:43:51,974] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[32m2025-02-16 11:43:51,979 - INFO - *** Initializing model kwargs ***[0m
[2025-02-16 11:43:52,002] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[32m2025-02-16 11:43:52,002 - INFO - *** Initializing model kwargs ***[0m
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2025-02-16 11:43:52,026] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2025-02-16 11:43:54,164] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 8.03B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.18s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.20s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.24s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
[2025-02-16 11:43:56,931] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
[2025-02-16 11:43:56,947] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:43:56,949] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
[2025-02-16 11:43:56,978] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
[2025-02-16 11:43:57,002] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
[2025-02-16 11:43:57,786] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:43:57,902] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 582, num_elems = 16.06B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.96s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
[33m2025-02-16 11:44:01,887 - WARNING - Detected kernel version 5.4.15, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.[0m
INFO 02-16 11:44:09 config.py:520] This model supports multiple tasks: {'score', 'reward', 'classify', 'embed', 'generate'}. Defaulting to 'generate'.
WARNING 02-16 11:44:09 arg_utils.py:1117] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 02-16 11:44:09 llm_engine.py:232] Initializing an LLM engine (v0.7.0) with config: model='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', speculative_config=None, tokenizer='/data1/huggingface/DeepSeek-R1-Distill-Llama-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:6, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data1/huggingface/DeepSeek-R1-Distill-Llama-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 02-16 11:44:10 cuda.py:225] Using Flash Attention backend.
INFO 02-16 11:44:10 model_runner.py:1110] Starting to load model /data1/huggingface/DeepSeek-R1-Distill-Llama-8B...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.22s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]

INFO 02-16 11:44:14 model_runner.py:1115] Loading model weights took 0.0000 GB
INFO 02-16 11:44:22 worker.py:266] Memory profiling takes 8.12 seconds
INFO 02-16 11:44:22 worker.py:266] the current vLLM instance can use total_gpu_memory (79.15GiB) x gpu_memory_utilization (0.50) = 39.58GiB
INFO 02-16 11:44:22 worker.py:266] model weights take 0.00GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.00GiB; the rest of the memory reserved for KV Cache is 39.58GiB.
INFO 02-16 11:44:22 executor_base.py:108] # CUDA blocks: 20263, # CPU blocks: 2048
INFO 02-16 11:44:22 executor_base.py:113] Maximum concurrency for 131072 tokens per request: 2.47x
INFO 02-16 11:44:24 model_runner.py:1430] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:20,  1.63it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:01<00:20,  1.64it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:19,  1.66it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:02<00:18,  1.65it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:03<00:18,  1.66it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:03<00:17,  1.65it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:04<00:17,  1.63it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:04<00:16,  1.64it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:05<00:15,  1.64it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:06<00:15,  1.66it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:06<00:14,  1.65it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:07<00:13,  1.65it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:07<00:13,  1.64it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:08<00:12,  1.64it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:09<00:12,  1.65it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:09<00:11,  1.65it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:10<00:11,  1.64it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:10<00:10,  1.65it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:11<00:09,  1.67it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:12<00:08,  1.68it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:12<00:08,  1.68it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:13<00:07,  1.67it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:13<00:07,  1.68it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:14<00:06,  1.68it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:15<00:05,  1.68it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:15<00:05,  1.69it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:16<00:04,  1.71it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:16<00:04,  1.71it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:17<00:03,  1.71it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:17<00:02,  1.71it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:18<00:02,  1.71it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:19<00:01,  1.71it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:19<00:01,  1.71it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:20<00:00,  1.71it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:20<00:00,  1.71it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:20<00:00,  1.67it/s]
INFO 02-16 11:44:45 model_runner.py:1558] Graph capturing finished in 21 secs, took 0.00 GiB
INFO 02-16 11:44:45 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 31.39 seconds
[2025-02-16 11:44:45,586] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,587] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-02-16 11:44:45,594] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-02-16 11:44:45,595] [INFO] [logging.py:129:log_dist] [Rank 0] Creating ZeRO Offload
[32m2025-02-16 11:44:45,616 - INFO - *** Starting training 2025-02-16 11:44:45 for 3.0 epochs***[0m
[32m2025-02-16 11:44:45,616 - INFO - *** Starting training 2025-02-16 11:44:45 for 3.0 epochs***[0m
[32m2025-02-16 11:44:45,617 - INFO - *** Starting training 2025-02-16 11:44:45 for 3.0 epochs***[0m
[32m2025-02-16 11:44:45,617 - INFO - Using checkpoint at None to resume training.[0m
[32m2025-02-16 11:44:45,617 - INFO - Using checkpoint at None to resume training.[0m
[32m2025-02-16 11:44:45,617 - INFO - *** Starting training 2025-02-16 11:44:45 for 3.0 epochs***[0m
[32m2025-02-16 11:44:45,617 - INFO - Using checkpoint at None to resume training.[0m
[32m2025-02-16 11:44:45,617 - INFO - Using checkpoint at None to resume training.[0m
[32m2025-02-16 11:44:45,619 - INFO - *** Starting training 2025-02-16 11:44:45 for 3.0 epochs***[0m
[32m2025-02-16 11:44:45,619 - INFO - Using checkpoint at None to resume training.[0m
[2025-02-16 11:44:45,916] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-02-16 11:44:45,917] [INFO] [utils.py:782:see_memory_usage] MA 4.99 GB         Max_MA 4.99 GB         CA 5.13 GB         Max_CA 5 GB 
[2025-02-16 11:44:45,917] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 50.57 GB, percent = 5.0%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2025-02-16 11:44:46,236] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-02-16 11:44:46,237] [INFO] [utils.py:782:see_memory_usage] MA 4.99 GB         Max_MA 4.99 GB         CA 5.13 GB         Max_CA 5 GB 
[2025-02-16 11:44:46,237] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 50.6 GB, percent = 5.0%
[2025-02-16 11:44:46,238] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1f44530670>
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-02-16 11:44:46,239] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   train_batch_size ............. 6
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   world_size ................... 6
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-02-16 11:44:46,240] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-02-16 11:44:46,241] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-02-16 11:44:46,241] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 6, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 1.677722e+07, 
    "zero_optimization.stage3_param_persistence_threshold": 4.096000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 1.509949e+07
}
[32m2025-02-16 11:44:46,242 - INFO - *** Starting training 2025-02-16 11:44:46 for 3.0 epochs***[0m
[32m2025-02-16 11:44:46,243 - INFO - Using checkpoint at None to resume training.[0m
Parameter Offload: Total persistent parameters: 266240 in 65 params
[1m[34mswanlab[0m[0m: \ Waiting for the swanlab cloud response.                                                                                                    [1m[34mswanlab[0m[0m: swanlab version 0.4.8 is available!  Upgrade: `pip install -U swanlab`
[1m[34mswanlab[0m[0m: \ Getting project...                                                                                                    [1m[34mswanlab[0m[0m: \ Creating experiment...[32m2025-02-16 11:44:53,753 - INFO - generate built-in connection pool success. maxsize=10,10[0m
[32m2025-02-16 11:44:53,753 - INFO - bound built-in connection pool when new client. maxsize=10,10[0m
                                                                                                    [1m[34mswanlab[0m[0m: Tracking run with swanlab version 0.4.7
[1m[34mswanlab[0m[0m: Run data will be saved locally in [35m[1m/data/youxiang/repos/RiskReasoner/swanlog/run-20250216_114452-d82c07cd[0m[0m
[1m[34mswanlab[0m[0m: 👋 Hi [1m[39mYouxiang[0m[0m, welcome to swanlab!
[1m[34mswanlab[0m[0m: Syncing run [33mR1-Distill-Llama-8B-4096[0m to the cloud
[1m[34mswanlab[0m[0m: 🌟 Run `[1mswanlab watch /data/youxiang/repos/RiskReasoner/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: 🏠 View project at [34m[4mhttps://api.swanlab.cn/@Youxiang/RiskReasoner-grpo[0m[0m
[1m[34mswanlab[0m[0m: 🚀 View run at [34m[4mhttps://api.swanlab.cn/@Youxiang/RiskReasoner-grpo/runs/ifg6tr1cfp7mx0tdu7bi7[0m[0m
  0%|          | 0/2000 [00:00<?, ?it/s]  0%|          | 1/2000 [00:29<16:17:17, 29.33s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.333333333333334e-09, 'completion_length': 699.7083740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 1/2000 [00:29<16:17:17, 29.33s/it]  0%|          | 2/2000 [00:55<15:15:36, 27.50s/it]                                                   {'loss': 0.0, 'grad_norm': 1.9072088618745346, 'learning_rate': 1.6666666666666667e-08, 'completion_length': 693.9791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.5625, 'reward': 1.5625, 'reward_std': 0.16340987384319305, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 2/2000 [00:55<15:15:36, 27.50s/it]  0%|          | 3/2000 [01:21<14:57:08, 26.95s/it]                                                   {'loss': 0.0, 'grad_norm': 1.9100567239548931, 'learning_rate': 2.5e-08, 'completion_length': 700.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7708333730697632, 'reward': 1.7708333730697632, 'reward_std': 0.16340987384319305, 'kl': 0.000492095947265625, 'epoch': 0.0}
  0%|          | 3/2000 [01:21<14:57:08, 26.95s/it]  0%|          | 4/2000 [01:48<14:56:03, 26.94s/it]                                                   {'loss': 0.0, 'grad_norm': 0.00048322871046750963, 'learning_rate': 3.3333333333333334e-08, 'completion_length': 703.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0004119873046875, 'epoch': 0.0}
  0%|          | 4/2000 [01:48<14:56:03, 26.94s/it]  0%|          | 5/2000 [02:18<15:28:59, 27.94s/it]                                                   {'loss': 0.0, 'grad_norm': 1.8073686339188664, 'learning_rate': 4.166666666666666e-08, 'completion_length': 704.4583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7708333730697632, 'reward': 1.7708333730697632, 'reward_std': 0.2041093409061432, 'kl': 0.00042724609375, 'epoch': 0.0}
  0%|          | 5/2000 [02:18<15:28:59, 27.94s/it]  0%|          | 6/2000 [02:55<17:12:05, 31.06s/it]                                                   {'loss': 0.0, 'grad_norm': 1.3141917918853183, 'learning_rate': 5e-08, 'completion_length': 712.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.000461578369140625, 'epoch': 0.0}
  0%|          | 6/2000 [02:55<17:12:05, 31.06s/it]  0%|          | 7/2000 [03:23<16:39:54, 30.10s/it]                                                   {'loss': 0.0, 'grad_norm': 1.2598531386708978, 'learning_rate': 5.833333333333333e-08, 'completion_length': 697.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.0004062652587890625, 'epoch': 0.0}
  0%|          | 7/2000 [03:23<16:39:54, 30.10s/it]  0%|          | 8/2000 [03:50<16:02:01, 28.98s/it]                                                   {'loss': 0.0, 'grad_norm': 1.3672855521574072, 'learning_rate': 6.666666666666667e-08, 'completion_length': 694.4791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.08908708393573761, 'kl': 0.0004253387451171875, 'epoch': 0.01}
  0%|          | 8/2000 [03:50<16:02:01, 28.98s/it]  0%|          | 9/2000 [04:20<16:18:39, 29.49s/it]                                                   {'loss': 0.0, 'grad_norm': 1.6583430033209043, 'learning_rate': 7.5e-08, 'completion_length': 709.5416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.00040435791015625, 'epoch': 0.01}
  0%|          | 9/2000 [04:20<16:18:39, 29.49s/it]  0%|          | 10/2000 [04:46<15:37:48, 28.28s/it]                                                    {'loss': 0.0, 'grad_norm': 2.1532420103478263, 'learning_rate': 8.333333333333333e-08, 'completion_length': 680.5416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.875, 'reward': 1.875, 'reward_std': 0.22233544290065765, 'kl': 0.00046539306640625, 'epoch': 0.01}
  0%|          | 10/2000 [04:46<15:37:48, 28.28s/it]  1%|          | 11/2000 [05:12<15:11:15, 27.49s/it]                                                    {'loss': 0.0, 'grad_norm': 1.5383093698494852, 'learning_rate': 9.166666666666665e-08, 'completion_length': 696.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.1451837718486786, 'kl': 0.000553131103515625, 'epoch': 0.01}
  1%|          | 11/2000 [05:12<15:11:15, 27.49s/it]  1%|          | 12/2000 [05:40<15:20:58, 27.80s/it]                                                    {'loss': 0.0, 'grad_norm': 1.4676800327180077, 'learning_rate': 1e-07, 'completion_length': 731.6458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0004634857177734375, 'epoch': 0.01}
  1%|          | 12/2000 [05:40<15:20:58, 27.80s/it]  1%|          | 13/2000 [06:14<16:22:28, 29.67s/it]                                                    {'loss': 0.0, 'grad_norm': 1.678644597601924, 'learning_rate': 1.0833333333333334e-07, 'completion_length': 739.5833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7708333730697632, 'reward': 1.7708333730697632, 'reward_std': 0.13607725501060486, 'kl': 0.0004405975341796875, 'epoch': 0.01}
  1%|          | 13/2000 [06:14<16:22:28, 29.67s/it]  1%|          | 14/2000 [06:39<15:34:14, 28.22s/it]                                                    {'loss': 0.0, 'grad_norm': 0.0005439034834218135, 'learning_rate': 1.1666666666666667e-07, 'completion_length': 674.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.000415802001953125, 'epoch': 0.01}
  1%|          | 14/2000 [06:39<15:34:14, 28.22s/it]  1%|          | 15/2000 [07:08<15:41:36, 28.46s/it]                                                    {'loss': 0.0, 'grad_norm': 2.1935122178858752, 'learning_rate': 1.25e-07, 'completion_length': 666.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.19500282406806946, 'kl': 0.0004253387451171875, 'epoch': 0.01}
  1%|          | 15/2000 [07:08<15:41:36, 28.46s/it]  1%|          | 16/2000 [07:33<15:10:03, 27.52s/it]                                                    {'loss': 0.0, 'grad_norm': 1.1630439730000877, 'learning_rate': 1.3333333333333334e-07, 'completion_length': 674.6666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.000400543212890625, 'epoch': 0.01}
  1%|          | 16/2000 [07:33<15:10:03, 27.52s/it]  1%|          | 17/2000 [08:02<15:23:21, 27.94s/it]                                                    {'loss': 0.0, 'grad_norm': 2.3819200489883223, 'learning_rate': 1.4166666666666665e-07, 'completion_length': 737.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.1767766922712326, 'kl': 0.00042724609375, 'epoch': 0.01}
  1%|          | 17/2000 [08:02<15:23:21, 27.94s/it]  1%|          | 18/2000 [08:30<15:22:41, 27.93s/it]                                                    {'loss': 0.0, 'grad_norm': 1.7852837522847003, 'learning_rate': 1.5e-07, 'completion_length': 714.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0004425048828125, 'epoch': 0.01}
  1%|          | 18/2000 [08:30<15:22:41, 27.93s/it]  1%|          | 19/2000 [09:00<15:39:46, 28.46s/it]                                                    {'loss': 0.0, 'grad_norm': 1.4118209222950737, 'learning_rate': 1.583333333333333e-07, 'completion_length': 711.9166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.000469207763671875, 'epoch': 0.01}
  1%|          | 19/2000 [09:00<15:39:46, 28.46s/it]  1%|          | 20/2000 [09:33<16:24:22, 29.83s/it]                                                    {'loss': 0.0, 'grad_norm': 1.793178211910019, 'learning_rate': 1.6666666666666665e-07, 'completion_length': 723.3958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.13607725501060486, 'kl': 0.00042724609375, 'epoch': 0.01}
  1%|          | 20/2000 [09:33<16:24:22, 29.83s/it]  1%|          | 21/2000 [10:02<16:14:37, 29.55s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0441670108620706, 'learning_rate': 1.75e-07, 'completion_length': 740.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0004425048828125, 'epoch': 0.01}
  1%|          | 21/2000 [10:02<16:14:37, 29.55s/it]  1%|          | 22/2000 [10:32<16:18:09, 29.67s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0458607551830286, 'learning_rate': 1.833333333333333e-07, 'completion_length': 679.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.07715167850255966, 'kl': 0.00041961669921875, 'epoch': 0.02}
  1%|          | 22/2000 [10:32<16:18:09, 29.67s/it]  1%|          | 23/2000 [10:58<15:39:15, 28.51s/it]                                                    {'loss': 0.0, 'grad_norm': 1.3214372850295093, 'learning_rate': 1.9166666666666668e-07, 'completion_length': 694.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.000457763671875, 'epoch': 0.02}
  1%|          | 23/2000 [10:58<15:39:15, 28.51s/it]  1%|          | 24/2000 [11:30<16:14:07, 29.58s/it]                                                    {'loss': 0.0, 'grad_norm': 1.721707350866685, 'learning_rate': 2e-07, 'completion_length': 730.7708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0004405975341796875, 'epoch': 0.02}
  1%|          | 24/2000 [11:30<16:14:07, 29.58s/it]  1%|▏         | 25/2000 [12:00<16:24:51, 29.92s/it]                                                    {'loss': 0.0, 'grad_norm': 2.553244356486024, 'learning_rate': 2.0833333333333333e-07, 'completion_length': 729.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.19500282406806946, 'kl': 0.0005340576171875, 'epoch': 0.02}
  1%|▏         | 25/2000 [12:00<16:24:51, 29.92s/it]  1%|▏         | 26/2000 [12:28<15:59:29, 29.16s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0902522550005265, 'learning_rate': 2.1666666666666667e-07, 'completion_length': 732.9791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7916666865348816, 'reward': 1.7916667461395264, 'reward_std': 0.07715167850255966, 'kl': 0.000499725341796875, 'epoch': 0.02}
  1%|▏         | 26/2000 [12:28<15:59:29, 29.16s/it]  1%|▏         | 27/2000 [12:56<15:50:33, 28.91s/it]                                                    {'loss': 0.0, 'grad_norm': 2.212615844399016, 'learning_rate': 2.25e-07, 'completion_length': 694.1666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7916666865348816, 'reward': 1.7916667461395264, 'reward_std': 0.2721545100212097, 'kl': 0.0004367828369140625, 'epoch': 0.02}
  1%|▏         | 27/2000 [12:56<15:50:33, 28.91s/it]  1%|▏         | 28/2000 [13:22<15:21:42, 28.04s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2932097526384854, 'learning_rate': 2.3333333333333333e-07, 'completion_length': 696.7708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.000507354736328125, 'epoch': 0.02}
  1%|▏         | 28/2000 [13:22<15:21:42, 28.04s/it]  1%|▏         | 29/2000 [13:56<16:19:46, 29.83s/it]                                                    {'loss': 0.0, 'grad_norm': 2.1437266403354824, 'learning_rate': 2.4166666666666665e-07, 'completion_length': 752.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7708333730697632, 'reward': 1.7708333730697632, 'reward_std': 0.28126102685928345, 'kl': 0.000499725341796875, 'epoch': 0.02}
  1%|▏         | 29/2000 [13:56<16:19:46, 29.83s/it]  2%|▏         | 30/2000 [14:26<16:23:39, 29.96s/it]                                                    {'loss': 0.0, 'grad_norm': 1.8999200374061767, 'learning_rate': 2.5e-07, 'completion_length': 758.5416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.5416666865348816, 'reward': 1.5416667461395264, 'reward_std': 0.1178511306643486, 'kl': 0.00066375732421875, 'epoch': 0.02}
  2%|▏         | 30/2000 [14:26<16:23:39, 29.96s/it]  2%|▏         | 31/2000 [14:53<15:49:57, 28.95s/it]                                                    {'loss': 0.0, 'grad_norm': 1.524000541109333, 'learning_rate': 2.5833333333333333e-07, 'completion_length': 654.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.000682830810546875, 'epoch': 0.02}
  2%|▏         | 31/2000 [14:53<15:49:57, 28.95s/it]  2%|▏         | 32/2000 [15:18<15:09:21, 27.72s/it]                                                    {'loss': 0.0, 'grad_norm': 1.05503891439114, 'learning_rate': 2.6666666666666667e-07, 'completion_length': 678.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.000537872314453125, 'epoch': 0.02}
  2%|▏         | 32/2000 [15:18<15:09:21, 27.72s/it]  2%|▏         | 33/2000 [15:47<15:25:19, 28.23s/it]                                                    {'loss': 0.0, 'grad_norm': 2.15399272126182, 'learning_rate': 2.75e-07, 'completion_length': 676.4791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.16340987384319305, 'kl': 0.00064849853515625, 'epoch': 0.02}
  2%|▏         | 33/2000 [15:47<15:25:19, 28.23s/it]  2%|▏         | 34/2000 [16:13<15:00:33, 27.48s/it]                                                    {'loss': 0.0, 'grad_norm': 0.0005771359399980509, 'learning_rate': 2.833333333333333e-07, 'completion_length': 662.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.00049591064453125, 'epoch': 0.02}
  2%|▏         | 34/2000 [16:13<15:00:33, 27.48s/it]  2%|▏         | 35/2000 [16:39<14:46:28, 27.07s/it]                                                    {'loss': 0.0, 'grad_norm': 0.0020908381784667577, 'learning_rate': 2.916666666666667e-07, 'completion_length': 681.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.000942230224609375, 'epoch': 0.02}
  2%|▏         | 35/2000 [16:39<14:46:28, 27.07s/it]  2%|▏         | 36/2000 [17:09<15:12:12, 27.87s/it]                                                    {'loss': 0.0, 'grad_norm': 1.171735264157295, 'learning_rate': 3e-07, 'completion_length': 741.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.08908708393573761, 'kl': 0.000701904296875, 'epoch': 0.03}
  2%|▏         | 36/2000 [17:09<15:12:12, 27.87s/it]  2%|▏         | 37/2000 [17:41<15:51:16, 29.08s/it]                                                    {'loss': 0.0, 'grad_norm': 1.705037022173031, 'learning_rate': 3.0833333333333333e-07, 'completion_length': 724.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0010528564453125, 'epoch': 0.03}
  2%|▏         | 37/2000 [17:41<15:51:16, 29.08s/it]  2%|▏         | 38/2000 [18:10<15:52:55, 29.14s/it]                                                    {'loss': 0.0, 'grad_norm': 1.5151424584054547, 'learning_rate': 3.166666666666666e-07, 'completion_length': 736.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0007781982421875, 'epoch': 0.03}
  2%|▏         | 38/2000 [18:10<15:52:55, 29.14s/it]  2%|▏         | 39/2000 [18:37<15:30:20, 28.47s/it]                                                    {'loss': 0.0, 'grad_norm': 2.8268057148517554, 'learning_rate': 3.25e-07, 'completion_length': 679.2916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.1767766922712326, 'kl': 0.00090789794921875, 'epoch': 0.03}
  2%|▏         | 39/2000 [18:37<15:30:20, 28.47s/it]  2%|▏         | 40/2000 [19:06<15:34:36, 28.61s/it]                                                    {'loss': 0.0, 'grad_norm': 1.250729247805412, 'learning_rate': 3.333333333333333e-07, 'completion_length': 725.8333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.0013580322265625, 'epoch': 0.03}
  2%|▏         | 40/2000 [19:06<15:34:36, 28.61s/it]  2%|▏         | 41/2000 [19:36<15:51:27, 29.14s/it]                                                    {'loss': 0.0, 'grad_norm': 2.1921641245201346, 'learning_rate': 3.4166666666666664e-07, 'completion_length': 705.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.234270840883255, 'kl': 0.0011138916015625, 'epoch': 0.03}
  2%|▏         | 41/2000 [19:36<15:51:27, 29.14s/it]  2%|▏         | 42/2000 [20:01<15:08:12, 27.83s/it]                                                    {'loss': 0.0, 'grad_norm': 1.6837365457677125, 'learning_rate': 3.5e-07, 'completion_length': 642.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.13607725501060486, 'kl': 0.0013427734375, 'epoch': 0.03}
  2%|▏         | 42/2000 [20:01<15:08:12, 27.83s/it]  2%|▏         | 43/2000 [20:31<15:33:45, 28.63s/it]                                                    {'loss': 0.0, 'grad_norm': 1.046273589630737, 'learning_rate': 3.583333333333333e-07, 'completion_length': 703.5416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8958333730697632, 'reward': 1.8958333730697632, 'reward_std': 0.08625819534063339, 'kl': 0.001983642578125, 'epoch': 0.03}
  2%|▏         | 43/2000 [20:31<15:33:45, 28.63s/it]  2%|▏         | 44/2000 [21:01<15:41:31, 28.88s/it]                                                    {'loss': 0.0, 'grad_norm': 1.5561199143009758, 'learning_rate': 3.666666666666666e-07, 'completion_length': 762.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.1178511306643486, 'kl': 0.002166748046875, 'epoch': 0.03}
  2%|▏         | 44/2000 [21:01<15:41:31, 28.88s/it]  2%|▏         | 45/2000 [21:31<15:51:54, 29.21s/it]                                                    {'loss': 0.0, 'grad_norm': 1.8910888743393937, 'learning_rate': 3.75e-07, 'completion_length': 702.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6041666865348816, 'reward': 1.6041667461395264, 'reward_std': 0.13607725501060486, 'kl': 0.00151824951171875, 'epoch': 0.03}
  2%|▏         | 45/2000 [21:31<15:51:54, 29.21s/it]  2%|▏         | 46/2000 [22:01<16:01:31, 29.52s/it]                                                    {'loss': 0.0, 'grad_norm': 2.0678828706665473, 'learning_rate': 3.8333333333333335e-07, 'completion_length': 703.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.19500279426574707, 'kl': 0.00154876708984375, 'epoch': 0.03}
  2%|▏         | 46/2000 [22:01<16:01:31, 29.52s/it]  2%|▏         | 47/2000 [22:29<15:45:00, 29.03s/it]                                                    {'loss': 0.0, 'grad_norm': 1.8567700081411456, 'learning_rate': 3.9166666666666664e-07, 'completion_length': 665.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.0015411376953125, 'epoch': 0.03}
  2%|▏         | 47/2000 [22:29<15:45:00, 29.03s/it]  2%|▏         | 48/2000 [22:58<15:44:18, 29.03s/it]                                                    {'loss': 0.0, 'grad_norm': 2.323448491522852, 'learning_rate': 4e-07, 'completion_length': 721.1666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9166666865348816, 'reward': 1.9166667461395264, 'reward_std': 0.2357022613286972, 'kl': 0.0023193359375, 'epoch': 0.03}
  2%|▏         | 48/2000 [22:58<15:44:18, 29.03s/it]  2%|▏         | 49/2000 [23:25<15:22:03, 28.36s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2892429071533786, 'learning_rate': 4.083333333333333e-07, 'completion_length': 694.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0017547607421875, 'epoch': 0.03}
  2%|▏         | 49/2000 [23:25<15:22:03, 28.36s/it]  2%|▎         | 50/2000 [23:57<15:54:05, 29.36s/it]                                                    {'loss': 0.0, 'grad_norm': 1.6303531112249499, 'learning_rate': 4.1666666666666667e-07, 'completion_length': 699.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0015106201171875, 'epoch': 0.04}
  2%|▎         | 50/2000 [23:57<15:54:05, 29.36s/it]  3%|▎         | 51/2000 [24:26<15:50:14, 29.25s/it]                                                    {'loss': 0.0, 'grad_norm': 0.002083189209155092, 'learning_rate': 4.2499999999999995e-07, 'completion_length': 687.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.00194549560546875, 'epoch': 0.04}
  3%|▎         | 51/2000 [24:26<15:50:14, 29.25s/it]  3%|▎         | 52/2000 [24:52<15:22:14, 28.41s/it]                                                    {'loss': 0.0, 'grad_norm': 0.002667122302353203, 'learning_rate': 4.3333333333333335e-07, 'completion_length': 688.3958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.002716064453125, 'epoch': 0.04}
  3%|▎         | 52/2000 [24:52<15:22:14, 28.41s/it]  3%|▎         | 53/2000 [25:23<15:44:44, 29.11s/it]                                                    {'loss': 0.0, 'grad_norm': 1.674912310710834, 'learning_rate': 4.4166666666666664e-07, 'completion_length': 697.8333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.002532958984375, 'epoch': 0.04}
  3%|▎         | 53/2000 [25:23<15:44:44, 29.11s/it]  3%|▎         | 54/2000 [25:51<15:30:57, 28.70s/it]                                                    {'loss': 0.0, 'grad_norm': 2.3127918994356684, 'learning_rate': 4.5e-07, 'completion_length': 694.4583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.13607725501060486, 'kl': 0.0027923583984375, 'epoch': 0.04}
  3%|▎         | 54/2000 [25:51<15:30:57, 28.70s/it]  3%|▎         | 55/2000 [26:17<15:10:47, 28.10s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9450591841486441, 'learning_rate': 4.5833333333333327e-07, 'completion_length': 703.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0034942626953125, 'epoch': 0.04}
  3%|▎         | 55/2000 [26:17<15:10:47, 28.10s/it]  3%|▎         | 56/2000 [26:44<14:59:02, 27.75s/it]                                                    {'loss': 0.0, 'grad_norm': 1.6848595058591085, 'learning_rate': 4.6666666666666666e-07, 'completion_length': 692.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.13607725501060486, 'kl': 0.0033721923828125, 'epoch': 0.04}
  3%|▎         | 56/2000 [26:44<14:59:02, 27.75s/it]  3%|▎         | 57/2000 [27:11<14:51:37, 27.53s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2488650128030914, 'learning_rate': 4.7499999999999995e-07, 'completion_length': 689.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.07715167850255966, 'kl': 0.0038299560546875, 'epoch': 0.04}
  3%|▎         | 57/2000 [27:11<14:51:37, 27.53s/it]  3%|▎         | 58/2000 [27:42<15:27:41, 28.66s/it]                                                    {'loss': 0.0, 'grad_norm': 0.772386534170767, 'learning_rate': 4.833333333333333e-07, 'completion_length': 758.2291870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.005157470703125, 'epoch': 0.04}
  3%|▎         | 58/2000 [27:42<15:27:41, 28.66s/it]  3%|▎         | 59/2000 [28:10<15:16:41, 28.34s/it]                                                    {'loss': 0.0, 'grad_norm': 1.5402078448539613, 'learning_rate': 4.916666666666666e-07, 'completion_length': 762.9166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.00390625, 'epoch': 0.04}
  3%|▎         | 59/2000 [28:10<15:16:41, 28.34s/it]  3%|▎         | 60/2000 [28:38<15:17:13, 28.37s/it]                                                    {'loss': 0.0, 'grad_norm': 9.427238404922543, 'learning_rate': 5e-07, 'completion_length': 671.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.19500279426574707, 'kl': 0.007293701171875, 'epoch': 0.04}
  3%|▎         | 60/2000 [28:38<15:17:13, 28.37s/it]  3%|▎         | 61/2000 [29:05<15:01:54, 27.91s/it]                                                    {'loss': 0.0, 'grad_norm': 1.7336658522440203, 'learning_rate': 4.999996722020723e-07, 'completion_length': 764.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0118408203125, 'epoch': 0.04}
  3%|▎         | 61/2000 [29:05<15:01:54, 27.91s/it]  3%|▎         | 62/2000 [29:35<15:19:26, 28.47s/it]                                                    {'loss': 0.0, 'grad_norm': 1.8419946748739653, 'learning_rate': 4.99998688809149e-07, 'completion_length': 765.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.004150390625, 'epoch': 0.04}
  3%|▎         | 62/2000 [29:35<15:19:26, 28.47s/it]  3%|▎         | 63/2000 [30:00<14:47:41, 27.50s/it]                                                    {'loss': 0.0, 'grad_norm': 1.503453283833871, 'learning_rate': 4.999970498238088e-07, 'completion_length': 646.1041870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.007720947265625, 'epoch': 0.04}
  3%|▎         | 63/2000 [30:00<14:47:41, 27.50s/it]  3%|▎         | 64/2000 [30:30<15:08:51, 28.17s/it]                                                    {'loss': 0.0, 'grad_norm': 0.004353966274923237, 'learning_rate': 4.999947552503497e-07, 'completion_length': 709.6458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0050048828125, 'epoch': 0.05}
  3%|▎         | 64/2000 [30:30<15:08:51, 28.17s/it]  3%|▎         | 65/2000 [30:57<14:55:44, 27.77s/it]                                                    {'loss': 0.0, 'grad_norm': 1.4358563264934427, 'learning_rate': 4.99991805094789e-07, 'completion_length': 728.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.0062255859375, 'epoch': 0.05}
  3%|▎         | 65/2000 [30:57<14:55:44, 27.77s/it]  3%|▎         | 66/2000 [31:24<14:46:52, 27.51s/it]                                                    {'loss': 0.0, 'grad_norm': 2.2898080080601177, 'learning_rate': 4.999881993648632e-07, 'completion_length': 729.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.875, 'reward': 1.875, 'reward_std': 0.2721545100212097, 'kl': 0.005950927734375, 'epoch': 0.05}
  3%|▎         | 66/2000 [31:24<14:46:52, 27.51s/it]  3%|▎         | 67/2000 [31:51<14:42:26, 27.39s/it]                                                    {'loss': 0.0, 'grad_norm': 1.9375900680831284, 'learning_rate': 4.999839380700281e-07, 'completion_length': 759.4791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.75, 'reward': 1.75, 'reward_std': 0.20693820714950562, 'kl': 0.006866455078125, 'epoch': 0.05}
  3%|▎         | 67/2000 [31:51<14:42:26, 27.39s/it]  3%|▎         | 68/2000 [32:15<14:08:14, 26.34s/it]                                                    {'loss': 0.0, 'grad_norm': 0.0032648092298836985, 'learning_rate': 4.999790212214579e-07, 'completion_length': 691.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.00628662109375, 'epoch': 0.05}
  3%|▎         | 68/2000 [32:15<14:08:14, 26.34s/it]  3%|▎         | 69/2000 [32:49<15:19:08, 28.56s/it]                                                    {'loss': 0.0, 'grad_norm': 1.1632322007461429, 'learning_rate': 4.999734488320469e-07, 'completion_length': 726.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8958333730697632, 'reward': 1.8958333730697632, 'reward_std': 0.08625819534063339, 'kl': 0.0087890625, 'epoch': 0.05}
  3%|▎         | 69/2000 [32:49<15:19:08, 28.56s/it]  4%|▎         | 70/2000 [33:17<15:14:31, 28.43s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2509644463290346, 'learning_rate': 4.99967220916408e-07, 'completion_length': 679.3333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6875, 'reward': 1.6875, 'reward_std': 0.0589255653321743, 'kl': 0.005859375, 'epoch': 0.05}
  4%|▎         | 70/2000 [33:17<15:14:31, 28.43s/it]  4%|▎         | 71/2000 [33:50<16:02:00, 29.92s/it]                                                    {'loss': 0.0, 'grad_norm': 0.002679862796203255, 'learning_rate': 4.99960337490873e-07, 'completion_length': 723.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.007232666015625, 'epoch': 0.05}
  4%|▎         | 71/2000 [33:50<16:02:00, 29.92s/it]  4%|▎         | 72/2000 [34:14<15:06:57, 28.23s/it]                                                    {'loss': 0.0, 'grad_norm': 1.4212701183295036, 'learning_rate': 4.999527985734931e-07, 'completion_length': 581.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.07715167850255966, 'kl': 0.042236328125, 'epoch': 0.05}
  4%|▎         | 72/2000 [34:14<15:06:57, 28.23s/it]  4%|▎         | 73/2000 [34:41<14:47:06, 27.62s/it]                                                    {'loss': 0.0, 'grad_norm': 2.1627153898070057, 'learning_rate': 4.999446041840381e-07, 'completion_length': 664.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.023193359375, 'epoch': 0.05}
  4%|▎         | 73/2000 [34:41<14:47:06, 27.62s/it]  4%|▎         | 74/2000 [35:06<14:22:25, 26.87s/it]                                                    {'loss': 0.0, 'grad_norm': 1.6166247941271445, 'learning_rate': 4.999357543439968e-07, 'completion_length': 698.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.00994873046875, 'epoch': 0.05}
  4%|▎         | 74/2000 [35:06<14:22:25, 26.87s/it]  4%|▍         | 75/2000 [35:31<14:10:08, 26.50s/it]                                                    {'loss': 0.0, 'grad_norm': 0.005953156919303001, 'learning_rate': 4.99926249076577e-07, 'completion_length': 674.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0098876953125, 'epoch': 0.05}
  4%|▍         | 75/2000 [35:31<14:10:08, 26.50s/it]  4%|▍         | 76/2000 [35:58<14:12:24, 26.58s/it]                                                    {'loss': 0.0, 'grad_norm': 0.009485813300314222, 'learning_rate': 4.99916088406705e-07, 'completion_length': 670.7708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0103759765625, 'epoch': 0.05}
  4%|▍         | 76/2000 [35:58<14:12:24, 26.58s/it]  4%|▍         | 77/2000 [36:27<14:32:49, 27.23s/it]                                                    {'loss': 0.0, 'grad_norm': 2.249853423964052, 'learning_rate': 4.999052723610261e-07, 'completion_length': 710.0416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7708333730697632, 'reward': 1.7708333730697632, 'reward_std': 0.25392839312553406, 'kl': 0.01104736328125, 'epoch': 0.05}
  4%|▍         | 77/2000 [36:27<14:32:49, 27.23s/it]  4%|▍         | 78/2000 [36:55<14:41:30, 27.52s/it]                                                    {'loss': 0.0, 'grad_norm': 0.006401465944008986, 'learning_rate': 4.998938009679042e-07, 'completion_length': 700.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0098876953125, 'epoch': 0.06}
  4%|▍         | 78/2000 [36:55<14:41:30, 27.52s/it]  4%|▍         | 79/2000 [37:18<13:59:09, 26.21s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0182525077282176, 'learning_rate': 4.998816742574213e-07, 'completion_length': 669.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.01416015625, 'epoch': 0.06}
  4%|▍         | 79/2000 [37:18<13:59:09, 26.21s/it]  4%|▍         | 80/2000 [37:45<14:02:53, 26.34s/it]                                                    {'loss': 0.0, 'grad_norm': 0.014697785741932801, 'learning_rate': 4.998688922613787e-07, 'completion_length': 689.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0145263671875, 'epoch': 0.06}
  4%|▍         | 80/2000 [37:45<14:02:53, 26.34s/it]  4%|▍         | 81/2000 [38:11<13:57:04, 26.17s/it]                                                    {'loss': 0.0001, 'grad_norm': 7.793668903509626, 'learning_rate': 4.998554550132955e-07, 'completion_length': 634.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.06591796875, 'epoch': 0.06}
  4%|▍         | 81/2000 [38:11<13:57:04, 26.17s/it]  4%|▍         | 82/2000 [38:36<13:47:16, 25.88s/it]                                                    {'loss': 0.0, 'grad_norm': 0.004851994882783192, 'learning_rate': 4.998413625484094e-07, 'completion_length': 678.7708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.01190185546875, 'epoch': 0.06}
  4%|▍         | 82/2000 [38:36<13:47:16, 25.88s/it]  4%|▍         | 83/2000 [39:00<13:35:10, 25.51s/it]                                                    {'loss': 0.0, 'grad_norm': 2.0980265960993942, 'learning_rate': 4.998266149036762e-07, 'completion_length': 692.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.0140380859375, 'epoch': 0.06}
  4%|▍         | 83/2000 [39:00<13:35:10, 25.51s/it]  4%|▍         | 84/2000 [39:30<14:12:27, 26.69s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2790108019489974, 'learning_rate': 4.998112121177698e-07, 'completion_length': 747.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0125732421875, 'epoch': 0.06}
  4%|▍         | 84/2000 [39:30<14:12:27, 26.69s/it]  4%|▍         | 85/2000 [39:57<14:13:32, 26.74s/it]                                                    {'loss': 0.0, 'grad_norm': 0.008865640135952537, 'learning_rate': 4.997951542310825e-07, 'completion_length': 660.4166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0135498046875, 'epoch': 0.06}
  4%|▍         | 85/2000 [39:57<14:13:32, 26.74s/it]  4%|▍         | 86/2000 [40:25<14:24:07, 27.09s/it]                                                    {'loss': 0.0, 'grad_norm': 1.4439363920360064, 'learning_rate': 4.997784412857239e-07, 'completion_length': 741.4791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.13607725501060486, 'kl': 0.01513671875, 'epoch': 0.06}
  4%|▍         | 86/2000 [40:25<14:24:07, 27.09s/it]  4%|▍         | 87/2000 [40:50<14:10:57, 26.69s/it]                                                    {'loss': 0.0, 'grad_norm': 0.9879292383832701, 'learning_rate': 4.997610733255219e-07, 'completion_length': 662.1666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.019775390625, 'epoch': 0.06}
  4%|▍         | 87/2000 [40:50<14:10:57, 26.69s/it]  4%|▍         | 88/2000 [41:15<13:47:43, 25.97s/it]                                                    {'loss': 0.0, 'grad_norm': 1.3408819596186767, 'learning_rate': 4.997430503960219e-07, 'completion_length': 676.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.01495361328125, 'epoch': 0.06}
  4%|▍         | 88/2000 [41:15<13:47:43, 25.97s/it]  4%|▍         | 89/2000 [41:47<14:49:53, 27.94s/it]                                                    {'loss': 0.0, 'grad_norm': 0.007884345033585453, 'learning_rate': 4.99724372544487e-07, 'completion_length': 690.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.01422119140625, 'epoch': 0.06}
  4%|▍         | 89/2000 [41:47<14:49:53, 27.94s/it]  4%|▍         | 90/2000 [42:14<14:34:35, 27.47s/it]                                                    {'loss': 0.0, 'grad_norm': 0.028962710930245474, 'learning_rate': 4.997050398198976e-07, 'completion_length': 686.4166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.02197265625, 'epoch': 0.06}
  4%|▍         | 90/2000 [42:14<14:34:35, 27.47s/it]  5%|▍         | 91/2000 [42:41<14:31:31, 27.39s/it]                                                    {'loss': 0.0, 'grad_norm': 1.0896596983509608, 'learning_rate': 4.996850522729516e-07, 'completion_length': 691.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.0142822265625, 'epoch': 0.06}
  5%|▍         | 91/2000 [42:41<14:31:31, 27.39s/it]  5%|▍         | 92/2000 [43:06<14:09:37, 26.72s/it]                                                    {'loss': 0.0, 'grad_norm': 0.005086167324994385, 'learning_rate': 4.996644099560641e-07, 'completion_length': 666.0416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0174560546875, 'epoch': 0.07}
  5%|▍         | 92/2000 [43:06<14:09:37, 26.72s/it]  5%|▍         | 93/2000 [43:32<14:06:23, 26.63s/it]                                                    {'loss': 0.0, 'grad_norm': 1.6015043220422147, 'learning_rate': 4.996431129233669e-07, 'completion_length': 670.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.875, 'reward': 1.875, 'reward_std': 0.1451837718486786, 'kl': 0.016845703125, 'epoch': 0.07}
  5%|▍         | 93/2000 [43:32<14:06:23, 26.63s/it]  5%|▍         | 94/2000 [43:59<14:04:50, 26.60s/it]                                                    {'loss': 0.0, 'grad_norm': 0.07676178276747625, 'learning_rate': 4.996211612307092e-07, 'completion_length': 680.7083740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.04931640625, 'epoch': 0.07}
  5%|▍         | 94/2000 [43:59<14:04:50, 26.60s/it]  5%|▍         | 95/2000 [44:24<13:51:00, 26.17s/it]                                                    {'loss': 0.0, 'grad_norm': 0.005906101994479484, 'learning_rate': 4.995985549356567e-07, 'completion_length': 656.1041870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0184326171875, 'epoch': 0.07}
  5%|▍         | 95/2000 [44:24<13:51:00, 26.17s/it]  5%|▍         | 96/2000 [44:52<14:04:51, 26.62s/it]                                                    {'loss': 0.0, 'grad_norm': 1.2610168692672135, 'learning_rate': 4.995752940974918e-07, 'completion_length': 683.7708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.028564453125, 'epoch': 0.07}
  5%|▍         | 96/2000 [44:52<14:04:51, 26.62s/it]  5%|▍         | 97/2000 [45:16<13:43:58, 25.98s/it]                                                    {'loss': 0.0, 'grad_norm': 0.06564330008158215, 'learning_rate': 4.995513787772133e-07, 'completion_length': 636.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0238037109375, 'epoch': 0.07}
  5%|▍         | 97/2000 [45:16<13:43:58, 25.98s/it]  5%|▍         | 98/2000 [45:39<13:09:08, 24.89s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.20299322182409799, 'learning_rate': 4.995268090375362e-07, 'completion_length': 522.4166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.2158203125, 'epoch': 0.07}
  5%|▍         | 98/2000 [45:39<13:09:08, 24.89s/it]  5%|▍         | 99/2000 [46:04<13:13:33, 25.05s/it]                                                    {'loss': 0.0, 'grad_norm': 1.037624044074701, 'learning_rate': 4.995015849428921e-07, 'completion_length': 675.5208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.020751953125, 'epoch': 0.07}
  5%|▍         | 99/2000 [46:04<13:13:33, 25.05s/it]  5%|▌         | 100/2000 [46:27<12:51:22, 24.36s/it]                                                     {'loss': 0.0, 'grad_norm': 1.1289777391525815, 'learning_rate': 4.994757065594279e-07, 'completion_length': 629.9166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.017822265625, 'epoch': 0.07}
  5%|▌         | 100/2000 [46:27<12:51:22, 24.36s/it]  5%|▌         | 101/2000 [46:54<13:13:47, 25.08s/it]                                                     {'loss': 0.0, 'grad_norm': 1.1909159691351017, 'learning_rate': 4.994491739550069e-07, 'completion_length': 687.4791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9375, 'reward': 1.9375, 'reward_std': 0.08625819534063339, 'kl': 0.020751953125, 'epoch': 0.07}
  5%|▌         | 101/2000 [46:54<13:13:47, 25.08s/it]  5%|▌         | 102/2000 [47:22<13:46:32, 26.13s/it]                                                     {'loss': 0.0, 'grad_norm': 0.008140949139189335, 'learning_rate': 4.994219871992076e-07, 'completion_length': 683.6666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0208740234375, 'epoch': 0.07}
  5%|▌         | 102/2000 [47:22<13:46:32, 26.13s/it]  5%|▌         | 103/2000 [47:47<13:30:04, 25.62s/it]                                                     {'loss': 0.0, 'grad_norm': 1.3448750864523946, 'learning_rate': 4.993941463633243e-07, 'completion_length': 644.8958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0201416015625, 'epoch': 0.07}
  5%|▌         | 103/2000 [47:47<13:30:04, 25.62s/it]  5%|▌         | 104/2000 [48:11<13:20:11, 25.32s/it]                                                     {'loss': 0.0, 'grad_norm': 0.009777322483716985, 'learning_rate': 4.993656515203662e-07, 'completion_length': 656.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0198974609375, 'epoch': 0.07}
  5%|▌         | 104/2000 [48:11<13:20:11, 25.32s/it]  5%|▌         | 105/2000 [48:39<13:41:24, 26.01s/it]                                                     {'loss': 0.0, 'grad_norm': 0.05325843575607516, 'learning_rate': 4.993365027450576e-07, 'completion_length': 715.1458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.034423828125, 'epoch': 0.07}
  5%|▌         | 105/2000 [48:39<13:41:24, 26.01s/it]  5%|▌         | 106/2000 [49:06<13:49:06, 26.27s/it]                                                     {'loss': 0.0, 'grad_norm': 0.011169991546863873, 'learning_rate': 4.993067001138379e-07, 'completion_length': 666.6458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0208740234375, 'epoch': 0.08}
  5%|▌         | 106/2000 [49:06<13:49:06, 26.27s/it]  5%|▌         | 107/2000 [49:30<13:30:21, 25.68s/it]                                                     {'loss': 0.0, 'grad_norm': 1.961322475608318, 'learning_rate': 4.992762437048612e-07, 'completion_length': 630.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8958333730697632, 'reward': 1.8958333730697632, 'reward_std': 0.14801263809204102, 'kl': 0.027587890625, 'epoch': 0.08}
  5%|▌         | 107/2000 [49:30<13:30:21, 25.68s/it]  5%|▌         | 108/2000 [49:56<13:35:51, 25.87s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.3451507299760337, 'learning_rate': 4.992451335979955e-07, 'completion_length': 564.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.07861328125, 'epoch': 0.08}
  5%|▌         | 108/2000 [49:56<13:35:51, 25.87s/it]  5%|▌         | 109/2000 [50:23<13:39:45, 26.01s/it]                                                     {'loss': 0.0, 'grad_norm': 1.1480539161809307, 'learning_rate': 4.992133698748237e-07, 'completion_length': 634.0416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0341796875, 'epoch': 0.08}
  5%|▌         | 109/2000 [50:23<13:39:45, 26.01s/it]  6%|▌         | 110/2000 [50:47<13:27:42, 25.64s/it]                                                     {'loss': 0.0, 'grad_norm': 1.269232190304864, 'learning_rate': 4.991809526186423e-07, 'completion_length': 656.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.027099609375, 'epoch': 0.08}
  6%|▌         | 110/2000 [50:47<13:27:42, 25.64s/it]  6%|▌         | 111/2000 [51:12<13:20:53, 25.44s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.11824994164750433, 'learning_rate': 4.991478819144619e-07, 'completion_length': 593.3541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.06298828125, 'epoch': 0.08}
  6%|▌         | 111/2000 [51:12<13:20:53, 25.44s/it]  6%|▌         | 112/2000 [51:40<13:39:48, 26.05s/it]                                                     {'loss': 0.0, 'grad_norm': 0.0067186084998676, 'learning_rate': 4.991141578490066e-07, 'completion_length': 645.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0203857421875, 'epoch': 0.08}
  6%|▌         | 112/2000 [51:40<13:39:48, 26.05s/it]  6%|▌         | 113/2000 [52:04<13:22:57, 25.53s/it]                                                     {'loss': 0.0, 'grad_norm': 0.01729300208812824, 'learning_rate': 4.990797805107137e-07, 'completion_length': 657.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.02783203125, 'epoch': 0.08}
  6%|▌         | 113/2000 [52:04<13:22:57, 25.53s/it]  6%|▌         | 114/2000 [52:31<13:33:52, 25.89s/it]                                                     {'loss': 0.0, 'grad_norm': 1.798812710359625, 'learning_rate': 4.990447499897339e-07, 'completion_length': 683.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0240478515625, 'epoch': 0.08}
  6%|▌         | 114/2000 [52:31<13:33:52, 25.89s/it]  6%|▌         | 115/2000 [52:55<13:15:18, 25.31s/it]                                                     {'loss': 0.0, 'grad_norm': 1.059882999376356, 'learning_rate': 4.990090663779304e-07, 'completion_length': 644.5833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.0230712890625, 'epoch': 0.08}
  6%|▌         | 115/2000 [52:55<13:15:18, 25.31s/it]  6%|▌         | 116/2000 [53:20<13:09:14, 25.14s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.016582341892857747, 'learning_rate': 4.989727297688796e-07, 'completion_length': 535.2291870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.08056640625, 'epoch': 0.08}
  6%|▌         | 116/2000 [53:20<13:09:14, 25.14s/it]  6%|▌         | 117/2000 [53:44<13:06:25, 25.06s/it]                                                     {'loss': 0.0, 'grad_norm': 0.011161074961513888, 'learning_rate': 4.989357402578699e-07, 'completion_length': 603.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.025390625, 'epoch': 0.08}
  6%|▌         | 117/2000 [53:44<13:06:25, 25.06s/it]  6%|▌         | 118/2000 [54:10<13:07:13, 25.10s/it]                                                     {'loss': 0.0, 'grad_norm': 1.131315846245472, 'learning_rate': 4.98898097941902e-07, 'completion_length': 655.9166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.027587890625, 'epoch': 0.08}
  6%|▌         | 118/2000 [54:10<13:07:13, 25.10s/it]  6%|▌         | 119/2000 [54:35<13:06:43, 25.09s/it]                                                     {'loss': 0.0, 'grad_norm': 0.0063276908281107705, 'learning_rate': 4.988598029196884e-07, 'completion_length': 668.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0220947265625, 'epoch': 0.08}
  6%|▌         | 119/2000 [54:35<13:06:43, 25.09s/it]  6%|▌         | 120/2000 [54:57<12:43:53, 24.38s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.48858771762662107, 'learning_rate': 4.988208552916535e-07, 'completion_length': 532.4583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.1474609375, 'epoch': 0.08}
  6%|▌         | 120/2000 [54:57<12:43:53, 24.38s/it]  6%|▌         | 121/2000 [55:27<13:28:42, 25.82s/it]                                                     {'loss': 0.0, 'grad_norm': 2.292519327572354, 'learning_rate': 4.987812551599327e-07, 'completion_length': 673.8333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7916666865348816, 'reward': 1.7916667461395264, 'reward_std': 0.1451837718486786, 'kl': 0.023193359375, 'epoch': 0.09}
  6%|▌         | 121/2000 [55:27<13:28:42, 25.82s/it]  6%|▌         | 122/2000 [55:56<14:03:55, 26.96s/it]                                                     {'loss': 0.0, 'grad_norm': 1.0902545644901631, 'learning_rate': 4.987410026283729e-07, 'completion_length': 641.8958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.044189453125, 'epoch': 0.09}
  6%|▌         | 122/2000 [55:56<14:03:55, 26.96s/it]  6%|▌         | 123/2000 [56:21<13:44:20, 26.35s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.03837760119660825, 'learning_rate': 4.987000978025318e-07, 'completion_length': 532.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.09326171875, 'epoch': 0.09}
  6%|▌         | 123/2000 [56:21<13:44:20, 26.35s/it]  6%|▌         | 124/2000 [56:46<13:29:48, 25.90s/it]                                                     {'loss': 0.0, 'grad_norm': 0.01707730540535251, 'learning_rate': 4.986585407896771e-07, 'completion_length': 652.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.028076171875, 'epoch': 0.09}
  6%|▌         | 124/2000 [56:46<13:29:48, 25.90s/it]  6%|▋         | 125/2000 [57:11<13:22:23, 25.68s/it]                                                     {'loss': 0.0, 'grad_norm': 1.3022034007262964, 'learning_rate': 4.986163316987876e-07, 'completion_length': 658.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0299072265625, 'epoch': 0.09}
  6%|▋         | 125/2000 [57:11<13:22:23, 25.68s/it]  6%|▋         | 126/2000 [57:36<13:15:58, 25.48s/it]                                                     {'loss': 0.0, 'grad_norm': 1.2586247818097558, 'learning_rate': 4.985734706405516e-07, 'completion_length': 650.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.022705078125, 'epoch': 0.09}
  6%|▋         | 126/2000 [57:36<13:15:58, 25.48s/it]  6%|▋         | 127/2000 [57:58<12:42:40, 24.43s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.018760569901540528, 'learning_rate': 4.985299577273672e-07, 'completion_length': 528.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.08251953125, 'epoch': 0.09}
  6%|▋         | 127/2000 [57:58<12:42:40, 24.43s/it]  6%|▋         | 128/2000 [58:21<12:28:32, 23.99s/it]                                                     {'loss': 0.0, 'grad_norm': 1.8492008559211803, 'learning_rate': 4.984857930733419e-07, 'completion_length': 594.8958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6875, 'reward': 1.6875, 'reward_std': 0.13607725501060486, 'kl': 0.039794921875, 'epoch': 0.09}
  6%|▋         | 128/2000 [58:21<12:28:32, 23.99s/it]  6%|▋         | 129/2000 [58:47<12:47:36, 24.62s/it]                                                     {'loss': 0.0, 'grad_norm': 0.009571878943710171, 'learning_rate': 4.984409767942925e-07, 'completion_length': 687.7291870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0283203125, 'epoch': 0.09}
  6%|▋         | 129/2000 [58:47<12:47:36, 24.62s/it]  6%|▋         | 130/2000 [59:10<12:32:32, 24.15s/it]                                                     {'loss': 0.0, 'grad_norm': 0.005932688295084627, 'learning_rate': 4.983955090077444e-07, 'completion_length': 598.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0244140625, 'epoch': 0.09}
  6%|▋         | 130/2000 [59:10<12:32:32, 24.15s/it]  7%|▋         | 131/2000 [59:38<13:05:00, 25.20s/it]                                                     {'loss': 0.0, 'grad_norm': 0.01376661704053106, 'learning_rate': 4.983493898329315e-07, 'completion_length': 639.1666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.031005859375, 'epoch': 0.09}
  7%|▋         | 131/2000 [59:38<13:05:00, 25.20s/it]  7%|▋         | 132/2000 [1:00:05<13:19:16, 25.67s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007902824094730587, 'learning_rate': 4.98302619390796e-07, 'completion_length': 655.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0264892578125, 'epoch': 0.09}
  7%|▋         | 132/2000 [1:00:05<13:19:16, 25.67s/it]  7%|▋         | 133/2000 [1:00:29<13:04:15, 25.20s/it]                                                       {'loss': 0.0, 'grad_norm': 0.031927777381966456, 'learning_rate': 4.982551978039882e-07, 'completion_length': 634.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.03857421875, 'epoch': 0.09}
  7%|▋         | 133/2000 [1:00:29<13:04:15, 25.20s/it]  7%|▋         | 134/2000 [1:00:51<12:38:01, 24.37s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007672884890092482, 'learning_rate': 4.982071251968652e-07, 'completion_length': 591.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.03076171875, 'epoch': 0.09}
  7%|▋         | 134/2000 [1:00:51<12:38:01, 24.37s/it]  7%|▋         | 135/2000 [1:01:18<13:04:14, 25.23s/it]                                                       {'loss': 0.0, 'grad_norm': 1.127519566448453, 'learning_rate': 4.98158401695492e-07, 'completion_length': 670.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.07715167850255966, 'kl': 0.037841796875, 'epoch': 0.1}
  7%|▋         | 135/2000 [1:01:18<13:04:14, 25.23s/it]  7%|▋         | 136/2000 [1:01:42<12:51:48, 24.84s/it]                                                       {'loss': 0.0001, 'grad_norm': 9.089505424802038, 'learning_rate': 4.981090274276405e-07, 'completion_length': 581.3958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.06689453125, 'epoch': 0.1}
  7%|▋         | 136/2000 [1:01:42<12:51:48, 24.84s/it]  7%|▋         | 137/2000 [1:02:05<12:32:45, 24.24s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.9930467653950915, 'learning_rate': 4.980590025227887e-07, 'completion_length': 556.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.1591796875, 'epoch': 0.1}
  7%|▋         | 137/2000 [1:02:05<12:32:45, 24.24s/it]  7%|▋         | 138/2000 [1:02:33<13:07:48, 25.39s/it]                                                       {'loss': 0.0, 'grad_norm': 0.011091897198164016, 'learning_rate': 4.980083271121214e-07, 'completion_length': 697.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0289306640625, 'epoch': 0.1}
  7%|▋         | 138/2000 [1:02:33<13:07:48, 25.39s/it]  7%|▋         | 139/2000 [1:02:57<12:55:45, 25.01s/it]                                                       {'loss': 0.0, 'grad_norm': 0.0061135540225334285, 'learning_rate': 4.979570013285285e-07, 'completion_length': 658.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.02734375, 'epoch': 0.1}
  7%|▋         | 139/2000 [1:02:57<12:55:45, 25.01s/it]  7%|▋         | 140/2000 [1:03:25<13:21:34, 25.86s/it]                                                       {'loss': 0.0, 'grad_norm': 1.2677166302824026, 'learning_rate': 4.979050253066063e-07, 'completion_length': 659.8958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0289306640625, 'epoch': 0.1}
  7%|▋         | 140/2000 [1:03:25<13:21:34, 25.86s/it]  7%|▋         | 141/2000 [1:03:48<12:56:06, 25.05s/it]                                                       {'loss': 0.0, 'grad_norm': 0.008050332107009155, 'learning_rate': 4.978523991826555e-07, 'completion_length': 620.2916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0286865234375, 'epoch': 0.1}
  7%|▋         | 141/2000 [1:03:48<12:56:06, 25.05s/it]  7%|▋         | 142/2000 [1:04:15<13:14:01, 25.64s/it]                                                       {'loss': 0.0, 'grad_norm': 0.03185646312029535, 'learning_rate': 4.977991230946823e-07, 'completion_length': 621.0416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.03955078125, 'epoch': 0.1}
  7%|▋         | 142/2000 [1:04:15<13:14:01, 25.64s/it]  7%|▋         | 143/2000 [1:04:41<13:09:09, 25.50s/it]                                                       {'loss': 0.0, 'grad_norm': 0.010755268119082837, 'learning_rate': 4.97745197182397e-07, 'completion_length': 658.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.02978515625, 'epoch': 0.1}
  7%|▋         | 143/2000 [1:04:41<13:09:09, 25.50s/it]  7%|▋         | 144/2000 [1:05:05<12:55:27, 25.07s/it]                                                       {'loss': 0.0002, 'grad_norm': 9.957470681629074, 'learning_rate': 4.976906215872137e-07, 'completion_length': 512.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.1787109375, 'epoch': 0.1}
  7%|▋         | 144/2000 [1:05:05<12:55:27, 25.07s/it]  7%|▋         | 145/2000 [1:05:32<13:11:51, 25.61s/it]                                                       {'loss': 0.0, 'grad_norm': 0.014714569000382104, 'learning_rate': 4.976353964522509e-07, 'completion_length': 668.9791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.030029296875, 'epoch': 0.1}
  7%|▋         | 145/2000 [1:05:32<13:11:51, 25.61s/it]  7%|▋         | 146/2000 [1:05:58<13:19:34, 25.88s/it]                                                       {'loss': 0.0, 'grad_norm': 1.824122529248645, 'learning_rate': 4.975795219223298e-07, 'completion_length': 668.3541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.0361328125, 'epoch': 0.1}
  7%|▋         | 146/2000 [1:05:58<13:19:34, 25.88s/it]  7%|▋         | 147/2000 [1:06:21<12:54:35, 25.08s/it]                                                       {'loss': 0.0001, 'grad_norm': 1.2086360645883416, 'learning_rate': 4.97522998143975e-07, 'completion_length': 502.1458435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.875, 'reward': 1.875, 'reward_std': 0.07715167850255966, 'kl': 0.091796875, 'epoch': 0.1}
  7%|▋         | 147/2000 [1:06:21<12:54:35, 25.08s/it]  7%|▋         | 148/2000 [1:06:41<12:03:35, 23.44s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.02675422842291738, 'learning_rate': 4.974658252654134e-07, 'completion_length': 484.5833435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.19140625, 'epoch': 0.1}
  7%|▋         | 148/2000 [1:06:41<12:03:35, 23.44s/it]  7%|▋         | 149/2000 [1:07:05<12:09:54, 23.66s/it]                                                       {'loss': 0.0, 'grad_norm': 0.01195890691644545, 'learning_rate': 4.974080034365746e-07, 'completion_length': 621.4166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.034912109375, 'epoch': 0.11}
  7%|▋         | 149/2000 [1:07:05<12:09:54, 23.66s/it]  8%|▊         | 150/2000 [1:07:28<12:05:07, 23.52s/it]                                                       {'loss': 0.0, 'grad_norm': 0.019023188703075084, 'learning_rate': 4.973495328090889e-07, 'completion_length': 610.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.036376953125, 'epoch': 0.11}
  8%|▊         | 150/2000 [1:07:28<12:05:07, 23.52s/it]  8%|▊         | 151/2000 [1:07:52<12:04:13, 23.50s/it]                                                       {'loss': 0.0, 'grad_norm': 0.010723110490574058, 'learning_rate': 4.972904135362894e-07, 'completion_length': 617.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.047119140625, 'epoch': 0.11}
  8%|▊         | 151/2000 [1:07:52<12:04:13, 23.50s/it]  8%|▊         | 152/2000 [1:08:18<12:26:41, 24.24s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007433643275702807, 'learning_rate': 4.97230645773209e-07, 'completion_length': 657.5416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.031494140625, 'epoch': 0.11}
  8%|▊         | 152/2000 [1:08:18<12:26:41, 24.24s/it]  8%|▊         | 153/2000 [1:08:42<12:28:02, 24.30s/it]                                                       {'loss': 0.0, 'grad_norm': 0.020461038964821886, 'learning_rate': 4.971702296765821e-07, 'completion_length': 627.2708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.042724609375, 'epoch': 0.11}
  8%|▊         | 153/2000 [1:08:42<12:28:02, 24.30s/it]  8%|▊         | 154/2000 [1:09:08<12:44:10, 24.84s/it]                                                       {'loss': 0.0001, 'grad_norm': 1.4166615296311382, 'learning_rate': 4.971091654048427e-07, 'completion_length': 583.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.07715167850255966, 'kl': 0.055908203125, 'epoch': 0.11}
  8%|▊         | 154/2000 [1:09:08<12:44:10, 24.84s/it]  8%|▊         | 155/2000 [1:09:32<12:32:14, 24.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.010536545476650484, 'learning_rate': 4.970474531181245e-07, 'completion_length': 583.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.052978515625, 'epoch': 0.11}
  8%|▊         | 155/2000 [1:09:32<12:32:14, 24.46s/it]  8%|▊         | 156/2000 [1:09:55<12:21:41, 24.13s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.012277805501824425, 'learning_rate': 4.96985092978261e-07, 'completion_length': 546.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.173828125, 'epoch': 0.11}
  8%|▊         | 156/2000 [1:09:55<12:21:41, 24.13s/it]  8%|▊         | 157/2000 [1:10:19<12:18:24, 24.04s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.05680821905778819, 'learning_rate': 4.969220851487844e-07, 'completion_length': 640.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.052490234375, 'epoch': 0.11}
  8%|▊         | 157/2000 [1:10:19<12:18:24, 24.04s/it]  8%|▊         | 158/2000 [1:10:47<12:55:02, 25.25s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.022509217881056535, 'learning_rate': 4.968584297949254e-07, 'completion_length': 647.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0576171875, 'epoch': 0.11}
  8%|▊         | 158/2000 [1:10:47<12:55:02, 25.25s/it]  8%|▊         | 159/2000 [1:11:15<13:16:37, 25.96s/it]                                                       {'loss': 0.0, 'grad_norm': 0.021639966613075542, 'learning_rate': 4.967941270836127e-07, 'completion_length': 692.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.042236328125, 'epoch': 0.11}
  8%|▊         | 159/2000 [1:11:15<13:16:37, 25.96s/it]  8%|▊         | 160/2000 [1:11:41<13:20:19, 26.10s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013201479920063628, 'learning_rate': 4.967291771834726e-07, 'completion_length': 635.9166870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0537109375, 'epoch': 0.11}
  8%|▊         | 160/2000 [1:11:41<13:20:19, 26.10s/it]  8%|▊         | 161/2000 [1:12:04<12:53:49, 25.25s/it]                                                       {'loss': 0.0, 'grad_norm': 0.007895953316548195, 'learning_rate': 4.966635802648288e-07, 'completion_length': 613.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.03515625, 'epoch': 0.11}
  8%|▊         | 161/2000 [1:12:04<12:53:49, 25.25s/it]  8%|▊         | 162/2000 [1:12:32<13:18:44, 26.07s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.037612355842259415, 'learning_rate': 4.965973364997015e-07, 'completion_length': 533.6458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.193359375, 'epoch': 0.11}
  8%|▊         | 162/2000 [1:12:32<13:18:44, 26.07s/it]  8%|▊         | 163/2000 [1:12:56<12:56:45, 25.37s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02793396254284115, 'learning_rate': 4.965304460618072e-07, 'completion_length': 618.9791870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.060546875, 'epoch': 0.12}
  8%|▊         | 163/2000 [1:12:56<12:56:45, 25.37s/it]  8%|▊         | 164/2000 [1:13:20<12:43:04, 24.94s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.013030735402612266, 'learning_rate': 4.964629091265583e-07, 'completion_length': 615.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.0673828125, 'epoch': 0.12}
  8%|▊         | 164/2000 [1:13:20<12:43:04, 24.94s/it]  8%|▊         | 165/2000 [1:13:45<12:38:47, 24.81s/it]                                                       {'loss': 0.0, 'grad_norm': 0.01188289270847529, 'learning_rate': 4.963947258710626e-07, 'completion_length': 608.8541870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.038330078125, 'epoch': 0.12}
  8%|▊         | 165/2000 [1:13:45<12:38:47, 24.81s/it]  8%|▊         | 166/2000 [1:14:09<12:34:18, 24.68s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02266889781613797, 'learning_rate': 4.963258964741226e-07, 'completion_length': 592.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0732421875, 'epoch': 0.12}
  8%|▊         | 166/2000 [1:14:09<12:34:18, 24.68s/it]  8%|▊         | 167/2000 [1:14:33<12:32:24, 24.63s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.015603235733739913, 'learning_rate': 4.962564211162355e-07, 'completion_length': 608.3958740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.050537109375, 'epoch': 0.12}
  8%|▊         | 167/2000 [1:14:33<12:32:24, 24.63s/it]  8%|▊         | 168/2000 [1:14:58<12:33:09, 24.67s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.007737307551914028, 'learning_rate': 4.961862999795923e-07, 'completion_length': 558.8333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.08349609375, 'epoch': 0.12}
  8%|▊         | 168/2000 [1:14:58<12:33:09, 24.67s/it]  8%|▊         | 169/2000 [1:15:23<12:35:56, 24.77s/it]                                                       {'loss': 0.0001, 'grad_norm': 1.8009209854550954, 'learning_rate': 4.961155332480774e-07, 'completion_length': 601.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.050537109375, 'epoch': 0.12}
  8%|▊         | 169/2000 [1:15:23<12:35:56, 24.77s/it]  8%|▊         | 170/2000 [1:15:48<12:34:55, 24.75s/it]                                                       {'loss': 0.0, 'grad_norm': 0.00814145061335762, 'learning_rate': 4.960441211072685e-07, 'completion_length': 664.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.03662109375, 'epoch': 0.12}
  8%|▊         | 170/2000 [1:15:48<12:34:55, 24.75s/it]  9%|▊         | 171/2000 [1:16:13<12:34:31, 24.75s/it]                                                       {'loss': 0.0001, 'grad_norm': 1.1023633220298923, 'learning_rate': 4.959720637444355e-07, 'completion_length': 591.7083740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.0615234375, 'epoch': 0.12}
  9%|▊         | 171/2000 [1:16:13<12:34:31, 24.75s/it]  9%|▊         | 172/2000 [1:16:38<12:38:58, 24.91s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.018758946938430617, 'learning_rate': 4.958993613485405e-07, 'completion_length': 512.6041870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.21875, 'epoch': 0.12}
  9%|▊         | 172/2000 [1:16:38<12:38:58, 24.91s/it]  9%|▊         | 173/2000 [1:17:15<14:26:30, 28.46s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.017825802729607928, 'learning_rate': 4.958260141102369e-07, 'completion_length': 629.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.05517578125, 'epoch': 0.12}
  9%|▊         | 173/2000 [1:17:15<14:26:30, 28.46s/it]  9%|▊         | 174/2000 [1:17:39<13:47:13, 27.18s/it]                                                       {'loss': 0.0, 'grad_norm': 1.1585816480902427, 'learning_rate': 4.957520222218694e-07, 'completion_length': 614.8333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.04248046875, 'epoch': 0.12}
  9%|▊         | 174/2000 [1:17:39<13:47:13, 27.18s/it]  9%|▉         | 175/2000 [1:18:02<13:12:42, 26.06s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.012315875040707643, 'learning_rate': 4.956773858774731e-07, 'completion_length': 635.2708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.053955078125, 'epoch': 0.12}
  9%|▉         | 175/2000 [1:18:02<13:12:42, 26.06s/it]  9%|▉         | 176/2000 [1:18:24<12:31:24, 24.72s/it]                                                       {'loss': 0.0001, 'grad_norm': 2.569295398240899, 'learning_rate': 4.956021052727731e-07, 'completion_length': 590.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.068359375, 'epoch': 0.12}
  9%|▉         | 176/2000 [1:18:24<12:31:24, 24.72s/it]  9%|▉         | 177/2000 [1:18:49<12:33:26, 24.80s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.025331871323793945, 'learning_rate': 4.955261806051839e-07, 'completion_length': 678.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.060546875, 'epoch': 0.13}
  9%|▉         | 177/2000 [1:18:49<12:33:26, 24.80s/it]  9%|▉         | 178/2000 [1:19:12<12:21:54, 24.43s/it]                                                       {'loss': 0.0002, 'grad_norm': 0.03927026054029547, 'learning_rate': 4.954496120738093e-07, 'completion_length': 534.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.212890625, 'epoch': 0.13}
  9%|▉         | 178/2000 [1:19:12<12:21:54, 24.43s/it]  9%|▉         | 179/2000 [1:19:34<11:55:08, 23.56s/it]                                                       {'loss': 0.0003, 'grad_norm': 0.021439480230285534, 'learning_rate': 4.953723998794413e-07, 'completion_length': 463.3333435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.283203125, 'epoch': 0.13}
  9%|▉         | 179/2000 [1:19:34<11:55:08, 23.56s/it]  9%|▉         | 180/2000 [1:19:57<11:48:13, 23.35s/it]                                                       {'loss': 0.0002, 'grad_norm': 3.3207852797380153, 'learning_rate': 4.952945442245597e-07, 'completion_length': 545.6666870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.7916666865348816, 'reward': 1.7916667461395264, 'reward_std': 0.1178511306643486, 'kl': 0.2431640625, 'epoch': 0.13}
  9%|▉         | 180/2000 [1:19:57<11:48:13, 23.35s/it]  9%|▉         | 181/2000 [1:20:19<11:40:03, 23.09s/it]                                                       {'loss': 0.0006, 'grad_norm': 0.028855825755505406, 'learning_rate': 4.95216045313332e-07, 'completion_length': 312.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.55859375, 'epoch': 0.13}
  9%|▉         | 181/2000 [1:20:19<11:40:03, 23.09s/it]  9%|▉         | 182/2000 [1:20:36<10:44:06, 21.26s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.14882307457409205, 'learning_rate': 4.951369033516127e-07, 'completion_length': 125.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8828125, 'epoch': 0.13}
  9%|▉         | 182/2000 [1:20:36<10:44:06, 21.26s/it]  9%|▉         | 183/2000 [1:20:54<10:09:06, 20.11s/it]                                                       {'loss': 0.0011, 'grad_norm': 0.008616093887206347, 'learning_rate': 4.950571185469418e-07, 'completion_length': 27.416667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.13}
  9%|▉         | 183/2000 [1:20:54<10:09:06, 20.11s/it]  9%|▉         | 184/2000 [1:21:04<8:36:21, 17.06s/it]                                                       {'loss': 0.001, 'grad_norm': 0.02139073820342276, 'learning_rate': 4.949766911085461e-07, 'completion_length': 32.270835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.13}
  9%|▉         | 184/2000 [1:21:04<8:36:21, 17.06s/it]  9%|▉         | 185/2000 [1:21:08<6:44:09, 13.36s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.018835435764208666, 'learning_rate': 4.948956212473369e-07, 'completion_length': 9.604166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.13}
  9%|▉         | 185/2000 [1:21:08<6:44:09, 13.36s/it]  9%|▉         | 186/2000 [1:21:20<6:23:09, 12.67s/it]                                                      {'loss': 0.001, 'grad_norm': 0.019663607610288958, 'learning_rate': 4.948139091759108e-07, 'completion_length': 24.604167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9765625, 'epoch': 0.13}
  9%|▉         | 186/2000 [1:21:20<6:23:09, 12.67s/it]  9%|▉         | 187/2000 [1:21:30<5:59:17, 11.89s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01758931493146825, 'learning_rate': 4.947315551085478e-07, 'completion_length': 18.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.13}
  9%|▉         | 187/2000 [1:21:30<5:59:17, 11.89s/it]  9%|▉         | 188/2000 [1:21:34<4:50:26,  9.62s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.018436527264470152, 'learning_rate': 4.946485592612122e-07, 'completion_length': 8.979166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.13}
  9%|▉         | 188/2000 [1:21:34<4:50:26,  9.62s/it]  9%|▉         | 189/2000 [1:21:38<4:02:28,  8.03s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0017888008627571345, 'learning_rate': 4.945649218515506e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.953125, 'epoch': 0.13}
  9%|▉         | 189/2000 [1:21:38<4:02:28,  8.03s/it] 10%|▉         | 190/2000 [1:21:43<3:28:49,  6.92s/it]                                                      {'loss': 0.001, 'grad_norm': 0.017123679545036106, 'learning_rate': 4.944806430988927e-07, 'completion_length': 8.979166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.13}
 10%|▉         | 190/2000 [1:21:43<3:28:49,  6.92s/it] 10%|▉         | 191/2000 [1:21:54<4:13:35,  8.41s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.02632203337126037, 'learning_rate': 4.943957232242494e-07, 'completion_length': 19.70833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.14}
 10%|▉         | 191/2000 [1:21:54<4:13:35,  8.41s/it] 10%|▉         | 192/2000 [1:21:59<3:36:36,  7.19s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0022845328456433975, 'learning_rate': 4.943101624503132e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0859375, 'epoch': 0.14}
 10%|▉         | 192/2000 [1:21:59<3:36:36,  7.19s/it] 10%|▉         | 193/2000 [1:22:05<3:32:03,  7.04s/it]                                                      {'loss': 0.001, 'grad_norm': 0.03390237757828254, 'learning_rate': 4.942239610014575e-07, 'completion_length': 17.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.14}
 10%|▉         | 193/2000 [1:22:05<3:32:03,  7.04s/it] 10%|▉         | 194/2000 [1:22:11<3:15:32,  6.50s/it]                                                      {'loss': 0.001, 'grad_norm': 0.05983376589335179, 'learning_rate': 4.941371191037353e-07, 'completion_length': 10.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.14}
 10%|▉         | 194/2000 [1:22:11<3:15:32,  6.50s/it] 10%|▉         | 195/2000 [1:22:17<3:09:16,  6.29s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.028466988541599732, 'learning_rate': 4.940496369848794e-07, 'completion_length': 11.270833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.14}
 10%|▉         | 195/2000 [1:22:17<3:09:16,  6.29s/it] 10%|▉         | 196/2000 [1:22:21<2:56:57,  5.89s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0019900431741348692, 'learning_rate': 4.939615148743017e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.14}
 10%|▉         | 196/2000 [1:22:21<2:56:57,  5.89s/it] 10%|▉         | 197/2000 [1:22:35<4:03:36,  8.11s/it]                                                      {'loss': 0.001, 'grad_norm': 0.04010339447637102, 'learning_rate': 4.938727530030919e-07, 'completion_length': 36.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.14}
 10%|▉         | 197/2000 [1:22:35<4:03:36,  8.11s/it] 10%|▉         | 198/2000 [1:22:40<3:40:59,  7.36s/it]                                                      {'loss': 0.001, 'grad_norm': 0.027368362760732633, 'learning_rate': 4.937833516040176e-07, 'completion_length': 11.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.14}
 10%|▉         | 198/2000 [1:22:40<3:40:59,  7.36s/it] 10%|▉         | 199/2000 [1:22:54<4:38:07,  9.27s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0473618404903978, 'learning_rate': 4.936933109115238e-07, 'completion_length': 32.79166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.14}
 10%|▉         | 199/2000 [1:22:54<4:38:07,  9.27s/it] 10%|█         | 200/2000 [1:23:03<4:37:21,  9.25s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0038110696499839415, 'learning_rate': 4.936026311617316e-07, 'completion_length': 20.104167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.14}
 10%|█         | 200/2000 [1:23:03<4:37:21,  9.25s/it] 10%|█         | 201/2000 [1:23:09<4:08:56,  8.30s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0074136505333490844, 'learning_rate': 4.935113125924379e-07, 'completion_length': 11.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.14}
 10%|█         | 201/2000 [1:23:09<4:08:56,  8.30s/it] 10%|█         | 202/2000 [1:23:22<4:44:45,  9.50s/it]                                                      {'loss': 0.001, 'grad_norm': 0.06353224424983969, 'learning_rate': 4.934193554431153e-07, 'completion_length': 22.541667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.14}
 10%|█         | 202/2000 [1:23:22<4:44:45,  9.50s/it] 10%|█         | 203/2000 [1:23:36<5:25:31, 10.87s/it]                                                      {'loss': 0.001, 'grad_norm': 0.002565479612172358, 'learning_rate': 4.933267599549105e-07, 'completion_length': 25.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.99609375, 'epoch': 0.14}
 10%|█         | 203/2000 [1:23:36<5:25:31, 10.87s/it] 10%|█         | 204/2000 [1:23:54<6:30:41, 13.05s/it]                                                      {'loss': 0.0011, 'grad_norm': 1.0645628802471083, 'learning_rate': 4.932335263706445e-07, 'completion_length': 28.45833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.0546875, 'epoch': 0.14}
 10%|█         | 204/2000 [1:23:54<6:30:41, 13.05s/it] 10%|█         | 205/2000 [1:24:04<6:04:16, 12.18s/it]                                                      {'loss': 0.001, 'grad_norm': 0.015528397350109609, 'learning_rate': 4.931396549348114e-07, 'completion_length': 18.33333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.15}
 10%|█         | 205/2000 [1:24:04<6:04:16, 12.18s/it] 10%|█         | 206/2000 [1:24:10<5:05:08, 10.21s/it]                                                      {'loss': 0.0012, 'grad_norm': 0.20034253263849391, 'learning_rate': 4.930451458935783e-07, 'completion_length': 11.708333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.21875, 'epoch': 0.15}
 10%|█         | 206/2000 [1:24:10<5:05:08, 10.21s/it] 10%|█         | 207/2000 [1:24:30<6:38:29, 13.34s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.05731236476577069, 'learning_rate': 4.929499994947838e-07, 'completion_length': 35.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.15}
 10%|█         | 207/2000 [1:24:30<6:38:29, 13.34s/it] 10%|█         | 208/2000 [1:24:36<5:28:18, 10.99s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.003494914905838003, 'learning_rate': 4.928542159879385e-07, 'completion_length': 10.354166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.15}
 10%|█         | 208/2000 [1:24:36<5:28:18, 10.99s/it] 10%|█         | 209/2000 [1:24:52<6:13:33, 12.51s/it]                                                      {'loss': 0.001, 'grad_norm': 1.2176084335588324, 'learning_rate': 4.927577956242234e-07, 'completion_length': 45.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.99609375, 'epoch': 0.15}
 10%|█         | 209/2000 [1:24:52<6:13:33, 12.51s/it] 10%|█         | 210/2000 [1:25:01<5:42:27, 11.48s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01853712502912848, 'learning_rate': 4.926607386564898e-07, 'completion_length': 24.27083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.15}
 10%|█         | 210/2000 [1:25:01<5:42:27, 11.48s/it] 11%|█         | 211/2000 [1:25:09<5:14:27, 10.55s/it]                                                      {'loss': 0.001, 'grad_norm': 0.022218294216949323, 'learning_rate': 4.92563045339258e-07, 'completion_length': 16.95833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.15}
 11%|█         | 211/2000 [1:25:09<5:14:27, 10.55s/it] 11%|█         | 212/2000 [1:25:15<4:27:38,  8.98s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010401305424096148, 'learning_rate': 4.924647159287175e-07, 'completion_length': 10.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.15}
 11%|█         | 212/2000 [1:25:15<4:27:38,  8.98s/it] 11%|█         | 213/2000 [1:25:33<5:55:48, 11.95s/it]                                                      {'loss': 0.001, 'grad_norm': 0.9402832116113068, 'learning_rate': 4.923657506827258e-07, 'completion_length': 31.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 1.0390625, 'epoch': 0.15}
 11%|█         | 213/2000 [1:25:33<5:55:48, 11.95s/it] 11%|█         | 214/2000 [1:25:52<6:54:35, 13.93s/it]                                                      {'loss': 0.001, 'grad_norm': 1.0607306338305398, 'learning_rate': 4.922661498608076e-07, 'completion_length': 52.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6458333730697632, 'reward': 1.6458333730697632, 'reward_std': 0.0589255653321743, 'kl': 1.0078125, 'epoch': 0.15}
 11%|█         | 214/2000 [1:25:52<6:54:35, 13.93s/it] 11%|█         | 215/2000 [1:25:57<5:31:52, 11.16s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.026514248912863223, 'learning_rate': 4.921659137241543e-07, 'completion_length': 9.645833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.15}
 11%|█         | 215/2000 [1:25:57<5:31:52, 11.16s/it] 11%|█         | 216/2000 [1:26:02<4:35:18,  9.26s/it]                                                      {'loss': 0.001, 'grad_norm': 0.002836715625930954, 'learning_rate': 4.920650425356239e-07, 'completion_length': 9.791666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.15}
 11%|█         | 216/2000 [1:26:02<4:35:18,  9.26s/it] 11%|█         | 217/2000 [1:26:12<4:45:56,  9.62s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009642756466228664, 'learning_rate': 4.919635365597389e-07, 'completion_length': 18.08333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.15}
 11%|█         | 217/2000 [1:26:12<4:45:56,  9.62s/it] 11%|█         | 218/2000 [1:26:18<4:11:20,  8.46s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0018904458476656596, 'learning_rate': 4.918613960626873e-07, 'completion_length': 11.020833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.15}
 11%|█         | 218/2000 [1:26:18<4:11:20,  8.46s/it] 11%|█         | 219/2000 [1:26:25<3:56:28,  7.97s/it]                                                      {'loss': 0.0012, 'grad_norm': 0.15122170323545894, 'learning_rate': 4.917586213123202e-07, 'completion_length': 16.479167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.1640625, 'epoch': 0.15}
 11%|█         | 219/2000 [1:26:25<3:56:28,  7.97s/it] 11%|█         | 220/2000 [1:26:34<4:12:30,  8.51s/it]                                                      {'loss': 0.0013, 'grad_norm': 3.9667700238643078, 'learning_rate': 4.916552125781528e-07, 'completion_length': 16.791667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.28125, 'epoch': 0.16}
 11%|█         | 220/2000 [1:26:34<4:12:30,  8.51s/it] 11%|█         | 221/2000 [1:26:41<3:52:54,  7.86s/it]                                                      {'loss': 0.001, 'grad_norm': 0.012384090979620172, 'learning_rate': 4.915511701313622e-07, 'completion_length': 11.020833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.16}
 11%|█         | 221/2000 [1:26:41<3:52:54,  7.86s/it] 11%|█         | 222/2000 [1:26:45<3:21:27,  6.80s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0014535827786254208, 'learning_rate': 4.914464942447876e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.16}
 11%|█         | 222/2000 [1:26:45<3:21:27,  6.80s/it] 11%|█         | 223/2000 [1:26:49<2:59:10,  6.05s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.001430858180046411, 'learning_rate': 4.913411851929294e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.16}
 11%|█         | 223/2000 [1:26:49<2:59:10,  6.05s/it] 11%|█         | 224/2000 [1:26:58<3:26:28,  6.98s/it]                                                      {'loss': 0.001, 'grad_norm': 1.699734817480244, 'learning_rate': 4.912352432519484e-07, 'completion_length': 19.70833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.0234375, 'epoch': 0.16}
 11%|█         | 224/2000 [1:26:58<3:26:28,  6.98s/it] 11%|█▏        | 225/2000 [1:27:13<4:36:24,  9.34s/it]                                                      {'loss': 0.001, 'grad_norm': 1.1150221612059652, 'learning_rate': 4.911286686996646e-07, 'completion_length': 23.95833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.0234375, 'epoch': 0.16}
 11%|█▏        | 225/2000 [1:27:13<4:36:24,  9.34s/it] 11%|█▏        | 226/2000 [1:27:20<4:12:22,  8.54s/it]                                                      {'loss': 0.001, 'grad_norm': 0.02654719748256952, 'learning_rate': 4.910214618155579e-07, 'completion_length': 12.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.16}
 11%|█▏        | 226/2000 [1:27:20<4:12:22,  8.54s/it] 11%|█▏        | 227/2000 [1:27:29<4:12:28,  8.54s/it]                                                      {'loss': 0.001, 'grad_norm': 0.03689293812806565, 'learning_rate': 4.909136228807654e-07, 'completion_length': 10.145833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.97265625, 'epoch': 0.16}
 11%|█▏        | 227/2000 [1:27:29<4:12:28,  8.54s/it] 11%|█▏        | 228/2000 [1:27:33<3:35:01,  7.28s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0009703062685626609, 'learning_rate': 4.908051521780824e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.16}
 11%|█▏        | 228/2000 [1:27:33<3:35:01,  7.28s/it] 11%|█▏        | 229/2000 [1:27:40<3:35:52,  7.31s/it]                                                      {'loss': 0.001, 'grad_norm': 0.025693658980539987, 'learning_rate': 4.906960499919605e-07, 'completion_length': 16.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.16}
 11%|█▏        | 229/2000 [1:27:40<3:35:52,  7.31s/it] 12%|█▏        | 230/2000 [1:27:45<3:09:17,  6.42s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0005621216263143429, 'learning_rate': 4.905863166085075e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.16}
 12%|█▏        | 230/2000 [1:27:45<3:09:17,  6.42s/it] 12%|█▏        | 231/2000 [1:27:49<2:50:49,  5.79s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0006564277709345245, 'learning_rate': 4.904759523154865e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.16}
 12%|█▏        | 231/2000 [1:27:49<2:50:49,  5.79s/it] 12%|█▏        | 232/2000 [1:27:53<2:37:57,  5.36s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00131290857073447, 'learning_rate': 4.90364957402315e-07, 'completion_length': 9.041666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.16}
 12%|█▏        | 232/2000 [1:27:53<2:37:57,  5.36s/it] 12%|█▏        | 233/2000 [1:27:58<2:31:10,  5.13s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0007229201323520246, 'learning_rate': 4.90253332160064e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.16}
 12%|█▏        | 233/2000 [1:27:58<2:31:10,  5.13s/it] 12%|█▏        | 234/2000 [1:28:03<2:26:36,  4.98s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0005161574011095427, 'learning_rate': 4.90141076881458e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.17}
 12%|█▏        | 234/2000 [1:28:03<2:26:36,  4.98s/it] 12%|█▏        | 235/2000 [1:28:07<2:20:35,  4.78s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0005535099650108261, 'learning_rate': 4.900281918608732e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.17}
 12%|█▏        | 235/2000 [1:28:07<2:20:35,  4.78s/it] 12%|█▏        | 236/2000 [1:28:11<2:16:31,  4.64s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00041141515446095454, 'learning_rate': 4.899146773943373e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.17}
 12%|█▏        | 236/2000 [1:28:11<2:16:31,  4.64s/it] 12%|█▏        | 237/2000 [1:28:15<2:13:36,  4.55s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00035025986146241937, 'learning_rate': 4.898005337795291e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.17}
 12%|█▏        | 237/2000 [1:28:15<2:13:36,  4.55s/it] 12%|█▏        | 238/2000 [1:28:31<3:48:44,  7.79s/it]                                                      {'loss': 0.0144, 'grad_norm': 16.309332534577134, 'learning_rate': 4.896857613157764e-07, 'completion_length': 24.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 14.4375, 'epoch': 0.17}
 12%|█▏        | 238/2000 [1:28:31<3:48:44,  7.79s/it] 12%|█▏        | 239/2000 [1:28:46<4:56:24, 10.10s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0017673758430117232, 'learning_rate': 4.895703603040572e-07, 'completion_length': 24.83333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.17}
 12%|█▏        | 239/2000 [1:28:46<4:56:24, 10.10s/it] 12%|█▏        | 240/2000 [1:28:51<4:05:26,  8.37s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0004987342007400654, 'learning_rate': 4.894543310469967e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.17}
 12%|█▏        | 240/2000 [1:28:51<4:05:26,  8.37s/it] 12%|█▏        | 241/2000 [1:28:55<3:29:41,  7.15s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0005073336036334968, 'learning_rate': 4.893376738488685e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.17}
 12%|█▏        | 241/2000 [1:28:55<3:29:41,  7.15s/it] 12%|█▏        | 242/2000 [1:28:59<3:04:25,  6.29s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0003847321193094898, 'learning_rate': 4.892203890155923e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.17}
 12%|█▏        | 242/2000 [1:28:59<3:04:25,  6.29s/it] 12%|█▏        | 243/2000 [1:29:07<3:17:37,  6.75s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0019311251785607251, 'learning_rate': 4.891024768547337e-07, 'completion_length': 14.020833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.17}
 12%|█▏        | 243/2000 [1:29:07<3:17:37,  6.75s/it] 12%|█▏        | 244/2000 [1:29:11<2:56:14,  6.02s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0004512034556684807, 'learning_rate': 4.88983937675504e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.17}
 12%|█▏        | 244/2000 [1:29:11<2:56:14,  6.02s/it] 12%|█▏        | 245/2000 [1:29:18<3:05:32,  6.34s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0008228194291751417, 'learning_rate': 4.888647717887581e-07, 'completion_length': 12.916666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.17}
 12%|█▏        | 245/2000 [1:29:18<3:05:32,  6.34s/it] 12%|█▏        | 246/2000 [1:29:25<3:03:06,  6.26s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0011712386299322984, 'learning_rate': 4.887449795069948e-07, 'completion_length': 10.666666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.17}
 12%|█▏        | 246/2000 [1:29:25<3:03:06,  6.26s/it] 12%|█▏        | 247/2000 [1:29:31<3:00:45,  6.19s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.05210110656259442, 'learning_rate': 4.886245611443554e-07, 'completion_length': 11.458333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.1015625, 'epoch': 0.17}
 12%|█▏        | 247/2000 [1:29:31<3:00:45,  6.19s/it] 12%|█▏        | 248/2000 [1:29:35<2:44:35,  5.64s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00047267773263776427, 'learning_rate': 4.885035170166228e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.18}
 12%|█▏        | 248/2000 [1:29:35<2:44:35,  5.64s/it] 12%|█▏        | 249/2000 [1:29:39<2:33:01,  5.24s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00045362333874778937, 'learning_rate': 4.883818474412213e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.109375, 'epoch': 0.18}
 12%|█▏        | 249/2000 [1:29:39<2:33:01,  5.24s/it] 12%|█▎        | 250/2000 [1:29:44<2:25:05,  4.97s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0004953119896299181, 'learning_rate': 4.882595527372152e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.18}
 12%|█▎        | 250/2000 [1:29:44<2:25:05,  4.97s/it] 13%|█▎        | 251/2000 [1:29:48<2:19:13,  4.78s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0005082881455006662, 'learning_rate': 4.881366332253081e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.18}
 13%|█▎        | 251/2000 [1:29:48<2:19:13,  4.78s/it] 13%|█▎        | 252/2000 [1:30:01<3:28:02,  7.14s/it]                                                      {'loss': 0.001, 'grad_norm': 0.04086911304175752, 'learning_rate': 4.880130892278419e-07, 'completion_length': 20.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.18}
 13%|█▎        | 252/2000 [1:30:01<3:28:02,  7.14s/it] 13%|█▎        | 253/2000 [1:30:06<3:15:13,  6.70s/it]                                                      {'loss': 0.0011, 'grad_norm': 15.266631034573344, 'learning_rate': 4.878889210687965e-07, 'completion_length': 11.604166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.1328125, 'epoch': 0.18}
 13%|█▎        | 253/2000 [1:30:06<3:15:13,  6.70s/it] 13%|█▎        | 254/2000 [1:30:11<2:54:58,  6.01s/it]                                                      {'loss': 0.001, 'grad_norm': 0.002882034227896067, 'learning_rate': 4.877641290737883e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.18}
 13%|█▎        | 254/2000 [1:30:11<2:54:58,  6.01s/it] 13%|█▎        | 255/2000 [1:30:15<2:40:15,  5.51s/it]                                                      {'loss': 0.001, 'grad_norm': 0.000514293553328652, 'learning_rate': 4.8763871357007e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.18}
 13%|█▎        | 255/2000 [1:30:15<2:40:15,  5.51s/it] 13%|█▎        | 256/2000 [1:30:24<3:10:02,  6.54s/it]                                                      {'loss': 0.0012, 'grad_norm': 5.648863319550813, 'learning_rate': 4.875126748865289e-07, 'completion_length': 16.041667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.203125, 'epoch': 0.18}
 13%|█▎        | 256/2000 [1:30:24<3:10:02,  6.54s/it] 13%|█▎        | 257/2000 [1:30:28<2:51:12,  5.89s/it]                                                      {'loss': 0.0011, 'grad_norm': 5.7112374639784065, 'learning_rate': 4.873860133536869e-07, 'completion_length': 9.145833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 1.0625, 'epoch': 0.18}
 13%|█▎        | 257/2000 [1:30:28<2:51:12,  5.89s/it] 13%|█▎        | 258/2000 [1:30:34<2:50:40,  5.88s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0025332791372048957, 'learning_rate': 4.872587293036991e-07, 'completion_length': 10.833333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.18}
 13%|█▎        | 258/2000 [1:30:34<2:50:40,  5.88s/it] 13%|█▎        | 259/2000 [1:30:39<2:40:00,  5.51s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00273570111382019, 'learning_rate': 4.871308230703528e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.18}
 13%|█▎        | 259/2000 [1:30:39<2:40:00,  5.51s/it] 13%|█▎        | 260/2000 [1:30:49<3:20:43,  6.92s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0646454035052748, 'learning_rate': 4.870022949890676e-07, 'completion_length': 19.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.18}
 13%|█▎        | 260/2000 [1:30:49<3:20:43,  6.92s/it] 13%|█▎        | 261/2000 [1:30:53<2:58:05,  6.14s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0004292004273910276, 'learning_rate': 4.868731453968932e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0859375, 'epoch': 0.18}
 13%|█▎        | 261/2000 [1:30:53<2:58:05,  6.14s/it] 13%|█▎        | 262/2000 [1:30:58<2:42:24,  5.61s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00040271866955343, 'learning_rate': 4.867433746325093e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.19}
 13%|█▎        | 262/2000 [1:30:58<2:42:24,  5.61s/it] 13%|█▎        | 263/2000 [1:31:02<2:31:06,  5.22s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00031245928121431487, 'learning_rate': 4.866129830362246e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.0, 'kl': 1.1171875, 'epoch': 0.19}
 13%|█▎        | 263/2000 [1:31:02<2:31:06,  5.22s/it] 13%|█▎        | 264/2000 [1:31:08<2:38:59,  5.50s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01120389772886995, 'learning_rate': 4.864819709499761e-07, 'completion_length': 12.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.19}
 13%|█▎        | 264/2000 [1:31:08<2:38:59,  5.50s/it] 13%|█▎        | 265/2000 [1:31:12<2:28:42,  5.14s/it]                                                      {'loss': 0.0017, 'grad_norm': 37.164207033132065, 'learning_rate': 4.863503387173275e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8958333730697632, 'reward': 1.8958333730697632, 'reward_std': 0.14801263809204102, 'kl': 1.7421875, 'epoch': 0.19}
 13%|█▎        | 265/2000 [1:31:12<2:28:42,  5.14s/it] 13%|█▎        | 266/2000 [1:31:17<2:22:07,  4.92s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0026061694106579527, 'learning_rate': 4.86218086683469e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.19}
 13%|█▎        | 266/2000 [1:31:17<2:22:07,  4.92s/it] 13%|█▎        | 267/2000 [1:31:26<2:55:05,  6.06s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.03972613903095757, 'learning_rate': 4.860852151952163e-07, 'completion_length': 15.395833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.19}
 13%|█▎        | 267/2000 [1:31:26<2:55:05,  6.06s/it] 13%|█▎        | 268/2000 [1:31:38<3:48:20,  7.91s/it]                                                      {'loss': 0.0011, 'grad_norm': 4.3502593768661235, 'learning_rate': 4.85951724601009e-07, 'completion_length': 20.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.078125, 'epoch': 0.19}
 13%|█▎        | 268/2000 [1:31:38<3:48:20,  7.91s/it] 13%|█▎        | 269/2000 [1:31:44<3:36:55,  7.52s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.10813411670152048, 'learning_rate': 4.858176152509111e-07, 'completion_length': 12.416666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.19}
 13%|█▎        | 269/2000 [1:31:44<3:36:55,  7.52s/it] 14%|█▎        | 270/2000 [1:31:49<3:09:15,  6.56s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0003308117987339105, 'learning_rate': 4.856828874966086e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.19}
 14%|█▎        | 270/2000 [1:31:49<3:09:15,  6.56s/it] 14%|█▎        | 271/2000 [1:31:57<3:26:04,  7.15s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0010124819919921201, 'learning_rate': 4.855475416914091e-07, 'completion_length': 17.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.19}
 14%|█▎        | 271/2000 [1:31:57<3:26:04,  7.15s/it] 14%|█▎        | 272/2000 [1:32:03<3:09:06,  6.57s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0023249086720824367, 'learning_rate': 4.854115781902414e-07, 'completion_length': 10.229166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.19}
 14%|█▎        | 272/2000 [1:32:03<3:09:06,  6.57s/it] 14%|█▎        | 273/2000 [1:32:07<2:49:41,  5.90s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0007283952143682173, 'learning_rate': 4.852749973496538e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.19}
 14%|█▎        | 273/2000 [1:32:07<2:49:41,  5.90s/it] 14%|█▎        | 274/2000 [1:32:11<2:36:11,  5.43s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0003774421267963633, 'learning_rate': 4.851377995278138e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.19}
 14%|█▎        | 274/2000 [1:32:11<2:36:11,  5.43s/it] 14%|█▍        | 275/2000 [1:32:24<3:37:57,  7.58s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.34699496733320945, 'learning_rate': 4.849999850845065e-07, 'completion_length': 22.604167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.1015625, 'epoch': 0.19}
 14%|█▍        | 275/2000 [1:32:24<3:37:57,  7.58s/it] 14%|█▍        | 276/2000 [1:32:28<3:10:10,  6.62s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0019111517200553153, 'learning_rate': 4.848615543811344e-07, 'completion_length': 9.041666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.2}
 14%|█▍        | 276/2000 [1:32:28<3:10:10,  6.62s/it] 14%|█▍        | 277/2000 [1:32:33<2:50:54,  5.95s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.002228692799329278, 'learning_rate': 4.847225077807159e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.2}
 14%|█▍        | 277/2000 [1:32:33<2:50:54,  5.95s/it] 14%|█▍        | 278/2000 [1:32:37<2:36:58,  5.47s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0004308418811356278, 'learning_rate': 4.845828456478842e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.2}
 14%|█▍        | 278/2000 [1:32:37<2:36:58,  5.47s/it] 14%|█▍        | 279/2000 [1:32:43<2:38:09,  5.51s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0018803303468325776, 'learning_rate': 4.844425683488873e-07, 'completion_length': 10.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.2}
 14%|█▍        | 279/2000 [1:32:43<2:38:09,  5.51s/it] 14%|█▍        | 280/2000 [1:32:47<2:28:04,  5.17s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00030882718192315435, 'learning_rate': 4.843016762515859e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.2}
 14%|█▍        | 280/2000 [1:32:47<2:28:04,  5.17s/it] 14%|█▍        | 281/2000 [1:33:02<3:51:31,  8.08s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.09202322492171469, 'learning_rate': 4.841601697254531e-07, 'completion_length': 31.854167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.2}
 14%|█▍        | 281/2000 [1:33:02<3:51:31,  8.08s/it] 14%|█▍        | 282/2000 [1:33:06<3:19:16,  6.96s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.000541811051801917, 'learning_rate': 4.840180491415733e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.2}
 14%|█▍        | 282/2000 [1:33:06<3:19:16,  6.96s/it] 14%|█▍        | 283/2000 [1:33:11<2:58:45,  6.25s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0002892757118529943, 'learning_rate': 4.838753148726411e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.2}
 14%|█▍        | 283/2000 [1:33:11<2:58:45,  6.25s/it] 14%|█▍        | 284/2000 [1:33:15<2:44:55,  5.77s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0003753505765443966, 'learning_rate': 4.837319672929606e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.953125, 'epoch': 0.2}
 14%|█▍        | 284/2000 [1:33:15<2:44:55,  5.77s/it] 14%|█▍        | 285/2000 [1:33:20<2:32:42,  5.34s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00047987785214367135, 'learning_rate': 4.835880067784441e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.2}
 14%|█▍        | 285/2000 [1:33:20<2:32:42,  5.34s/it] 14%|█▍        | 286/2000 [1:33:24<2:24:08,  5.05s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0005820648786837856, 'learning_rate': 4.834434337066111e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.2}
 14%|█▍        | 286/2000 [1:33:24<2:24:08,  5.05s/it] 14%|█▍        | 287/2000 [1:33:42<4:12:04,  8.83s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.13987872538462193, 'learning_rate': 4.832982484565878e-07, 'completion_length': 27.77083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0859375, 'epoch': 0.2}
 14%|█▍        | 287/2000 [1:33:42<4:12:04,  8.83s/it] 14%|█▍        | 288/2000 [1:33:48<3:52:22,  8.14s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.03652211383373379, 'learning_rate': 4.831524514091056e-07, 'completion_length': 12.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0859375, 'epoch': 0.2}
 14%|█▍        | 288/2000 [1:33:48<3:52:22,  8.14s/it] 14%|█▍        | 289/2000 [1:33:53<3:19:38,  7.00s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.00045275829669057433, 'learning_rate': 4.830060429465001e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.2}
 14%|█▍        | 289/2000 [1:33:53<3:19:38,  7.00s/it] 14%|█▍        | 290/2000 [1:33:57<2:57:19,  6.22s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0023841813270532846, 'learning_rate': 4.828590234527106e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.21}
 14%|█▍        | 290/2000 [1:33:57<2:57:19,  6.22s/it] 15%|█▍        | 291/2000 [1:34:01<2:41:37,  5.67s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0018290350138999536, 'learning_rate': 4.827113933132784e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.21}
 15%|█▍        | 291/2000 [1:34:01<2:41:37,  5.67s/it] 15%|█▍        | 292/2000 [1:34:07<2:44:14,  5.77s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0024237887591220513, 'learning_rate': 4.825631529153466e-07, 'completion_length': 11.395833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.21}
 15%|█▍        | 292/2000 [1:34:07<2:44:14,  5.77s/it] 15%|█▍        | 293/2000 [1:34:12<2:31:56,  5.34s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0006159839221853727, 'learning_rate': 4.82414302647658e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.21}
 15%|█▍        | 293/2000 [1:34:12<2:31:56,  5.34s/it] 15%|█▍        | 294/2000 [1:34:16<2:23:23,  5.04s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0005985990501252486, 'learning_rate': 4.822648429005553e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.21}
 15%|█▍        | 294/2000 [1:34:16<2:23:23,  5.04s/it] 15%|█▍        | 295/2000 [1:34:20<2:17:40,  4.85s/it]                                                      {'loss': 0.001, 'grad_norm': 0.001534176346350214, 'learning_rate': 4.821147740659793e-07, 'completion_length': 9.104166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.21}
 15%|█▍        | 295/2000 [1:34:20<2:17:40,  4.85s/it] 15%|█▍        | 296/2000 [1:34:33<3:22:18,  7.12s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0008304384361943535, 'learning_rate': 4.81964096537468e-07, 'completion_length': 19.979167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.21}
 15%|█▍        | 296/2000 [1:34:33<3:22:18,  7.12s/it] 15%|█▍        | 297/2000 [1:34:42<3:36:47,  7.64s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0015223980420616943, 'learning_rate': 4.818128107101557e-07, 'completion_length': 16.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91796875, 'epoch': 0.21}
 15%|█▍        | 297/2000 [1:34:42<3:36:47,  7.64s/it] 15%|█▍        | 298/2000 [1:34:46<3:08:25,  6.64s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.000578636910562468, 'learning_rate': 4.816609169807716e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.21}
 15%|█▍        | 298/2000 [1:34:46<3:08:25,  6.64s/it] 15%|█▍        | 299/2000 [1:34:50<2:48:50,  5.96s/it]                                                      {'loss': 0.001, 'grad_norm': 0.000720263655345422, 'learning_rate': 4.815084157476395e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.21}
 15%|█▍        | 299/2000 [1:34:50<2:48:50,  5.96s/it] 15%|█▌        | 300/2000 [1:34:56<2:47:25,  5.91s/it]                                                      {'loss': 0.001, 'grad_norm': 0.011401460713478018, 'learning_rate': 4.81355307410676e-07, 'completion_length': 12.791666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.21}
 15%|█▌        | 300/2000 [1:34:56<2:47:25,  5.91s/it] 15%|█▌        | 301/2000 [1:35:09<3:49:31,  8.11s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0027133798614534096, 'learning_rate': 4.812015923713901e-07, 'completion_length': 21.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.21}
 15%|█▌        | 301/2000 [1:35:09<3:49:31,  8.11s/it] 15%|█▌        | 302/2000 [1:35:18<3:56:33,  8.36s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0006778266645228653, 'learning_rate': 4.810472710328812e-07, 'completion_length': 15.541666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.21}
 15%|█▌        | 302/2000 [1:35:18<3:56:33,  8.36s/it] 15%|█▌        | 303/2000 [1:35:23<3:22:04,  7.14s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0004190864982044988, 'learning_rate': 4.808923437998392e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.21}
 15%|█▌        | 303/2000 [1:35:23<3:22:04,  7.14s/it] 15%|█▌        | 304/2000 [1:35:40<4:48:04, 10.19s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006642276449483353, 'learning_rate': 4.80736811078543e-07, 'completion_length': 27.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.22}
 15%|█▌        | 304/2000 [1:35:40<4:48:04, 10.19s/it] 15%|█▌        | 305/2000 [1:35:45<4:05:35,  8.69s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0027267617027400257, 'learning_rate': 4.805806732768584e-07, 'completion_length': 10.229166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.22}
 15%|█▌        | 305/2000 [1:35:45<4:05:35,  8.69s/it] 15%|█▌        | 306/2000 [1:35:51<3:44:41,  7.96s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.10886408914737247, 'learning_rate': 4.804239308042391e-07, 'completion_length': 14.416666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.1484375, 'epoch': 0.22}
 15%|█▌        | 306/2000 [1:35:51<3:44:41,  7.96s/it] 15%|█▌        | 307/2000 [1:36:04<4:27:20,  9.47s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.004821016703609961, 'learning_rate': 4.802665840717238e-07, 'completion_length': 21.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.22}
 15%|█▌        | 307/2000 [1:36:04<4:27:20,  9.47s/it] 15%|█▌        | 308/2000 [1:36:11<4:02:37,  8.60s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.07856048973730768, 'learning_rate': 4.80108633491936e-07, 'completion_length': 12.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.09375, 'epoch': 0.22}
 15%|█▌        | 308/2000 [1:36:11<4:02:37,  8.60s/it] 15%|█▌        | 309/2000 [1:36:17<3:42:10,  7.88s/it]                                                      {'loss': 0.001, 'grad_norm': 0.015913295380655276, 'learning_rate': 4.799500794790826e-07, 'completion_length': 13.041666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.22}
 15%|█▌        | 309/2000 [1:36:17<3:42:10,  7.88s/it] 16%|█▌        | 310/2000 [1:36:23<3:27:49,  7.38s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0029155199245504545, 'learning_rate': 4.79790922448953e-07, 'completion_length': 11.729166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.22}
 16%|█▌        | 310/2000 [1:36:23<3:27:49,  7.38s/it] 16%|█▌        | 311/2000 [1:36:28<3:01:50,  6.46s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0007828918343757596, 'learning_rate': 4.796311628189181e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0703125, 'epoch': 0.22}
 16%|█▌        | 311/2000 [1:36:28<3:01:50,  6.46s/it] 16%|█▌        | 312/2000 [1:36:40<3:49:59,  8.17s/it]                                                      {'loss': 0.001, 'grad_norm': 0.02176296178424807, 'learning_rate': 4.794708010079288e-07, 'completion_length': 32.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.22}
 16%|█▌        | 312/2000 [1:36:40<3:49:59,  8.17s/it] 16%|█▌        | 313/2000 [1:36:55<4:52:25, 10.40s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0008432796913472143, 'learning_rate': 4.793098374365152e-07, 'completion_length': 24.83333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.22}
 16%|█▌        | 313/2000 [1:36:55<4:52:25, 10.40s/it] 16%|█▌        | 314/2000 [1:37:05<4:48:47, 10.28s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010696184695304246, 'learning_rate': 4.791482725267856e-07, 'completion_length': 23.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.22}
 16%|█▌        | 314/2000 [1:37:05<4:48:47, 10.28s/it] 16%|█▌        | 315/2000 [1:37:11<4:08:20,  8.84s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.028648089025340124, 'learning_rate': 4.789861067024252e-07, 'completion_length': 12.291666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.22}
 16%|█▌        | 315/2000 [1:37:11<4:08:20,  8.84s/it] 16%|█▌        | 316/2000 [1:37:17<3:45:51,  8.05s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005985826613157952, 'learning_rate': 4.788233403886949e-07, 'completion_length': 11.645833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.22}
 16%|█▌        | 316/2000 [1:37:17<3:45:51,  8.05s/it] 16%|█▌        | 317/2000 [1:37:22<3:20:15,  7.14s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.015881639002273736, 'learning_rate': 4.786599740124302e-07, 'completion_length': 10.083333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.22}
 16%|█▌        | 317/2000 [1:37:22<3:20:15,  7.14s/it] 16%|█▌        | 318/2000 [1:37:27<2:56:41,  6.30s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0013091588596030582, 'learning_rate': 4.784960080020407e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.23}
 16%|█▌        | 318/2000 [1:37:27<2:56:41,  6.30s/it] 16%|█▌        | 319/2000 [1:37:33<3:01:53,  6.49s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005134167791929091, 'learning_rate': 4.783314427875079e-07, 'completion_length': 14.083333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.23}
 16%|█▌        | 319/2000 [1:37:33<3:01:53,  6.49s/it] 16%|█▌        | 320/2000 [1:37:44<3:34:24,  7.66s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.002215342660143298, 'learning_rate': 4.78166278800385e-07, 'completion_length': 20.354167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.23}
 16%|█▌        | 320/2000 [1:37:44<3:34:24,  7.66s/it] 16%|█▌        | 321/2000 [1:37:53<3:50:06,  8.22s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0017456297573698219, 'learning_rate': 4.780005164737953e-07, 'completion_length': 17.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.23}
 16%|█▌        | 321/2000 [1:37:53<3:50:06,  8.22s/it] 16%|█▌        | 322/2000 [1:38:05<4:17:45,  9.22s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.04549321055756083, 'learning_rate': 4.778341562424311e-07, 'completion_length': 20.104167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.23}
 16%|█▌        | 322/2000 [1:38:05<4:17:45,  9.22s/it] 16%|█▌        | 323/2000 [1:38:10<3:46:14,  8.09s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005569953021224199, 'learning_rate': 4.776671985425529e-07, 'completion_length': 10.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.23}
 16%|█▌        | 323/2000 [1:38:10<3:46:14,  8.09s/it] 16%|█▌        | 324/2000 [1:38:15<3:14:57,  6.98s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00283151846254743, 'learning_rate': 4.774996438119876e-07, 'completion_length': 9.083333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.23}
 16%|█▌        | 324/2000 [1:38:15<3:14:57,  6.98s/it] 16%|█▋        | 325/2000 [1:38:22<3:12:48,  6.91s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008906770446049872, 'learning_rate': 4.773314924901281e-07, 'completion_length': 14.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.23}
 16%|█▋        | 325/2000 [1:38:22<3:12:48,  6.91s/it] 16%|█▋        | 326/2000 [1:38:27<2:58:18,  6.39s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01204992411510536, 'learning_rate': 4.771627450179314e-07, 'completion_length': 10.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.23}
 16%|█▋        | 326/2000 [1:38:27<2:58:18,  6.39s/it] 16%|█▋        | 327/2000 [1:38:35<3:16:15,  7.04s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004722186813021165, 'learning_rate': 4.769934018379184e-07, 'completion_length': 17.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.23}
 16%|█▋        | 327/2000 [1:38:35<3:16:15,  7.04s/it] 16%|█▋        | 328/2000 [1:38:49<4:12:15,  9.05s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0018880324903054703, 'learning_rate': 4.7682346339417157e-07, 'completion_length': 22.291667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.23}
 16%|█▋        | 328/2000 [1:38:49<4:12:15,  9.05s/it] 16%|█▋        | 329/2000 [1:38:55<3:46:23,  8.13s/it]                                                      {'loss': 0.001, 'grad_norm': 0.04581874978442468, 'learning_rate': 4.766529301323348e-07, 'completion_length': 12.770833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.23}
 16%|█▋        | 329/2000 [1:38:55<3:46:23,  8.13s/it] 16%|█▋        | 330/2000 [1:38:59<3:14:36,  6.99s/it]                                                      {'loss': 0.001, 'grad_norm': 0.001886609228723948, 'learning_rate': 4.7648180249961165e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.23}
 16%|█▋        | 330/2000 [1:38:59<3:14:36,  6.99s/it] 17%|█▋        | 331/2000 [1:39:07<3:23:30,  7.32s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0027791609148798916, 'learning_rate': 4.763100809447645e-07, 'completion_length': 14.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.23}
 17%|█▋        | 331/2000 [1:39:07<3:23:30,  7.32s/it] 17%|█▋        | 332/2000 [1:39:13<3:13:01,  6.94s/it]                                                      {'loss': 0.001, 'grad_norm': 0.002642367027843681, 'learning_rate': 4.7613776591811295e-07, 'completion_length': 11.604166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.23}
 17%|█▋        | 332/2000 [1:39:13<3:13:01,  6.94s/it] 17%|█▋        | 333/2000 [1:39:20<3:08:52,  6.80s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008711850644014064, 'learning_rate': 4.759648578715332e-07, 'completion_length': 12.520833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.24}
 17%|█▋        | 333/2000 [1:39:20<3:08:52,  6.80s/it] 17%|█▋        | 334/2000 [1:39:27<3:09:01,  6.81s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0024657283049094292, 'learning_rate': 4.7579135725845633e-07, 'completion_length': 12.145833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.24}
 17%|█▋        | 334/2000 [1:39:27<3:09:01,  6.81s/it] 17%|█▋        | 335/2000 [1:39:44<4:32:02,  9.80s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.002512800404868774, 'learning_rate': 4.7561726453386744e-07, 'completion_length': 26.58333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.24}
 17%|█▋        | 335/2000 [1:39:44<4:32:02,  9.80s/it] 17%|█▋        | 336/2000 [1:39:52<4:17:52,  9.30s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0021990409792143934, 'learning_rate': 4.754425801543046e-07, 'completion_length': 14.416666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.93359375, 'epoch': 0.24}
 17%|█▋        | 336/2000 [1:39:52<4:17:52,  9.30s/it] 17%|█▋        | 337/2000 [1:40:06<5:00:11, 10.83s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006128679515782401, 'learning_rate': 4.7526730457785705e-07, 'completion_length': 35.270835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.24}
 17%|█▋        | 337/2000 [1:40:06<5:00:11, 10.83s/it] 17%|█▋        | 338/2000 [1:40:15<4:42:53, 10.21s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015486428794027684, 'learning_rate': 4.750914382641647e-07, 'completion_length': 24.52083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.828125, 'epoch': 0.24}
 17%|█▋        | 338/2000 [1:40:15<4:42:53, 10.21s/it] 17%|█▋        | 339/2000 [1:40:29<5:18:35, 11.51s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004655365926406249, 'learning_rate': 4.7491498167441634e-07, 'completion_length': 26.58333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.24}
 17%|█▋        | 339/2000 [1:40:29<5:18:35, 11.51s/it] 17%|█▋        | 340/2000 [1:40:37<4:43:10, 10.24s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009316481122125795, 'learning_rate': 4.747379352713488e-07, 'completion_length': 17.416667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.24}
 17%|█▋        | 340/2000 [1:40:37<4:43:10, 10.24s/it] 17%|█▋        | 341/2000 [1:40:56<5:55:01, 12.84s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.002588895673519827, 'learning_rate': 4.745602995192457e-07, 'completion_length': 38.708335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.90234375, 'epoch': 0.24}
 17%|█▋        | 341/2000 [1:40:56<5:55:01, 12.84s/it] 17%|█▋        | 342/2000 [1:41:10<6:05:47, 13.24s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01143654652176681, 'learning_rate': 4.743820748839361e-07, 'completion_length': 28.041667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.24}
 17%|█▋        | 342/2000 [1:41:10<6:05:47, 13.24s/it] 17%|█▋        | 343/2000 [1:41:18<5:22:12, 11.67s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0652136793378705, 'learning_rate': 4.7420326183279323e-07, 'completion_length': 19.95833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0546875, 'epoch': 0.24}
 17%|█▋        | 343/2000 [1:41:18<5:22:12, 11.67s/it] 17%|█▋        | 344/2000 [1:41:25<4:48:12, 10.44s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004255345337063286, 'learning_rate': 4.7402386083473364e-07, 'completion_length': 13.729166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.24}
 17%|█▋        | 344/2000 [1:41:25<4:48:12, 10.44s/it] 17%|█▋        | 345/2000 [1:41:32<4:16:41,  9.31s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008642250630827316, 'learning_rate': 4.738438723602154e-07, 'completion_length': 13.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.24}
 17%|█▋        | 345/2000 [1:41:32<4:16:41,  9.31s/it] 17%|█▋        | 346/2000 [1:41:42<4:25:28,  9.63s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006081910262843038, 'learning_rate': 4.736632968812373e-07, 'completion_length': 25.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9609375, 'epoch': 0.24}
 17%|█▋        | 346/2000 [1:41:42<4:25:28,  9.63s/it] 17%|█▋        | 347/2000 [1:41:57<5:06:48, 11.14s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010374276040578535, 'learning_rate': 4.734821348713375e-07, 'completion_length': 22.02083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.25}
 17%|█▋        | 347/2000 [1:41:57<5:06:48, 11.14s/it] 17%|█▋        | 348/2000 [1:42:11<5:31:23, 12.04s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009281629610980984, 'learning_rate': 4.7330038680559224e-07, 'completion_length': 32.520835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.25}
 17%|█▋        | 348/2000 [1:42:11<5:31:23, 12.04s/it] 17%|█▋        | 349/2000 [1:42:23<5:32:15, 12.07s/it]                                                      {'loss': 0.001, 'grad_norm': 0.011520506853851536, 'learning_rate': 4.7311805316061473e-07, 'completion_length': 25.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9765625, 'epoch': 0.25}
 17%|█▋        | 349/2000 [1:42:23<5:32:15, 12.07s/it] 18%|█▊        | 350/2000 [1:42:29<4:42:54, 10.29s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006662408727069845, 'learning_rate': 4.7293513441455357e-07, 'completion_length': 17.58333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94140625, 'epoch': 0.25}
 18%|█▊        | 350/2000 [1:42:29<4:42:54, 10.29s/it] 18%|█▊        | 351/2000 [1:42:40<4:47:28, 10.46s/it]                                                      {'loss': 0.001, 'grad_norm': 0.012451039972861878, 'learning_rate': 4.7275163104709194e-07, 'completion_length': 33.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.25}
 18%|█▊        | 351/2000 [1:42:40<4:47:28, 10.46s/it] 18%|█▊        | 352/2000 [1:42:48<4:22:17,  9.55s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00586554051798985, 'learning_rate': 4.72567543539446e-07, 'completion_length': 21.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.25}
 18%|█▊        | 352/2000 [1:42:48<4:22:17,  9.55s/it] 18%|█▊        | 353/2000 [1:42:54<3:59:10,  8.71s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008319827276397542, 'learning_rate': 4.723828723743638e-07, 'completion_length': 19.95833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.25}
 18%|█▊        | 353/2000 [1:42:54<3:59:10,  8.71s/it] 18%|█▊        | 354/2000 [1:43:02<3:47:10,  8.28s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006894217203140349, 'learning_rate': 4.721976180361238e-07, 'completion_length': 19.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.25}
 18%|█▊        | 354/2000 [1:43:02<3:47:10,  8.28s/it] 18%|█▊        | 355/2000 [1:43:09<3:35:05,  7.85s/it]                                                      {'loss': 0.001, 'grad_norm': 2.6605267584472228, 'learning_rate': 4.720117810105341e-07, 'completion_length': 20.64583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.984375, 'epoch': 0.25}
 18%|█▊        | 355/2000 [1:43:09<3:35:05,  7.85s/it] 18%|█▊        | 356/2000 [1:43:21<4:11:53,  9.19s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010517507240432525, 'learning_rate': 4.718253617849305e-07, 'completion_length': 37.10416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.25}
 18%|█▊        | 356/2000 [1:43:21<4:11:53,  9.19s/it] 18%|█▊        | 357/2000 [1:43:28<3:52:23,  8.49s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006614486681962529, 'learning_rate': 4.7163836084817585e-07, 'completion_length': 17.166667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.25}
 18%|█▊        | 357/2000 [1:43:28<3:52:23,  8.49s/it] 18%|█▊        | 358/2000 [1:43:44<4:59:15, 10.94s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01149136049263336, 'learning_rate': 4.714507786906581e-07, 'completion_length': 54.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.25}
 18%|█▊        | 358/2000 [1:43:44<4:59:15, 10.94s/it] 18%|█▊        | 359/2000 [1:43:55<4:54:24, 10.76s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010689201858882624, 'learning_rate': 4.712626158042897e-07, 'completion_length': 19.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.25}
 18%|█▊        | 359/2000 [1:43:55<4:54:24, 10.76s/it] 18%|█▊        | 360/2000 [1:44:02<4:27:29,  9.79s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0044735081585773615, 'learning_rate': 4.7107387268250586e-07, 'completion_length': 14.729166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.25}
 18%|█▊        | 360/2000 [1:44:02<4:27:29,  9.79s/it] 18%|█▊        | 361/2000 [1:44:09<4:01:04,  8.83s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0739603328993314, 'learning_rate': 4.708845498202635e-07, 'completion_length': 14.458333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.26}
 18%|█▊        | 361/2000 [1:44:09<4:01:04,  8.83s/it] 18%|█▊        | 362/2000 [1:44:23<4:47:29, 10.53s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006973528090802307, 'learning_rate': 4.7069464771403957e-07, 'completion_length': 36.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.26}
 18%|█▊        | 362/2000 [1:44:23<4:47:29, 10.53s/it] 18%|█▊        | 363/2000 [1:44:40<5:40:56, 12.50s/it]                                                      {'loss': 0.001, 'grad_norm': 0.040454881378697724, 'learning_rate': 4.7050416686183036e-07, 'completion_length': 51.770835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.26}
 18%|█▊        | 363/2000 [1:44:40<5:40:56, 12.50s/it] 18%|█▊        | 364/2000 [1:44:47<4:55:37, 10.84s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007355522158810674, 'learning_rate': 4.703131077631497e-07, 'completion_length': 17.166667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.26}
 18%|█▊        | 364/2000 [1:44:47<4:55:37, 10.84s/it] 18%|█▊        | 365/2000 [1:44:54<4:19:12,  9.51s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004716578621985021, 'learning_rate': 4.7012147091902764e-07, 'completion_length': 12.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.953125, 'epoch': 0.26}
 18%|█▊        | 365/2000 [1:44:54<4:19:12,  9.51s/it] 18%|█▊        | 366/2000 [1:45:02<4:12:06,  9.26s/it]                                                      {'loss': 0.001, 'grad_norm': 0.021925579379219247, 'learning_rate': 4.699292568320097e-07, 'completion_length': 20.729167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.26}
 18%|█▊        | 366/2000 [1:45:02<4:12:06,  9.26s/it] 18%|█▊        | 367/2000 [1:45:09<3:51:03,  8.49s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007909907611711677, 'learning_rate': 4.6973646600615477e-07, 'completion_length': 17.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.26}
 18%|█▊        | 367/2000 [1:45:09<3:51:03,  8.49s/it] 18%|█▊        | 368/2000 [1:45:17<3:43:21,  8.21s/it]                                                      {'loss': 0.001, 'grad_norm': 0.003049643959021114, 'learning_rate': 4.6954309894703426e-07, 'completion_length': 13.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.26}
 18%|█▊        | 368/2000 [1:45:17<3:43:21,  8.21s/it] 18%|█▊        | 369/2000 [1:45:27<3:58:37,  8.78s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.004731814271644928, 'learning_rate': 4.693491561617309e-07, 'completion_length': 17.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.26}
 18%|█▊        | 369/2000 [1:45:27<3:58:37,  8.78s/it] 18%|█▊        | 370/2000 [1:45:42<4:53:46, 10.81s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004282955498270503, 'learning_rate': 4.691546381588369e-07, 'completion_length': 45.72916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9765625, 'epoch': 0.26}
 18%|█▊        | 370/2000 [1:45:42<4:53:46, 10.81s/it] 19%|█▊        | 371/2000 [1:45:51<4:33:09, 10.06s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00862835189347978, 'learning_rate': 4.689595454484531e-07, 'completion_length': 17.14583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.26}
 19%|█▊        | 371/2000 [1:45:51<4:33:09, 10.06s/it] 19%|█▊        | 372/2000 [1:45:58<4:11:13,  9.26s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008992281637885593, 'learning_rate': 4.6876387854218744e-07, 'completion_length': 16.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.26}
 19%|█▊        | 372/2000 [1:45:58<4:11:13,  9.26s/it] 19%|█▊        | 373/2000 [1:46:05<3:49:34,  8.47s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0070146961801335235, 'learning_rate': 4.6856763795315344e-07, 'completion_length': 13.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.26}
 19%|█▊        | 373/2000 [1:46:05<3:49:34,  8.47s/it] 19%|█▊        | 374/2000 [1:46:17<4:21:07,  9.64s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005166312185925173, 'learning_rate': 4.6837082419596936e-07, 'completion_length': 21.979167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.26}
 19%|█▊        | 374/2000 [1:46:17<4:21:07,  9.64s/it] 19%|█▉        | 375/2000 [1:46:24<3:57:49,  8.78s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009095745414604362, 'learning_rate': 4.681734377867561e-07, 'completion_length': 20.58333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9609375, 'epoch': 0.27}
 19%|█▉        | 375/2000 [1:46:24<3:57:49,  8.78s/it] 19%|█▉        | 376/2000 [1:46:39<4:50:00, 10.71s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006296322453817518, 'learning_rate': 4.6797547924313673e-07, 'completion_length': 43.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.27}
 19%|█▉        | 376/2000 [1:46:39<4:50:00, 10.71s/it] 19%|█▉        | 377/2000 [1:46:44<4:02:01,  8.95s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007852626603741517, 'learning_rate': 4.677769490842343e-07, 'completion_length': 9.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.27}
 19%|█▉        | 377/2000 [1:46:44<4:02:01,  8.95s/it] 19%|█▉        | 378/2000 [1:46:51<3:48:52,  8.47s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0066365982100174935, 'learning_rate': 4.675778478306711e-07, 'completion_length': 17.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.27}
 19%|█▉        | 378/2000 [1:46:51<3:48:52,  8.47s/it] 19%|█▉        | 379/2000 [1:46:56<3:20:21,  7.42s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006193121698364285, 'learning_rate': 4.673781760045669e-07, 'completion_length': 10.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0390625, 'epoch': 0.27}
 19%|█▉        | 379/2000 [1:46:56<3:20:21,  7.42s/it] 19%|█▉        | 380/2000 [1:47:03<3:13:17,  7.16s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0035373870651719745, 'learning_rate': 4.6717793412953776e-07, 'completion_length': 14.208333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.27}
 19%|█▉        | 380/2000 [1:47:03<3:13:17,  7.16s/it] 19%|█▉        | 381/2000 [1:47:17<4:10:58,  9.30s/it]                                                      {'loss': 0.001, 'grad_norm': 0.003927105071850676, 'learning_rate': 4.6697712273069467e-07, 'completion_length': 25.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.27}
 19%|█▉        | 381/2000 [1:47:17<4:10:58,  9.30s/it] 19%|█▉        | 382/2000 [1:47:23<3:44:04,  8.31s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00626542081700476, 'learning_rate': 4.6677574233464224e-07, 'completion_length': 13.270833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.27}
 19%|█▉        | 382/2000 [1:47:23<3:44:04,  8.31s/it] 19%|█▉        | 383/2000 [1:47:30<3:35:01,  7.98s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005698649167129906, 'learning_rate': 4.665737934694769e-07, 'completion_length': 15.729166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.27}
 19%|█▉        | 383/2000 [1:47:30<3:35:01,  7.98s/it] 19%|█▉        | 384/2000 [1:47:47<4:42:58, 10.51s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0096274354715036, 'learning_rate': 4.6637127666478617e-07, 'completion_length': 45.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.27}
 19%|█▉        | 384/2000 [1:47:47<4:42:58, 10.51s/it] 19%|█▉        | 385/2000 [1:47:59<4:57:11, 11.04s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004404340131297705, 'learning_rate': 4.6616819245164655e-07, 'completion_length': 28.02083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.27}
 19%|█▉        | 385/2000 [1:47:59<4:57:11, 11.04s/it] 19%|█▉        | 386/2000 [1:48:14<5:30:06, 12.27s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01223644407578149, 'learning_rate': 4.6596454136262294e-07, 'completion_length': 48.395835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.27}
 19%|█▉        | 386/2000 [1:48:14<5:30:06, 12.27s/it] 19%|█▉        | 387/2000 [1:48:29<5:47:11, 12.91s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007916839627909232, 'learning_rate': 4.6576032393176643e-07, 'completion_length': 27.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.27}
 19%|█▉        | 387/2000 [1:48:29<5:47:11, 12.91s/it] 19%|█▉        | 388/2000 [1:48:38<5:16:35, 11.78s/it]                                                      {'loss': 0.001, 'grad_norm': 4.1962191074940645, 'learning_rate': 4.6555554069461346e-07, 'completion_length': 27.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.99609375, 'epoch': 0.27}
 19%|█▉        | 388/2000 [1:48:38<5:16:35, 11.78s/it] 19%|█▉        | 389/2000 [1:48:45<4:38:46, 10.38s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.009286344596741778, 'learning_rate': 4.653501921881843e-07, 'completion_length': 23.166667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.92578125, 'epoch': 0.28}
 19%|█▉        | 389/2000 [1:48:45<4:38:46, 10.38s/it] 20%|█▉        | 390/2000 [1:48:58<5:00:39, 11.20s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010630339635762579, 'learning_rate': 4.651442789509813e-07, 'completion_length': 28.52083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.28}
 20%|█▉        | 390/2000 [1:48:58<5:00:39, 11.20s/it] 20%|█▉        | 391/2000 [1:49:03<4:14:41,  9.50s/it]                                                      {'loss': 0.001, 'grad_norm': 0.004389089042905911, 'learning_rate': 4.64937801522988e-07, 'completion_length': 10.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.28}
 20%|█▉        | 391/2000 [1:49:03<4:14:41,  9.50s/it] 20%|█▉        | 392/2000 [1:49:10<3:54:36,  8.75s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005057031631269015, 'learning_rate': 4.647307604456674e-07, 'completion_length': 16.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.28}
 20%|█▉        | 392/2000 [1:49:10<3:54:36,  8.75s/it] 20%|█▉        | 393/2000 [1:49:23<4:23:18,  9.83s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005230555509059367, 'learning_rate': 4.645231562619606e-07, 'completion_length': 32.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.28}
 20%|█▉        | 393/2000 [1:49:23<4:23:18,  9.83s/it] 20%|█▉        | 394/2000 [1:49:38<5:02:50, 11.31s/it]                                                      {'loss': 0.0009, 'grad_norm': 3.344681132544836, 'learning_rate': 4.643149895162853e-07, 'completion_length': 41.29166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.91796875, 'epoch': 0.28}
 20%|█▉        | 394/2000 [1:49:38<5:02:50, 11.31s/it] 20%|█▉        | 395/2000 [1:49:52<5:26:08, 12.19s/it]                                                      {'loss': 0.001, 'grad_norm': 0.003687738670173406, 'learning_rate': 4.6410626075453465e-07, 'completion_length': 23.33333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.28}
 20%|█▉        | 395/2000 [1:49:52<5:26:08, 12.19s/it] 20%|█▉        | 396/2000 [1:50:02<5:11:26, 11.65s/it]                                                      {'loss': 0.0018, 'grad_norm': 31.116849408414065, 'learning_rate': 4.6389697052407526e-07, 'completion_length': 24.416667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.875, 'reward': 1.875, 'reward_std': 0.07715167850255966, 'kl': 1.8203125, 'epoch': 0.28}
 20%|█▉        | 396/2000 [1:50:02<5:11:26, 11.65s/it] 20%|█▉        | 397/2000 [1:50:09<4:32:23, 10.20s/it]                                                      {'loss': 0.001, 'grad_norm': 0.03395096948910106, 'learning_rate': 4.636871193737466e-07, 'completion_length': 13.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.28}
 20%|█▉        | 397/2000 [1:50:09<4:32:23, 10.20s/it] 20%|█▉        | 398/2000 [1:50:24<5:12:35, 11.71s/it]                                                      {'loss': 0.001, 'grad_norm': 0.019114013317402024, 'learning_rate': 4.634767078538588e-07, 'completion_length': 44.208335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.28}
 20%|█▉        | 398/2000 [1:50:24<5:12:35, 11.71s/it] 20%|█▉        | 399/2000 [1:50:32<4:38:12, 10.43s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00690499184554987, 'learning_rate': 4.632657365161914e-07, 'completion_length': 13.458333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.28}
 20%|█▉        | 399/2000 [1:50:32<4:38:12, 10.43s/it] 20%|██        | 400/2000 [1:50:38<4:03:46,  9.14s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006153626768774669, 'learning_rate': 4.630542059139923e-07, 'completion_length': 13.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9140625, 'epoch': 0.28}
 20%|██        | 400/2000 [1:50:38<4:03:46,  9.14s/it] 20%|██        | 401/2000 [1:50:45<3:44:56,  8.44s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006426432608250479, 'learning_rate': 4.628421166019758e-07, 'completion_length': 17.89583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.28}
 20%|██        | 401/2000 [1:50:45<3:44:56,  8.44s/it] 20%|██        | 402/2000 [1:50:51<3:28:41,  7.84s/it]                                                      {'loss': 0.001, 'grad_norm': 0.013431027411922748, 'learning_rate': 4.6262946913632126e-07, 'completion_length': 17.979167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.97265625, 'epoch': 0.28}
 20%|██        | 402/2000 [1:50:51<3:28:41,  7.84s/it] 20%|██        | 403/2000 [1:51:07<4:32:57, 10.25s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010159060171377075, 'learning_rate': 4.624162640746721e-07, 'completion_length': 32.833335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.29}
 20%|██        | 403/2000 [1:51:07<4:32:57, 10.25s/it] 20%|██        | 404/2000 [1:51:11<3:45:24,  8.47s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0029997693617524954, 'learning_rate': 4.622025019761336e-07, 'completion_length': 9.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.29}
 20%|██        | 404/2000 [1:51:11<3:45:24,  8.47s/it] 20%|██        | 405/2000 [1:51:26<4:34:09, 10.31s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01061477649725415, 'learning_rate': 4.6198818340127196e-07, 'completion_length': 29.83333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.29}
 20%|██        | 405/2000 [1:51:26<4:34:09, 10.31s/it] 20%|██        | 406/2000 [1:51:37<4:36:39, 10.41s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008204689484283597, 'learning_rate': 4.6177330891211263e-07, 'completion_length': 24.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0234375, 'epoch': 0.29}
 20%|██        | 406/2000 [1:51:37<4:36:39, 10.41s/it] 20%|██        | 407/2000 [1:51:44<4:09:56,  9.41s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005941034255753946, 'learning_rate': 4.61557879072139e-07, 'completion_length': 15.833333969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.29}
 20%|██        | 407/2000 [1:51:44<4:09:56,  9.41s/it] 20%|██        | 408/2000 [1:51:54<4:17:38,  9.71s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010137018362204792, 'learning_rate': 4.613418944462906e-07, 'completion_length': 27.854167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.29}
 20%|██        | 408/2000 [1:51:54<4:17:38,  9.71s/it] 20%|██        | 409/2000 [1:52:04<4:23:25,  9.93s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006344473643526615, 'learning_rate': 4.6112535560096203e-07, 'completion_length': 21.77083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.29}
 20%|██        | 409/2000 [1:52:04<4:23:25,  9.93s/it] 20%|██        | 410/2000 [1:52:18<4:51:24, 11.00s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01026230773768954, 'learning_rate': 4.609082631040011e-07, 'completion_length': 34.145835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.29}
 20%|██        | 410/2000 [1:52:18<4:51:24, 11.00s/it] 21%|██        | 411/2000 [1:52:35<5:38:02, 12.76s/it]                                                      {'loss': 0.001, 'grad_norm': 0.021097318018584554, 'learning_rate': 4.6069061752470763e-07, 'completion_length': 31.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.29}
 21%|██        | 411/2000 [1:52:35<5:38:02, 12.76s/it] 21%|██        | 412/2000 [1:52:51<6:05:21, 13.80s/it]                                                      {'loss': 0.001, 'grad_norm': 0.014354565313410672, 'learning_rate': 4.6047241943383173e-07, 'completion_length': 28.229167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.29}
 21%|██        | 412/2000 [1:52:51<6:05:21, 13.80s/it] 21%|██        | 413/2000 [1:53:02<5:43:00, 12.97s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009320609988292605, 'learning_rate': 4.602536694035725e-07, 'completion_length': 25.791667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.29}
 21%|██        | 413/2000 [1:53:02<5:43:00, 12.97s/it] 21%|██        | 414/2000 [1:53:16<5:46:34, 13.11s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.00672301798995868, 'learning_rate': 4.600343680075763e-07, 'completion_length': 34.770835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.29}
 21%|██        | 414/2000 [1:53:16<5:46:34, 13.11s/it] 21%|██        | 415/2000 [1:53:22<4:54:44, 11.16s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009993085851111649, 'learning_rate': 4.5981451582093555e-07, 'completion_length': 16.39583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.29}
 21%|██        | 415/2000 [1:53:22<4:54:44, 11.16s/it] 21%|██        | 416/2000 [1:53:37<5:26:00, 12.35s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0042277465120731696, 'learning_rate': 4.5959411342018704e-07, 'completion_length': 34.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.29}
 21%|██        | 416/2000 [1:53:37<5:26:00, 12.35s/it] 21%|██        | 417/2000 [1:53:42<4:29:24, 10.21s/it]                                                      {'loss': 0.001, 'grad_norm': 0.05209859482311091, 'learning_rate': 4.5937316138331025e-07, 'completion_length': 10.291666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.3}
 21%|██        | 417/2000 [1:53:42<4:29:24, 10.21s/it] 21%|██        | 418/2000 [1:53:55<4:49:15, 10.97s/it]                                                      {'loss': 0.001, 'grad_norm': 0.020344871357716617, 'learning_rate': 4.591516602897262e-07, 'completion_length': 30.604167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.3}
 21%|██        | 418/2000 [1:53:55<4:49:15, 10.97s/it] 21%|██        | 419/2000 [1:54:10<5:15:24, 11.97s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008221361616228747, 'learning_rate': 4.589296107202957e-07, 'completion_length': 31.83333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.3}
 21%|██        | 419/2000 [1:54:10<5:15:24, 11.97s/it] 21%|██        | 420/2000 [1:54:25<5:39:45, 12.90s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006943590400508002, 'learning_rate': 4.5870701325731773e-07, 'completion_length': 38.270835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.3}
 21%|██        | 420/2000 [1:54:25<5:39:45, 12.90s/it] 21%|██        | 421/2000 [1:54:42<6:13:25, 14.19s/it]                                                      {'loss': 0.001, 'grad_norm': 0.013818431410237399, 'learning_rate': 4.5848386848452843e-07, 'completion_length': 33.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.3}
 21%|██        | 421/2000 [1:54:42<6:13:25, 14.19s/it] 21%|██        | 422/2000 [1:54:48<5:13:48, 11.93s/it]                                                      {'loss': 0.001, 'grad_norm': 0.00557140653544118, 'learning_rate': 4.582601769870987e-07, 'completion_length': 15.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.3}
 21%|██        | 422/2000 [1:54:48<5:13:48, 11.93s/it] 21%|██        | 423/2000 [1:54:59<5:00:27, 11.43s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007415075579050122, 'learning_rate': 4.5803593935163363e-07, 'completion_length': 25.20833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.97265625, 'epoch': 0.3}
 21%|██        | 423/2000 [1:54:59<5:00:27, 11.43s/it] 21%|██        | 424/2000 [1:55:15<5:37:35, 12.85s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005284831362832795, 'learning_rate': 4.578111561661702e-07, 'completion_length': 64.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.3}
 21%|██        | 424/2000 [1:55:15<5:37:35, 12.85s/it] 21%|██▏       | 425/2000 [1:55:30<5:52:45, 13.44s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0053079022637001205, 'learning_rate': 4.5758582802017597e-07, 'completion_length': 38.91666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.875, 'epoch': 0.3}
 21%|██▏       | 425/2000 [1:55:30<5:52:45, 13.44s/it] 21%|██▏       | 426/2000 [1:55:39<5:19:21, 12.17s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009498849453495092, 'learning_rate': 4.573599555045479e-07, 'completion_length': 17.64583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.3}
 21%|██▏       | 426/2000 [1:55:39<5:19:21, 12.17s/it] 21%|██▏       | 427/2000 [1:56:01<6:40:18, 15.27s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01951834354910361, 'learning_rate': 4.571335392116103e-07, 'completion_length': 38.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.3}
 21%|██▏       | 427/2000 [1:56:01<6:40:18, 15.27s/it] 21%|██▏       | 428/2000 [1:56:18<6:47:01, 15.54s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006652380763398933, 'learning_rate': 4.569065797351135e-07, 'completion_length': 39.41666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.3}
 21%|██▏       | 428/2000 [1:56:18<6:47:01, 15.54s/it] 21%|██▏       | 429/2000 [1:56:24<5:35:48, 12.82s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.019121195850516796, 'learning_rate': 4.5667907767023215e-07, 'completion_length': 17.791667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.3}
 21%|██▏       | 429/2000 [1:56:24<5:35:48, 12.82s/it] 22%|██▏       | 430/2000 [1:56:40<6:00:10, 13.76s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.013077342914875445, 'learning_rate': 4.5645103361356407e-07, 'completion_length': 47.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.3}
 22%|██▏       | 430/2000 [1:56:40<6:00:10, 13.76s/it] 22%|██▏       | 431/2000 [1:56:56<6:17:01, 14.42s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005716538430058254, 'learning_rate': 4.5622244816312815e-07, 'completion_length': 49.16666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.31}
 22%|██▏       | 431/2000 [1:56:56<6:17:01, 14.42s/it] 22%|██▏       | 432/2000 [1:57:09<6:06:41, 14.03s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01766020195082753, 'learning_rate': 4.559933219183631e-07, 'completion_length': 40.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.31}
 22%|██▏       | 432/2000 [1:57:09<6:06:41, 14.03s/it] 22%|██▏       | 433/2000 [1:57:24<6:14:31, 14.34s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.05963727330907167, 'learning_rate': 4.557636554801257e-07, 'completion_length': 48.22916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.93359375, 'epoch': 0.31}
 22%|██▏       | 433/2000 [1:57:24<6:14:31, 14.34s/it] 22%|██▏       | 434/2000 [1:57:32<5:21:24, 12.31s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.00929169321324957, 'learning_rate': 4.555334494506895e-07, 'completion_length': 18.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.31}
 22%|██▏       | 434/2000 [1:57:32<5:21:24, 12.31s/it] 22%|██▏       | 435/2000 [1:57:40<4:47:19, 11.02s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007320486990519916, 'learning_rate': 4.55302704433743e-07, 'completion_length': 15.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.31}
 22%|██▏       | 435/2000 [1:57:40<4:47:19, 11.02s/it] 22%|██▏       | 436/2000 [1:57:53<5:01:11, 11.55s/it]                                                      {'loss': 0.001, 'grad_norm': 1.3817887982020542, 'learning_rate': 4.550714210343879e-07, 'completion_length': 30.95833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 1.0234375, 'epoch': 0.31}
 22%|██▏       | 436/2000 [1:57:53<5:01:11, 11.55s/it] 22%|██▏       | 437/2000 [1:58:04<4:59:49, 11.51s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015644559081799597, 'learning_rate': 4.548395998591382e-07, 'completion_length': 50.208335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.31}
 22%|██▏       | 437/2000 [1:58:04<4:59:49, 11.51s/it] 22%|██▏       | 438/2000 [1:58:10<4:14:08,  9.76s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.0757735457497979, 'learning_rate': 4.5460724151591783e-07, 'completion_length': 11.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.078125, 'epoch': 0.31}
 22%|██▏       | 438/2000 [1:58:10<4:14:08,  9.76s/it] 22%|██▏       | 439/2000 [1:58:16<3:50:01,  8.84s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02517132306058076, 'learning_rate': 4.5437434661405945e-07, 'completion_length': 18.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8828125, 'epoch': 0.31}
 22%|██▏       | 439/2000 [1:58:16<3:50:01,  8.84s/it] 22%|██▏       | 440/2000 [1:58:29<4:15:58,  9.85s/it]                                                      {'loss': 0.001, 'grad_norm': 0.005366726733101523, 'learning_rate': 4.541409157643027e-07, 'completion_length': 26.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.31}
 22%|██▏       | 440/2000 [1:58:29<4:15:58,  9.85s/it] 22%|██▏       | 441/2000 [1:58:41<4:36:53, 10.66s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012260166218920584, 'learning_rate': 4.5390694957879293e-07, 'completion_length': 33.895835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.31}
 22%|██▏       | 441/2000 [1:58:41<4:36:53, 10.66s/it] 22%|██▏       | 442/2000 [1:58:47<3:59:58,  9.24s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009913497119656087, 'learning_rate': 4.53672448671079e-07, 'completion_length': 12.791666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.31}
 22%|██▏       | 442/2000 [1:58:47<3:59:58,  9.24s/it] 22%|██▏       | 443/2000 [1:59:03<4:50:14, 11.18s/it]                                                      {'loss': 0.0026, 'grad_norm': 2.553828693483017, 'learning_rate': 4.534374136561124e-07, 'completion_length': 30.729167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 2.609375, 'epoch': 0.31}
 22%|██▏       | 443/2000 [1:59:03<4:50:14, 11.18s/it] 22%|██▏       | 444/2000 [1:59:09<4:13:54,  9.79s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006508616776988209, 'learning_rate': 4.5320184515024493e-07, 'completion_length': 12.229166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.31}
 22%|██▏       | 444/2000 [1:59:09<4:13:54,  9.79s/it] 22%|██▏       | 445/2000 [1:59:15<3:39:31,  8.47s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006161555143890202, 'learning_rate': 4.529657437712276e-07, 'completion_length': 10.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.31}
 22%|██▏       | 445/2000 [1:59:15<3:39:31,  8.47s/it] 22%|██▏       | 446/2000 [1:59:34<5:00:16, 11.59s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006181103056262084, 'learning_rate': 4.527291101382087e-07, 'completion_length': 40.895835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9140625, 'epoch': 0.32}
 22%|██▏       | 446/2000 [1:59:34<5:00:16, 11.59s/it] 22%|██▏       | 447/2000 [1:59:40<4:18:26,  9.98s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01043648688601974, 'learning_rate': 4.524919448717324e-07, 'completion_length': 13.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.03125, 'epoch': 0.32}
 22%|██▏       | 447/2000 [1:59:40<4:18:26,  9.98s/it] 22%|██▏       | 448/2000 [1:59:53<4:41:33, 10.88s/it]                                                      {'loss': 0.001, 'grad_norm': 0.017500710162041216, 'learning_rate': 4.5225424859373684e-07, 'completion_length': 26.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.32}
 22%|██▏       | 448/2000 [1:59:53<4:41:33, 10.88s/it] 22%|██▏       | 449/2000 [2:00:05<4:48:19, 11.15s/it]                                                      {'loss': 0.001, 'grad_norm': 0.04339882427824794, 'learning_rate': 4.5201602192755297e-07, 'completion_length': 22.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.32}
 22%|██▏       | 449/2000 [2:00:05<4:48:19, 11.15s/it] 22%|██▎       | 450/2000 [2:00:20<5:21:28, 12.44s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.027760738593410054, 'learning_rate': 4.517772654979023e-07, 'completion_length': 61.35416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.32}
 22%|██▎       | 450/2000 [2:00:20<5:21:28, 12.44s/it] 23%|██▎       | 451/2000 [2:00:31<5:09:19, 11.98s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0789430465642285, 'learning_rate': 4.5153797993089583e-07, 'completion_length': 25.52083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.32}
 23%|██▎       | 451/2000 [2:00:31<5:09:19, 11.98s/it] 23%|██▎       | 452/2000 [2:00:44<5:17:02, 12.29s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.03417520095790173, 'learning_rate': 4.51298165854032e-07, 'completion_length': 45.16666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91796875, 'epoch': 0.32}
 23%|██▎       | 452/2000 [2:00:44<5:17:02, 12.29s/it] 23%|██▎       | 453/2000 [2:00:58<5:28:30, 12.74s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.03206771064676713, 'learning_rate': 4.510578238961954e-07, 'completion_length': 29.854167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.83984375, 'epoch': 0.32}
 23%|██▎       | 453/2000 [2:00:58<5:28:30, 12.74s/it] 23%|██▎       | 454/2000 [2:01:15<6:03:10, 14.10s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.03618372391847795, 'learning_rate': 4.508169546876546e-07, 'completion_length': 71.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.32}
 23%|██▎       | 454/2000 [2:01:15<6:03:10, 14.10s/it] 23%|██▎       | 455/2000 [2:01:31<6:19:25, 14.74s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.03842999079487287, 'learning_rate': 4.505755588600612e-07, 'completion_length': 66.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8515625, 'epoch': 0.32}
 23%|██▎       | 455/2000 [2:01:31<6:19:25, 14.74s/it] 23%|██▎       | 456/2000 [2:01:46<6:19:52, 14.76s/it]                                                      {'loss': 0.0007, 'grad_norm': 2.4527570350848786, 'learning_rate': 4.503336370464475e-07, 'completion_length': 98.97917175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.7421875, 'epoch': 0.32}
 23%|██▎       | 456/2000 [2:01:46<6:19:52, 14.76s/it] 23%|██▎       | 457/2000 [2:02:02<6:30:10, 15.17s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.03815866019252885, 'learning_rate': 4.500911898812253e-07, 'completion_length': 82.85417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8359375, 'epoch': 0.32}
 23%|██▎       | 457/2000 [2:02:02<6:30:10, 15.17s/it] 23%|██▎       | 458/2000 [2:02:21<6:58:30, 16.28s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.03417121481567591, 'learning_rate': 4.49848218000184e-07, 'completion_length': 45.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.32}
 23%|██▎       | 458/2000 [2:02:21<6:58:30, 16.28s/it] 23%|██▎       | 459/2000 [2:02:32<6:16:31, 14.66s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.024781575446039976, 'learning_rate': 4.4960472204048905e-07, 'completion_length': 19.604167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.32}
 23%|██▎       | 459/2000 [2:02:32<6:16:31, 14.66s/it] 23%|██▎       | 460/2000 [2:02:49<6:36:57, 15.47s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0379565359451052, 'learning_rate': 4.4936070264068016e-07, 'completion_length': 73.08333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8984375, 'epoch': 0.33}
 23%|██▎       | 460/2000 [2:02:49<6:36:57, 15.47s/it] 23%|██▎       | 461/2000 [2:03:12<7:29:24, 17.52s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02229203053057677, 'learning_rate': 4.4911616044066993e-07, 'completion_length': 84.95833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.33}
 23%|██▎       | 461/2000 [2:03:12<7:29:24, 17.52s/it] 23%|██▎       | 462/2000 [2:03:28<7:17:34, 17.07s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02026181206133396, 'learning_rate': 4.4887109608174157e-07, 'completion_length': 62.35416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8984375, 'epoch': 0.33}
 23%|██▎       | 462/2000 [2:03:28<7:17:34, 17.07s/it] 23%|██▎       | 463/2000 [2:03:48<7:42:50, 18.07s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02021958138312835, 'learning_rate': 4.4862551020654785e-07, 'completion_length': 46.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8828125, 'epoch': 0.33}
 23%|██▎       | 463/2000 [2:03:48<7:42:50, 18.07s/it] 23%|██▎       | 464/2000 [2:04:07<7:52:35, 18.46s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.027002699971676307, 'learning_rate': 4.4837940345910917e-07, 'completion_length': 87.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.33}
 23%|██▎       | 464/2000 [2:04:07<7:52:35, 18.46s/it] 23%|██▎       | 465/2000 [2:04:26<7:52:56, 18.49s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.02328585333550066, 'learning_rate': 4.4813277648481174e-07, 'completion_length': 65.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.81640625, 'epoch': 0.33}
 23%|██▎       | 465/2000 [2:04:26<7:52:56, 18.49s/it] 23%|██▎       | 466/2000 [2:04:39<7:14:33, 17.00s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02230384896266767, 'learning_rate': 4.478856299304061e-07, 'completion_length': 33.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.93359375, 'epoch': 0.33}
 23%|██▎       | 466/2000 [2:04:39<7:14:33, 17.00s/it] 23%|██▎       | 467/2000 [2:04:56<7:09:52, 16.82s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.0312298424000365, 'learning_rate': 4.4763796444400517e-07, 'completion_length': 79.89583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8046875, 'epoch': 0.33}
 23%|██▎       | 467/2000 [2:04:56<7:09:52, 16.82s/it] 23%|██▎       | 468/2000 [2:05:16<7:33:28, 17.76s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.044893518764299215, 'learning_rate': 4.473897806750828e-07, 'completion_length': 60.395835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8359375, 'epoch': 0.33}
 23%|██▎       | 468/2000 [2:05:16<7:33:28, 17.76s/it] 23%|██▎       | 469/2000 [2:05:34<7:36:49, 17.90s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.019007810410914146, 'learning_rate': 4.471410792744722e-07, 'completion_length': 103.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.72265625, 'epoch': 0.33}
 23%|██▎       | 469/2000 [2:05:34<7:36:49, 17.90s/it] 24%|██▎       | 470/2000 [2:05:50<7:25:24, 17.47s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01599324294354931, 'learning_rate': 4.468918608943636e-07, 'completion_length': 60.708335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.79296875, 'epoch': 0.33}
 24%|██▎       | 470/2000 [2:05:50<7:25:24, 17.47s/it] 24%|██▎       | 471/2000 [2:06:09<7:35:00, 17.86s/it]                                                      {'loss': 0.0008, 'grad_norm': 1.6967437629013828, 'learning_rate': 4.466421261883032e-07, 'completion_length': 108.79167175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.7578125, 'epoch': 0.33}
 24%|██▎       | 471/2000 [2:06:09<7:35:00, 17.86s/it] 24%|██▎       | 472/2000 [2:06:24<7:08:17, 16.82s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.019807025853132078, 'learning_rate': 4.4639187581119116e-07, 'completion_length': 43.41666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8515625, 'epoch': 0.33}
 24%|██▎       | 472/2000 [2:06:24<7:08:17, 16.82s/it] 24%|██▎       | 473/2000 [2:06:39<6:56:09, 16.35s/it]                                                      {'loss': 0.0009, 'grad_norm': 9.57105414723768, 'learning_rate': 4.4614111041927993e-07, 'completion_length': 64.91667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.8828125, 'epoch': 0.33}
 24%|██▎       | 473/2000 [2:06:39<6:56:09, 16.35s/it] 24%|██▎       | 474/2000 [2:06:55<6:50:33, 16.14s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0416613424971715, 'learning_rate': 4.458898306701725e-07, 'completion_length': 50.29166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.34}
 24%|██▎       | 474/2000 [2:06:55<6:50:33, 16.14s/it] 24%|██▍       | 475/2000 [2:07:09<6:38:46, 15.69s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015709623911269274, 'learning_rate': 4.4563803722282074e-07, 'completion_length': 37.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.34}
 24%|██▍       | 475/2000 [2:07:09<6:38:46, 15.69s/it] 24%|██▍       | 476/2000 [2:07:26<6:45:12, 15.95s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.016791229130522525, 'learning_rate': 4.453857307375236e-07, 'completion_length': 34.22916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.34}
 24%|██▍       | 476/2000 [2:07:26<6:45:12, 15.95s/it] 24%|██▍       | 477/2000 [2:07:40<6:32:31, 15.46s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.011499183056822376, 'learning_rate': 4.451329118759254e-07, 'completion_length': 36.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90234375, 'epoch': 0.34}
 24%|██▍       | 477/2000 [2:07:40<6:32:31, 15.46s/it] 24%|██▍       | 478/2000 [2:07:53<6:15:21, 14.80s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.018923403801687746, 'learning_rate': 4.448795813010142e-07, 'completion_length': 27.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9140625, 'epoch': 0.34}
 24%|██▍       | 478/2000 [2:07:53<6:15:21, 14.80s/it] 24%|██▍       | 479/2000 [2:08:04<5:47:02, 13.69s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.026043466188190766, 'learning_rate': 4.446257396771198e-07, 'completion_length': 32.395835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.82421875, 'epoch': 0.34}
 24%|██▍       | 479/2000 [2:08:04<5:47:02, 13.69s/it] 24%|██▍       | 480/2000 [2:08:17<5:39:16, 13.39s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01374432398783163, 'learning_rate': 4.443713876699123e-07, 'completion_length': 36.395835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.34}
 24%|██▍       | 480/2000 [2:08:17<5:39:16, 13.39s/it] 24%|██▍       | 481/2000 [2:08:34<6:04:51, 14.41s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01175203026281911, 'learning_rate': 4.4411652594640026e-07, 'completion_length': 31.08333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9765625, 'epoch': 0.34}
 24%|██▍       | 481/2000 [2:08:34<6:04:51, 14.41s/it] 24%|██▍       | 482/2000 [2:08:46<5:44:45, 13.63s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010701040485033566, 'learning_rate': 4.4386115517492873e-07, 'completion_length': 42.458335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.34}
 24%|██▍       | 482/2000 [2:08:46<5:44:45, 13.63s/it] 24%|██▍       | 483/2000 [2:09:02<6:05:08, 14.44s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0127894392060772, 'learning_rate': 4.4360527602517795e-07, 'completion_length': 48.770835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.34}
 24%|██▍       | 483/2000 [2:09:02<6:05:08, 14.44s/it] 24%|██▍       | 484/2000 [2:09:21<6:38:16, 15.76s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.013553423705368235, 'learning_rate': 4.433488891681609e-07, 'completion_length': 76.20833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.34}
 24%|██▍       | 484/2000 [2:09:21<6:38:16, 15.76s/it] 24%|██▍       | 485/2000 [2:09:35<6:27:04, 15.33s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010285706716563672, 'learning_rate': 4.4309199527622254e-07, 'completion_length': 39.333335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.34}
 24%|██▍       | 485/2000 [2:09:35<6:27:04, 15.33s/it] 24%|██▍       | 486/2000 [2:09:41<5:17:24, 12.58s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0522224863855464, 'learning_rate': 4.428345950230369e-07, 'completion_length': 19.541667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.34}
 24%|██▍       | 486/2000 [2:09:41<5:17:24, 12.58s/it] 24%|██▍       | 487/2000 [2:10:03<6:22:49, 15.18s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.017591242887251626, 'learning_rate': 4.425766890836062e-07, 'completion_length': 68.41667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.34}
 24%|██▍       | 487/2000 [2:10:03<6:22:49, 15.18s/it] 24%|██▍       | 488/2000 [2:10:15<6:03:43, 14.43s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.011772487140478672, 'learning_rate': 4.423182781342588e-07, 'completion_length': 48.97916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.35}
 24%|██▍       | 488/2000 [2:10:15<6:03:43, 14.43s/it] 24%|██▍       | 489/2000 [2:10:31<6:12:21, 14.79s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01777492703223588, 'learning_rate': 4.420593628526472e-07, 'completion_length': 58.770835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.90234375, 'epoch': 0.35}
 24%|██▍       | 489/2000 [2:10:31<6:12:21, 14.79s/it] 24%|██▍       | 490/2000 [2:10:45<6:03:59, 14.46s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.009747421983863282, 'learning_rate': 4.417999439177465e-07, 'completion_length': 31.33333396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.92578125, 'epoch': 0.35}
 24%|██▍       | 490/2000 [2:10:45<6:03:59, 14.46s/it] 25%|██▍       | 491/2000 [2:10:55<5:29:43, 13.11s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015755710386825217, 'learning_rate': 4.4154002200985274e-07, 'completion_length': 36.22916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.35}
 25%|██▍       | 491/2000 [2:10:55<5:29:43, 13.11s/it] 25%|██▍       | 492/2000 [2:11:09<5:36:23, 13.38s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01749930709570792, 'learning_rate': 4.412795978105807e-07, 'completion_length': 73.22917175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.35}
 25%|██▍       | 492/2000 [2:11:09<5:36:23, 13.38s/it] 25%|██▍       | 493/2000 [2:11:26<6:08:51, 14.69s/it]                                                      {'loss': 0.0009, 'grad_norm': 13.42514115185087, 'learning_rate': 4.4101867200286256e-07, 'completion_length': 38.270835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.94140625, 'epoch': 0.35}
 25%|██▍       | 493/2000 [2:11:26<6:08:51, 14.69s/it] 25%|██▍       | 494/2000 [2:11:41<6:05:15, 14.55s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012053084003725614, 'learning_rate': 4.407572452709458e-07, 'completion_length': 32.708335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.92578125, 'epoch': 0.35}
 25%|██▍       | 494/2000 [2:11:41<6:05:15, 14.55s/it] 25%|██▍       | 495/2000 [2:11:57<6:16:36, 15.01s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015565480276994021, 'learning_rate': 4.4049531830039157e-07, 'completion_length': 45.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.80859375, 'epoch': 0.35}
 25%|██▍       | 495/2000 [2:11:57<6:16:36, 15.01s/it] 25%|██▍       | 496/2000 [2:12:06<5:34:33, 13.35s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015287228436948859, 'learning_rate': 4.402328917780728e-07, 'completion_length': 23.666667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.35}
 25%|██▍       | 496/2000 [2:12:06<5:34:33, 13.35s/it] 25%|██▍       | 497/2000 [2:12:22<5:52:34, 14.07s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.019329293819388808, 'learning_rate': 4.399699663921724e-07, 'completion_length': 50.583335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.35}
 25%|██▍       | 497/2000 [2:12:22<5:52:34, 14.07s/it] 25%|██▍       | 498/2000 [2:12:35<5:43:51, 13.74s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010107475671625583, 'learning_rate': 4.3970654283218167e-07, 'completion_length': 31.64583396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.35}
 25%|██▍       | 498/2000 [2:12:35<5:43:51, 13.74s/it] 25%|██▍       | 499/2000 [2:12:43<4:58:22, 11.93s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01019880560427942, 'learning_rate': 4.39442621788898e-07, 'completion_length': 16.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.35}
 25%|██▍       | 499/2000 [2:12:43<4:58:22, 11.93s/it] 25%|██▌       | 500/2000 [2:12:59<5:31:30, 13.26s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01078733187840576, 'learning_rate': 4.391782039544238e-07, 'completion_length': 75.16667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.35}
 25%|██▌       | 500/2000 [2:12:59<5:31:30, 13.26s/it] 25%|██▌       | 501/2000 [2:13:57<11:08:39, 26.76s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.10785221190988732, 'learning_rate': 4.389132900221638e-07, 'completion_length': 51.958335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.35}
 25%|██▌       | 501/2000 [2:13:57<11:08:39, 26.76s/it] 25%|██▌       | 502/2000 [2:14:13<9:49:19, 23.60s/it]                                                       {'loss': 0.0009, 'grad_norm': 0.07753523766715151, 'learning_rate': 4.386478806868241e-07, 'completion_length': 70.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8828125, 'epoch': 0.36}
 25%|██▌       | 502/2000 [2:14:13<9:49:19, 23.60s/it] 25%|██▌       | 503/2000 [2:14:32<9:13:17, 22.18s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012026445337377246, 'learning_rate': 4.3838197664440944e-07, 'completion_length': 40.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94140625, 'epoch': 0.36}
 25%|██▌       | 503/2000 [2:14:32<9:13:17, 22.18s/it] 25%|██▌       | 504/2000 [2:14:50<8:36:19, 20.71s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01149297373684856, 'learning_rate': 4.381155785922225e-07, 'completion_length': 58.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.765625, 'epoch': 0.36}
 25%|██▌       | 504/2000 [2:14:50<8:36:19, 20.71s/it] 25%|██▌       | 505/2000 [2:15:06<8:02:33, 19.37s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.00983767816850188, 'learning_rate': 4.37848687228861e-07, 'completion_length': 30.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.36}
 25%|██▌       | 505/2000 [2:15:06<8:02:33, 19.37s/it] 25%|██▌       | 506/2000 [2:15:27<8:13:44, 19.83s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.014844877222641948, 'learning_rate': 4.375813032542164e-07, 'completion_length': 84.35417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.83984375, 'epoch': 0.36}
 25%|██▌       | 506/2000 [2:15:27<8:13:44, 19.83s/it] 25%|██▌       | 507/2000 [2:15:44<7:55:51, 19.12s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012502684127247816, 'learning_rate': 4.3731342736947194e-07, 'completion_length': 71.64583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.36}
 25%|██▌       | 507/2000 [2:15:44<7:55:51, 19.12s/it] 25%|██▌       | 508/2000 [2:16:04<7:59:50, 19.30s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015257881105345029, 'learning_rate': 4.37045060277101e-07, 'completion_length': 91.54167175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8515625, 'epoch': 0.36}
 25%|██▌       | 508/2000 [2:16:04<7:59:50, 19.30s/it] 25%|██▌       | 509/2000 [2:16:22<7:47:29, 18.81s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.013472530270497066, 'learning_rate': 4.367762026808649e-07, 'completion_length': 76.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.8671875, 'epoch': 0.36}
 25%|██▌       | 509/2000 [2:16:22<7:47:29, 18.81s/it] 26%|██▌       | 510/2000 [2:16:34<7:00:01, 16.91s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.02563175743859049, 'learning_rate': 4.365068552858115e-07, 'completion_length': 37.395835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.80078125, 'epoch': 0.36}
 26%|██▌       | 510/2000 [2:16:34<7:00:01, 16.91s/it] 26%|██▌       | 511/2000 [2:16:50<6:51:13, 16.57s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01825143266157299, 'learning_rate': 4.362370187982728e-07, 'completion_length': 59.41666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.36}
 26%|██▌       | 511/2000 [2:16:50<6:51:13, 16.57s/it] 26%|██▌       | 512/2000 [2:16:59<5:54:43, 14.30s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015488993823257677, 'learning_rate': 4.3596669392586363e-07, 'completion_length': 32.97916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.84375, 'epoch': 0.36}
 26%|██▌       | 512/2000 [2:16:59<5:54:43, 14.30s/it] 26%|██▌       | 513/2000 [2:17:19<6:39:47, 16.13s/it]                                                      {'loss': 0.0008, 'grad_norm': 1.571665686770577, 'learning_rate': 4.3569588137747923e-07, 'completion_length': 125.16667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.7890625, 'epoch': 0.36}
 26%|██▌       | 513/2000 [2:17:19<6:39:47, 16.13s/it] 26%|██▌       | 514/2000 [2:17:36<6:46:07, 16.40s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015333419263251085, 'learning_rate': 4.3542458186329435e-07, 'completion_length': 99.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.85546875, 'epoch': 0.36}
 26%|██▌       | 514/2000 [2:17:36<6:46:07, 16.40s/it] 26%|██▌       | 515/2000 [2:17:50<6:27:05, 15.64s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0359524021203344, 'learning_rate': 4.3515279609475996e-07, 'completion_length': 42.208335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.36}
 26%|██▌       | 515/2000 [2:17:50<6:27:05, 15.64s/it] 26%|██▌       | 516/2000 [2:18:05<6:24:20, 15.54s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.014223557309315933, 'learning_rate': 4.348805247846027e-07, 'completion_length': 42.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9140625, 'epoch': 0.37}
 26%|██▌       | 516/2000 [2:18:05<6:24:20, 15.54s/it] 26%|██▌       | 517/2000 [2:18:18<6:04:23, 14.74s/it]                                                      {'loss': 0.001, 'grad_norm': 0.10769308747587533, 'learning_rate': 4.3460776864682237e-07, 'completion_length': 46.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9765625, 'epoch': 0.37}
 26%|██▌       | 517/2000 [2:18:18<6:04:23, 14.74s/it] 26%|██▌       | 518/2000 [2:18:34<6:11:39, 15.05s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.011027191452618088, 'learning_rate': 4.3433452839669005e-07, 'completion_length': 56.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.7890625, 'epoch': 0.37}
 26%|██▌       | 518/2000 [2:18:34<6:11:39, 15.05s/it] 26%|██▌       | 519/2000 [2:18:41<5:11:23, 12.62s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010931453330165087, 'learning_rate': 4.340608047507465e-07, 'completion_length': 24.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.37}
 26%|██▌       | 519/2000 [2:18:41<5:11:23, 12.62s/it] 26%|██▌       | 520/2000 [2:18:59<5:48:56, 14.15s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.028612068446081055, 'learning_rate': 4.337865984268001e-07, 'completion_length': 72.60417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.84765625, 'epoch': 0.37}
 26%|██▌       | 520/2000 [2:18:59<5:48:56, 14.15s/it] 26%|██▌       | 521/2000 [2:19:09<5:19:49, 12.97s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0356229042492418, 'learning_rate': 4.335119101439249e-07, 'completion_length': 29.666667938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.37}
 26%|██▌       | 521/2000 [2:19:09<5:19:49, 12.97s/it] 26%|██▌       | 522/2000 [2:19:16<4:37:11, 11.25s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0076088441620090945, 'learning_rate': 4.3323674062245896e-07, 'completion_length': 16.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.37}
 26%|██▌       | 522/2000 [2:19:16<4:37:11, 11.25s/it] 26%|██▌       | 523/2000 [2:19:36<5:43:53, 13.97s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008500331138780492, 'learning_rate': 4.3296109058400223e-07, 'completion_length': 49.91666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.984375, 'epoch': 0.37}
 26%|██▌       | 523/2000 [2:19:36<5:43:53, 13.97s/it] 26%|██▌       | 524/2000 [2:19:53<6:04:52, 14.83s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.009979878572805809, 'learning_rate': 4.326849607514148e-07, 'completion_length': 38.958335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.37}
 26%|██▌       | 524/2000 [2:19:53<6:04:52, 14.83s/it] 26%|██▋       | 525/2000 [2:19:59<4:58:41, 12.15s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.31809458752567193, 'learning_rate': 4.324083518488151e-07, 'completion_length': 13.395833969116211, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.140625, 'epoch': 0.37}
 26%|██▋       | 525/2000 [2:19:59<4:58:41, 12.15s/it] 26%|██▋       | 526/2000 [2:20:15<5:28:08, 13.36s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.009715727207978543, 'learning_rate': 4.3213126460157744e-07, 'completion_length': 59.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.37}
 26%|██▋       | 526/2000 [2:20:15<5:28:08, 13.36s/it] 26%|██▋       | 527/2000 [2:20:21<4:31:41, 11.07s/it]                                                      {'loss': 0.001, 'grad_norm': 0.009013597416753857, 'learning_rate': 4.318536997363311e-07, 'completion_length': 11.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.37}
 26%|██▋       | 527/2000 [2:20:21<4:31:41, 11.07s/it] 26%|██▋       | 528/2000 [2:20:40<5:31:24, 13.51s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0152376828691387, 'learning_rate': 4.3157565798095746e-07, 'completion_length': 73.83333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8671875, 'epoch': 0.37}
 26%|██▋       | 528/2000 [2:20:40<5:31:24, 13.51s/it] 26%|██▋       | 529/2000 [2:20:52<5:15:07, 12.85s/it]                                                      {'loss': 0.001, 'grad_norm': 0.010492831454711258, 'learning_rate': 4.312971400645886e-07, 'completion_length': 27.104167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.37}
 26%|██▋       | 529/2000 [2:20:52<5:15:07, 12.85s/it] 26%|██▋       | 530/2000 [2:21:06<5:25:55, 13.30s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.018605084660473597, 'learning_rate': 4.310181467176054e-07, 'completion_length': 53.10416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.89453125, 'epoch': 0.38}
 26%|██▋       | 530/2000 [2:21:06<5:25:55, 13.30s/it] 27%|██▋       | 531/2000 [2:21:12<4:31:27, 11.09s/it]                                                      {'loss': 0.001, 'grad_norm': 0.02315607807782316, 'learning_rate': 4.307386786716352e-07, 'completion_length': 12.916666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.98046875, 'epoch': 0.38}
 27%|██▋       | 531/2000 [2:21:12<4:31:27, 11.09s/it] 27%|██▋       | 532/2000 [2:21:28<5:07:30, 12.57s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.009042638200055063, 'learning_rate': 4.304587366595505e-07, 'completion_length': 46.833335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.83984375, 'epoch': 0.38}
 27%|██▋       | 532/2000 [2:21:28<5:07:30, 12.57s/it] 27%|██▋       | 533/2000 [2:21:45<5:39:33, 13.89s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.014940681544766491, 'learning_rate': 4.301783214154666e-07, 'completion_length': 69.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.828125, 'epoch': 0.38}
 27%|██▋       | 533/2000 [2:21:45<5:39:33, 13.89s/it] 27%|██▋       | 534/2000 [2:21:58<5:30:03, 13.51s/it]                                                      {'loss': 0.001, 'grad_norm': 27.449106545133198, 'learning_rate': 4.298974336747397e-07, 'completion_length': 38.35416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.9765625, 'epoch': 0.38}
 27%|██▋       | 534/2000 [2:21:58<5:30:03, 13.51s/it] 27%|██▋       | 535/2000 [2:22:03<4:33:25, 11.20s/it]                                                      {'loss': 0.001, 'grad_norm': 0.012949156458203371, 'learning_rate': 4.2961607417396517e-07, 'completion_length': 14.416666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.98828125, 'epoch': 0.38}
 27%|██▋       | 535/2000 [2:22:03<4:33:25, 11.20s/it] 27%|██▋       | 536/2000 [2:22:10<3:59:47,  9.83s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.021253115975757523, 'learning_rate': 4.293342436509756e-07, 'completion_length': 19.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.921875, 'epoch': 0.38}
 27%|██▋       | 536/2000 [2:22:10<3:59:47,  9.83s/it] 27%|██▋       | 537/2000 [2:22:23<4:22:21, 10.76s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.011871423701109248, 'learning_rate': 4.290519428448386e-07, 'completion_length': 40.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.38}
 27%|██▋       | 537/2000 [2:22:23<4:22:21, 10.76s/it] 27%|██▋       | 538/2000 [2:22:37<4:49:53, 11.90s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.011209829372317175, 'learning_rate': 4.287691724958551e-07, 'completion_length': 31.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.921875, 'epoch': 0.38}
 27%|██▋       | 538/2000 [2:22:37<4:49:53, 11.90s/it] 27%|██▋       | 539/2000 [2:22:55<5:30:59, 13.59s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.016959841294255512, 'learning_rate': 4.284859333455575e-07, 'completion_length': 85.79167175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.77734375, 'epoch': 0.38}
 27%|██▋       | 539/2000 [2:22:55<5:30:59, 13.59s/it] 27%|██▋       | 540/2000 [2:23:12<5:57:45, 14.70s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012428454646198139, 'learning_rate': 4.282022261367073e-07, 'completion_length': 92.02083587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.88671875, 'epoch': 0.38}
 27%|██▋       | 540/2000 [2:23:12<5:57:45, 14.70s/it] 27%|██▋       | 541/2000 [2:23:27<5:57:43, 14.71s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.014896654591301598, 'learning_rate': 4.2791805161329363e-07, 'completion_length': 60.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.92578125, 'epoch': 0.38}
 27%|██▋       | 541/2000 [2:23:27<5:57:43, 14.71s/it] 27%|██▋       | 542/2000 [2:23:44<6:15:14, 15.44s/it]                                                      {'loss': 0.001, 'grad_norm': 0.016104890485975236, 'learning_rate': 4.2763341052053113e-07, 'completion_length': 33.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.38}
 27%|██▋       | 542/2000 [2:23:44<6:15:14, 15.44s/it] 27%|██▋       | 543/2000 [2:23:57<5:56:48, 14.69s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0192797553755828, 'learning_rate': 4.273483036048577e-07, 'completion_length': 37.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91796875, 'epoch': 0.38}
 27%|██▋       | 543/2000 [2:23:57<5:56:48, 14.69s/it] 27%|██▋       | 544/2000 [2:24:12<5:56:33, 14.69s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.016611106048878478, 'learning_rate': 4.2706273161393326e-07, 'completion_length': 46.895835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.875, 'epoch': 0.38}
 27%|██▋       | 544/2000 [2:24:12<5:56:33, 14.69s/it] 27%|██▋       | 545/2000 [2:24:29<6:15:13, 15.47s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015389846380232577, 'learning_rate': 4.2677669529663686e-07, 'completion_length': 85.91667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.81640625, 'epoch': 0.39}
 27%|██▋       | 545/2000 [2:24:29<6:15:13, 15.47s/it] 27%|██▋       | 546/2000 [2:24:40<5:40:42, 14.06s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.029058862084435824, 'learning_rate': 4.264901954030654e-07, 'completion_length': 46.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8125, 'epoch': 0.39}
 27%|██▋       | 546/2000 [2:24:40<5:40:42, 14.06s/it] 27%|██▋       | 547/2000 [2:24:55<5:50:00, 14.45s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.023971896117949424, 'learning_rate': 4.262032326845316e-07, 'completion_length': 48.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.83984375, 'epoch': 0.39}
 27%|██▋       | 547/2000 [2:24:55<5:50:00, 14.45s/it] 27%|██▋       | 548/2000 [2:25:11<5:58:04, 14.80s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.042938215347095514, 'learning_rate': 4.259158078935615e-07, 'completion_length': 62.47916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.8515625, 'epoch': 0.39}
 27%|██▋       | 548/2000 [2:25:11<5:58:04, 14.80s/it] 27%|██▋       | 549/2000 [2:25:22<5:34:07, 13.82s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.018927010010857375, 'learning_rate': 4.256279217838933e-07, 'completion_length': 34.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.39}
 27%|██▋       | 549/2000 [2:25:22<5:34:07, 13.82s/it] 28%|██▊       | 550/2000 [2:25:35<5:25:08, 13.45s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.03235954980773283, 'learning_rate': 4.253395751104748e-07, 'completion_length': 47.97916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.859375, 'epoch': 0.39}
 28%|██▊       | 550/2000 [2:25:35<5:25:08, 13.45s/it] 28%|██▊       | 551/2000 [2:25:55<6:12:25, 15.42s/it]                                                      {'loss': 0.0007, 'grad_norm': 4.446580917063074, 'learning_rate': 4.250507686294613e-07, 'completion_length': 133.83334350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.69921875, 'epoch': 0.39}
 28%|██▊       | 551/2000 [2:25:55<6:12:25, 15.42s/it] 28%|██▊       | 552/2000 [2:26:08<5:51:37, 14.57s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.18252424903754993, 'learning_rate': 4.2476150309821437e-07, 'completion_length': 42.583335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.39}
 28%|██▊       | 552/2000 [2:26:08<5:51:37, 14.57s/it] 28%|██▊       | 553/2000 [2:26:20<5:34:36, 13.87s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.024008150996308972, 'learning_rate': 4.24471779275299e-07, 'completion_length': 36.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.86328125, 'epoch': 0.39}
 28%|██▊       | 553/2000 [2:26:20<5:34:36, 13.87s/it] 28%|██▊       | 554/2000 [2:26:37<5:57:36, 14.84s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.026487201197230612, 'learning_rate': 4.2418159792048214e-07, 'completion_length': 56.020835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.85546875, 'epoch': 0.39}
 28%|██▊       | 554/2000 [2:26:37<5:57:36, 14.84s/it] 28%|██▊       | 555/2000 [2:26:56<6:29:40, 16.18s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.028975428739323912, 'learning_rate': 4.238909597947307e-07, 'completion_length': 75.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.74609375, 'epoch': 0.39}
 28%|██▊       | 555/2000 [2:26:56<6:29:40, 16.18s/it] 28%|██▊       | 556/2000 [2:27:11<6:22:02, 15.87s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.029755170353265806, 'learning_rate': 4.235998656602091e-07, 'completion_length': 70.20833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.828125, 'epoch': 0.39}
 28%|██▊       | 556/2000 [2:27:11<6:22:02, 15.87s/it] 28%|██▊       | 557/2000 [2:27:33<7:04:26, 17.65s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.031202788323390476, 'learning_rate': 4.2330831628027783e-07, 'completion_length': 108.52083587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.76953125, 'epoch': 0.39}
 28%|██▊       | 557/2000 [2:27:33<7:04:26, 17.65s/it] 28%|██▊       | 558/2000 [2:27:53<7:19:02, 18.27s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.022292547217196132, 'learning_rate': 4.230163124194912e-07, 'completion_length': 103.85417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7734375, 'epoch': 0.39}
 28%|██▊       | 558/2000 [2:27:53<7:19:02, 18.27s/it] 28%|██▊       | 559/2000 [2:28:13<7:30:15, 18.75s/it]                                                      {'loss': 0.0011, 'grad_norm': 1.0120825756399903, 'learning_rate': 4.2272385484359534e-07, 'completion_length': 124.14583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0625, 'epoch': 0.4}
 28%|██▊       | 559/2000 [2:28:13<7:30:15, 18.75s/it] 28%|██▊       | 560/2000 [2:28:28<7:04:21, 17.68s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.02523313010868572, 'learning_rate': 4.2243094431952607e-07, 'completion_length': 75.02083587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.80859375, 'epoch': 0.4}
 28%|██▊       | 560/2000 [2:28:28<7:04:21, 17.68s/it] 28%|██▊       | 561/2000 [2:28:45<7:02:01, 17.60s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.029999098726916553, 'learning_rate': 4.2213758161540703e-07, 'completion_length': 70.33333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.4}
 28%|██▊       | 561/2000 [2:28:45<7:02:01, 17.60s/it] 28%|██▊       | 562/2000 [2:29:01<6:49:15, 17.08s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02055315806179155, 'learning_rate': 4.2184376750054785e-07, 'completion_length': 66.95833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.86328125, 'epoch': 0.4}
 28%|██▊       | 562/2000 [2:29:01<6:49:15, 17.08s/it] 28%|██▊       | 563/2000 [2:29:19<6:56:03, 17.37s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.04091642802945838, 'learning_rate': 4.2154950274544173e-07, 'completion_length': 80.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.75, 'epoch': 0.4}
 28%|██▊       | 563/2000 [2:29:19<6:56:03, 17.37s/it] 28%|██▊       | 564/2000 [2:29:33<6:28:09, 16.22s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.023922812815947093, 'learning_rate': 4.2125478812176363e-07, 'completion_length': 51.958335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.83203125, 'epoch': 0.4}
 28%|██▊       | 564/2000 [2:29:33<6:28:09, 16.22s/it] 28%|██▊       | 565/2000 [2:29:53<6:55:14, 17.36s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.021570725176239758, 'learning_rate': 4.2095962440236843e-07, 'completion_length': 115.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.77734375, 'epoch': 0.4}
 28%|██▊       | 565/2000 [2:29:53<6:55:14, 17.36s/it] 28%|██▊       | 566/2000 [2:30:09<6:48:42, 17.10s/it]                                                      {'loss': 0.0009, 'grad_norm': 9.460122275629796, 'learning_rate': 4.206640123612884e-07, 'completion_length': 84.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.85546875, 'epoch': 0.4}
 28%|██▊       | 566/2000 [2:30:09<6:48:42, 17.10s/it] 28%|██▊       | 567/2000 [2:30:27<6:52:23, 17.27s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.020957578610084293, 'learning_rate': 4.203679527737318e-07, 'completion_length': 94.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.78125, 'epoch': 0.4}
 28%|██▊       | 567/2000 [2:30:27<6:52:23, 17.27s/it] 28%|██▊       | 568/2000 [2:30:46<7:04:19, 17.78s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.018430128889197164, 'learning_rate': 4.2007144641608035e-07, 'completion_length': 75.83333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8515625, 'epoch': 0.4}
 28%|██▊       | 568/2000 [2:30:46<7:04:19, 17.78s/it] 28%|██▊       | 569/2000 [2:31:05<7:13:02, 18.16s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.017747932753528223, 'learning_rate': 4.1977449406588736e-07, 'completion_length': 133.4791717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.7109375, 'epoch': 0.4}
 28%|██▊       | 569/2000 [2:31:05<7:13:02, 18.16s/it] 28%|██▊       | 570/2000 [2:31:21<7:00:06, 17.63s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.021140127153194094, 'learning_rate': 4.194770965018758e-07, 'completion_length': 66.70833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.4}
 28%|██▊       | 570/2000 [2:31:21<7:00:06, 17.63s/it] 29%|██▊       | 571/2000 [2:31:37<6:48:25, 17.15s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01659165890112347, 'learning_rate': 4.19179254503936e-07, 'completion_length': 91.60417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7734375, 'epoch': 0.4}
 29%|██▊       | 571/2000 [2:31:37<6:48:25, 17.15s/it] 29%|██▊       | 572/2000 [2:31:56<6:59:48, 17.64s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.019249944436973282, 'learning_rate': 4.188809688531241e-07, 'completion_length': 77.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.4}
 29%|██▊       | 572/2000 [2:31:56<6:59:48, 17.64s/it] 29%|██▊       | 573/2000 [2:32:18<7:26:46, 18.79s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.01765969544119396, 'learning_rate': 4.1858224033165925e-07, 'completion_length': 64.33333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.71484375, 'epoch': 0.41}
 29%|██▊       | 573/2000 [2:32:18<7:26:46, 18.79s/it] 29%|██▊       | 574/2000 [2:32:33<7:02:52, 17.79s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.05875078353262361, 'learning_rate': 4.1828306972292226e-07, 'completion_length': 69.89583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.74609375, 'epoch': 0.41}
 29%|██▊       | 574/2000 [2:32:33<7:02:52, 17.79s/it] 29%|██▉       | 575/2000 [2:32:49<6:49:51, 17.26s/it]                                                      {'loss': 0.0009, 'grad_norm': 1.3768488028501136, 'learning_rate': 4.1798345781145305e-07, 'completion_length': 63.72916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.87109375, 'epoch': 0.41}
 29%|██▉       | 575/2000 [2:32:49<6:49:51, 17.26s/it] 29%|██▉       | 576/2000 [2:33:13<7:36:21, 19.23s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.015017295194893905, 'learning_rate': 4.1768340538294914e-07, 'completion_length': 146.6666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.72265625, 'epoch': 0.41}
 29%|██▉       | 576/2000 [2:33:13<7:36:21, 19.23s/it] 29%|██▉       | 577/2000 [2:33:29<7:16:11, 18.39s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.014963092912927977, 'learning_rate': 4.173829132242629e-07, 'completion_length': 95.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8125, 'epoch': 0.41}
 29%|██▉       | 577/2000 [2:33:29<7:16:11, 18.39s/it] 29%|██▉       | 578/2000 [2:33:48<7:15:54, 18.39s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.023868606839121304, 'learning_rate': 4.1708198212340006e-07, 'completion_length': 59.85416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.41}
 29%|██▉       | 578/2000 [2:33:48<7:15:54, 18.39s/it] 29%|██▉       | 579/2000 [2:34:03<6:52:21, 17.41s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.015750965279564846, 'learning_rate': 4.167806128695173e-07, 'completion_length': 64.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.859375, 'epoch': 0.41}
 29%|██▉       | 579/2000 [2:34:03<6:52:21, 17.41s/it] 29%|██▉       | 580/2000 [2:34:18<6:36:00, 16.73s/it]                                                      {'loss': 0.001, 'grad_norm': 0.049469635370503376, 'learning_rate': 4.1647880625292027e-07, 'completion_length': 34.333335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.41}
 29%|██▉       | 580/2000 [2:34:18<6:36:00, 16.73s/it] 29%|██▉       | 581/2000 [2:34:33<6:22:53, 16.19s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01811419885540188, 'learning_rate': 4.1617656306506175e-07, 'completion_length': 31.27083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.41}
 29%|██▉       | 581/2000 [2:34:33<6:22:53, 16.19s/it] 29%|██▉       | 582/2000 [2:34:49<6:21:09, 16.13s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.01675583159579634, 'learning_rate': 4.158738840985393e-07, 'completion_length': 40.79166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.92578125, 'epoch': 0.41}
 29%|██▉       | 582/2000 [2:34:49<6:21:09, 16.13s/it] 29%|██▉       | 583/2000 [2:34:55<5:10:33, 13.15s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.007315898404812377, 'learning_rate': 4.155707701470932e-07, 'completion_length': 12.041666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.41}
 29%|██▉       | 583/2000 [2:34:55<5:10:33, 13.15s/it] 29%|██▉       | 584/2000 [2:35:01<4:17:10, 10.90s/it]                                                      {'loss': 0.0011, 'grad_norm': 0.008017726658580217, 'learning_rate': 4.1526722200560436e-07, 'completion_length': 10.916666984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.046875, 'epoch': 0.41}
 29%|██▉       | 584/2000 [2:35:01<4:17:10, 10.90s/it] 29%|██▉       | 585/2000 [2:35:08<3:49:07,  9.72s/it]                                                      {'loss': 0.001, 'grad_norm': 0.012409251677634396, 'learning_rate': 4.1496324047009244e-07, 'completion_length': 16.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96484375, 'epoch': 0.41}
 29%|██▉       | 585/2000 [2:35:08<3:49:07,  9.72s/it] 29%|██▉       | 586/2000 [2:35:21<4:13:57, 10.78s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012952174840723753, 'learning_rate': 4.1465882633771364e-07, 'completion_length': 35.833335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.93359375, 'epoch': 0.41}
 29%|██▉       | 586/2000 [2:35:21<4:13:57, 10.78s/it] 29%|██▉       | 587/2000 [2:35:33<4:19:19, 11.01s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0109678394890137, 'learning_rate': 4.1435398040675844e-07, 'completion_length': 37.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9375, 'epoch': 0.42}
 29%|██▉       | 587/2000 [2:35:33<4:19:19, 11.01s/it] 29%|██▉       | 588/2000 [2:35:51<5:11:33, 13.24s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008443153133942826, 'learning_rate': 4.140487034766499e-07, 'completion_length': 31.45833396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9921875, 'epoch': 0.42}
 29%|██▉       | 588/2000 [2:35:51<5:11:33, 13.24s/it] 29%|██▉       | 589/2000 [2:36:06<5:26:14, 13.87s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02377824032293744, 'learning_rate': 4.13742996347941e-07, 'completion_length': 55.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.921875, 'epoch': 0.42}
 29%|██▉       | 589/2000 [2:36:06<5:26:14, 13.87s/it] 30%|██▉       | 590/2000 [2:36:21<5:33:11, 14.18s/it]                                                      {'loss': 0.001, 'grad_norm': 0.01951769021306963, 'learning_rate': 4.1343685982231315e-07, 'completion_length': 34.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.953125, 'epoch': 0.42}
 30%|██▉       | 590/2000 [2:36:21<5:33:11, 14.18s/it] 30%|██▉       | 591/2000 [2:36:36<5:37:34, 14.37s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006753582736750493, 'learning_rate': 4.131302947025736e-07, 'completion_length': 32.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.42}
 30%|██▉       | 591/2000 [2:36:36<5:37:34, 14.37s/it] 30%|██▉       | 592/2000 [2:36:53<5:53:58, 15.08s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.017864594273763825, 'learning_rate': 4.1282330179265377e-07, 'completion_length': 56.97916793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.42}
 30%|██▉       | 592/2000 [2:36:53<5:53:58, 15.08s/it] 30%|██▉       | 593/2000 [2:37:11<6:15:45, 16.02s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006762892590714871, 'learning_rate': 4.125158818976068e-07, 'completion_length': 31.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.96875, 'epoch': 0.42}
 30%|██▉       | 593/2000 [2:37:11<6:15:45, 16.02s/it] 30%|██▉       | 594/2000 [2:37:18<5:14:19, 13.41s/it]                                                      {'loss': 0.001, 'grad_norm': 0.006198981864641507, 'learning_rate': 4.122080358236054e-07, 'completion_length': 15.854166984558105, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.95703125, 'epoch': 0.42}
 30%|██▉       | 594/2000 [2:37:18<5:14:19, 13.41s/it] 30%|██▉       | 595/2000 [2:37:39<6:06:26, 15.65s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008385215819406914, 'learning_rate': 4.1189976437794003e-07, 'completion_length': 77.54167175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.921875, 'epoch': 0.42}
 30%|██▉       | 595/2000 [2:37:39<6:06:26, 15.65s/it] 30%|██▉       | 596/2000 [2:37:56<6:10:36, 15.84s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.012354535115285217, 'learning_rate': 4.115910683690167e-07, 'completion_length': 56.41666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.76171875, 'epoch': 0.42}
 30%|██▉       | 596/2000 [2:37:56<6:10:36, 15.84s/it] 30%|██▉       | 597/2000 [2:38:10<6:03:49, 15.56s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.012931044046736792, 'learning_rate': 4.1128194860635456e-07, 'completion_length': 48.60416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.42}
 30%|██▉       | 597/2000 [2:38:10<6:03:49, 15.56s/it] 30%|██▉       | 598/2000 [2:38:26<6:06:16, 15.67s/it]                                                      {'loss': 0.001, 'grad_norm': 0.013177452882468665, 'learning_rate': 4.1097240590058435e-07, 'completion_length': 49.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.99609375, 'epoch': 0.42}
 30%|██▉       | 598/2000 [2:38:26<6:06:16, 15.67s/it] 30%|██▉       | 599/2000 [2:38:45<6:27:48, 16.61s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.00822013293900986, 'learning_rate': 4.106624410634456e-07, 'completion_length': 128.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.72265625, 'epoch': 0.42}
 30%|██▉       | 599/2000 [2:38:45<6:27:48, 16.61s/it] 30%|███       | 600/2000 [2:39:03<6:33:30, 16.86s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008106617570701745, 'learning_rate': 4.1035205490778496e-07, 'completion_length': 39.85416793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.42}
 30%|███       | 600/2000 [2:39:03<6:33:30, 16.86s/it] 30%|███       | 601/2000 [2:39:20<6:37:40, 17.06s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.006710468070137684, 'learning_rate': 4.1004124824755397e-07, 'completion_length': 70.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.43}
 30%|███       | 601/2000 [2:39:20<6:37:40, 17.06s/it] 30%|███       | 602/2000 [2:39:31<5:57:15, 15.33s/it]                                                      {'loss': 0.001, 'grad_norm': 0.0073360344638386315, 'learning_rate': 4.0973002189780693e-07, 'completion_length': 25.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0078125, 'epoch': 0.43}
 30%|███       | 602/2000 [2:39:31<5:57:15, 15.33s/it] 30%|███       | 603/2000 [2:39:46<5:49:07, 14.99s/it]                                                      {'loss': 0.001, 'grad_norm': 0.007099401428941473, 'learning_rate': 4.094183766746985e-07, 'completion_length': 34.958335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.97265625, 'epoch': 0.43}
 30%|███       | 603/2000 [2:39:46<5:49:07, 14.99s/it] 30%|███       | 604/2000 [2:40:03<6:08:58, 15.86s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.009500434002044176, 'learning_rate': 4.09106313395482e-07, 'completion_length': 51.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.94921875, 'epoch': 0.43}
 30%|███       | 604/2000 [2:40:04<6:08:58, 15.86s/it] 30%|███       | 605/2000 [2:40:16<5:47:33, 14.95s/it]                                                      {'loss': 0.001, 'grad_norm': 0.008046680623315872, 'learning_rate': 4.0879383287850713e-07, 'completion_length': 26.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.97265625, 'epoch': 0.43}
 30%|███       | 605/2000 [2:40:16<5:47:33, 14.95s/it] 30%|███       | 606/2000 [2:40:33<5:56:25, 15.34s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.025694068531443428, 'learning_rate': 4.084809359432175e-07, 'completion_length': 48.16666793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.43}
 30%|███       | 606/2000 [2:40:33<5:56:25, 15.34s/it] 30%|███       | 607/2000 [2:40:55<6:43:17, 17.37s/it]                                                      {'loss': 0.0017, 'grad_norm': 16.66173000971151, 'learning_rate': 4.081676234101488e-07, 'completion_length': 94.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.671875, 'epoch': 0.43}
 30%|███       | 607/2000 [2:40:55<6:43:17, 17.37s/it] 30%|███       | 608/2000 [2:41:14<6:55:52, 17.93s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.010307090795506497, 'learning_rate': 4.078538961009268e-07, 'completion_length': 135.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.828125, 'epoch': 0.43}
 30%|███       | 608/2000 [2:41:14<6:55:52, 17.93s/it] 30%|███       | 609/2000 [2:41:25<6:07:05, 15.83s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.016714479760177745, 'learning_rate': 4.075397548382646e-07, 'completion_length': 28.104167938232422, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.921875, 'epoch': 0.43}
 30%|███       | 609/2000 [2:41:25<6:07:05, 15.83s/it] 30%|███       | 610/2000 [2:41:42<6:13:50, 16.14s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.00863807938929118, 'learning_rate': 4.072252004459611e-07, 'completion_length': 50.708335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.43}
 30%|███       | 610/2000 [2:41:42<6:13:50, 16.14s/it] 31%|███       | 611/2000 [2:41:58<6:17:47, 16.32s/it]                                                      {'loss': 0.001, 'grad_norm': 0.15323802385232477, 'learning_rate': 4.069102337488986e-07, 'completion_length': 43.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.0, 'epoch': 0.43}
 31%|███       | 611/2000 [2:41:58<6:17:47, 16.32s/it] 31%|███       | 612/2000 [2:42:16<6:24:27, 16.62s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008214758495645258, 'learning_rate': 4.0659485557304047e-07, 'completion_length': 93.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9140625, 'epoch': 0.43}
 31%|███       | 612/2000 [2:42:16<6:24:27, 16.62s/it] 31%|███       | 613/2000 [2:42:31<6:15:11, 16.23s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008965966067129079, 'learning_rate': 4.0627906674542924e-07, 'completion_length': 69.45833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.91015625, 'epoch': 0.43}
 31%|███       | 613/2000 [2:42:31<6:15:11, 16.23s/it] 31%|███       | 614/2000 [2:42:45<6:00:01, 15.59s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.013172582833524404, 'learning_rate': 4.059628680941843e-07, 'completion_length': 45.770835876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.90625, 'epoch': 0.43}
 31%|███       | 614/2000 [2:42:45<6:00:01, 15.59s/it] 31%|███       | 615/2000 [2:43:01<5:58:50, 15.55s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.009772831760955477, 'learning_rate': 4.056462604484997e-07, 'completion_length': 85.54167175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7421875, 'epoch': 0.44}
 31%|███       | 615/2000 [2:43:01<5:58:50, 15.55s/it] 31%|███       | 616/2000 [2:43:17<6:03:41, 15.77s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.008114591011036785, 'learning_rate': 4.0532924463864214e-07, 'completion_length': 42.708335876464844, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.8671875, 'epoch': 0.44}
 31%|███       | 616/2000 [2:43:17<6:03:41, 15.77s/it] 31%|███       | 617/2000 [2:43:37<6:32:14, 17.02s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.009487863654186968, 'learning_rate': 4.050118214959486e-07, 'completion_length': 105.70833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.75390625, 'epoch': 0.44}
 31%|███       | 617/2000 [2:43:37<6:32:14, 17.02s/it] 31%|███       | 618/2000 [2:43:56<6:45:40, 17.61s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010623973132180104, 'learning_rate': 4.0469399185282425e-07, 'completion_length': 74.375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.44}
 31%|███       | 618/2000 [2:43:56<6:45:40, 17.61s/it] 31%|███       | 619/2000 [2:44:05<5:46:20, 15.05s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.007966288853677707, 'learning_rate': 4.0437575654274037e-07, 'completion_length': 21.02083396911621, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.84375, 'epoch': 0.44}
 31%|███       | 619/2000 [2:44:05<5:46:20, 15.05s/it] 31%|███       | 620/2000 [2:44:19<5:41:08, 14.83s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.0114518169675498, 'learning_rate': 4.040571164002318e-07, 'completion_length': 52.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.9296875, 'epoch': 0.44}
 31%|███       | 620/2000 [2:44:19<5:41:08, 14.83s/it] 31%|███       | 621/2000 [2:44:34<5:37:02, 14.66s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.016096494447218765, 'learning_rate': 4.037380722608953e-07, 'completion_length': 76.33333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.8984375, 'epoch': 0.44}
 31%|███       | 621/2000 [2:44:34<5:37:02, 14.66s/it] 31%|███       | 622/2000 [2:44:53<6:12:26, 16.22s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.010196127821622394, 'learning_rate': 4.034186249613868e-07, 'completion_length': 140.7291717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.71875, 'epoch': 0.44}
 31%|███       | 622/2000 [2:44:53<6:12:26, 16.22s/it] 31%|███       | 623/2000 [2:45:11<6:22:48, 16.68s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.01116294494720328, 'learning_rate': 4.030987753394198e-07, 'completion_length': 169.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.74609375, 'epoch': 0.44}
 31%|███       | 623/2000 [2:45:11<6:22:48, 16.68s/it] 31%|███       | 624/2000 [2:45:26<6:09:21, 16.11s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010486989751901783, 'learning_rate': 4.027785242337625e-07, 'completion_length': 32.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.9453125, 'epoch': 0.44}
 31%|███       | 624/2000 [2:45:26<6:09:21, 16.11s/it] 31%|███▏      | 625/2000 [2:45:46<6:36:23, 17.30s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.010801515872235518, 'learning_rate': 4.024578724842361e-07, 'completion_length': 108.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.859375, 'epoch': 0.44}
 31%|███▏      | 625/2000 [2:45:46<6:36:23, 17.30s/it] 31%|███▏      | 626/2000 [2:45:59<6:07:52, 16.06s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.02199479388837575, 'learning_rate': 4.021368209317125e-07, 'completion_length': 35.04166793823242, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.890625, 'epoch': 0.44}
 31%|███▏      | 626/2000 [2:45:59<6:07:52, 16.06s/it] 31%|███▏      | 627/2000 [2:46:13<5:52:26, 15.40s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.015514251807592899, 'learning_rate': 4.018153704181119e-07, 'completion_length': 69.72917175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.84765625, 'epoch': 0.44}
 31%|███▏      | 627/2000 [2:46:13<5:52:26, 15.40s/it] 31%|███▏      | 628/2000 [2:46:37<6:52:21, 18.03s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.0108495157904961, 'learning_rate': 4.0149352178640084e-07, 'completion_length': 108.95833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.83984375, 'epoch': 0.44}
 31%|███▏      | 628/2000 [2:46:37<6:52:21, 18.03s/it] 31%|███▏      | 629/2000 [2:46:55<6:50:45, 17.98s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01077165535773991, 'learning_rate': 4.011712758805898e-07, 'completion_length': 90.14583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.84765625, 'epoch': 0.45}
 31%|███▏      | 629/2000 [2:46:55<6:50:45, 17.98s/it] 32%|███▏      | 630/2000 [2:47:25<8:13:24, 21.61s/it]                                                      {'loss': 0.0009, 'grad_norm': 0.011649722625724085, 'learning_rate': 4.0084863354573116e-07, 'completion_length': 117.85417175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.87890625, 'epoch': 0.45}
 32%|███▏      | 630/2000 [2:47:25<8:13:24, 21.61s/it] 32%|███▏      | 631/2000 [2:47:44<7:52:55, 20.73s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.018571051554158585, 'learning_rate': 4.0052559562791676e-07, 'completion_length': 95.83333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.75390625, 'epoch': 0.45}
 32%|███▏      | 631/2000 [2:47:44<7:52:55, 20.73s/it] 32%|███▏      | 632/2000 [2:48:05<7:54:27, 20.81s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.010987997868829286, 'learning_rate': 4.002021629742759e-07, 'completion_length': 138.70834350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.765625, 'epoch': 0.45}
 32%|███▏      | 632/2000 [2:48:05<7:54:27, 20.81s/it] 32%|███▏      | 633/2000 [2:48:26<7:58:11, 20.99s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.012434683573901767, 'learning_rate': 3.9987833643297296e-07, 'completion_length': 156.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.76953125, 'epoch': 0.45}
 32%|███▏      | 633/2000 [2:48:26<7:58:11, 20.99s/it] 32%|███▏      | 634/2000 [2:48:44<7:37:31, 20.10s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01331181515213813, 'learning_rate': 3.9955411685320544e-07, 'completion_length': 94.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.8046875, 'epoch': 0.45}
 32%|███▏      | 634/2000 [2:48:44<7:37:31, 20.10s/it] 32%|███▏      | 635/2000 [2:49:06<7:51:02, 20.71s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.012805284187252481, 'learning_rate': 3.9922950508520126e-07, 'completion_length': 171.1666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.74609375, 'epoch': 0.45}
 32%|███▏      | 635/2000 [2:49:06<7:51:02, 20.71s/it] 32%|███▏      | 636/2000 [2:49:26<7:42:31, 20.35s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.010819797766375643, 'learning_rate': 3.9890450198021705e-07, 'completion_length': 153.4791717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.5859375, 'epoch': 0.45}
 32%|███▏      | 636/2000 [2:49:26<7:42:31, 20.35s/it] 32%|███▏      | 637/2000 [2:49:42<7:15:43, 19.18s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.012731599381102092, 'learning_rate': 3.9857910839053545e-07, 'completion_length': 106.22917175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.53515625, 'epoch': 0.45}
 32%|███▏      | 637/2000 [2:49:42<7:15:43, 19.18s/it] 32%|███▏      | 638/2000 [2:49:58<6:53:28, 18.21s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.02330900315008998, 'learning_rate': 3.982533251694632e-07, 'completion_length': 101.64583587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.71484375, 'epoch': 0.45}
 32%|███▏      | 638/2000 [2:49:58<6:53:28, 18.21s/it] 32%|███▏      | 639/2000 [2:50:16<6:53:19, 18.22s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.014613764525730988, 'learning_rate': 3.9792715317132894e-07, 'completion_length': 125.33333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7265625, 'epoch': 0.45}
 32%|███▏      | 639/2000 [2:50:16<6:53:19, 18.22s/it] 32%|███▏      | 640/2000 [2:50:34<6:47:15, 17.97s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.03579731714465916, 'learning_rate': 3.9760059325148063e-07, 'completion_length': 91.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.8125, 'epoch': 0.45}
 32%|███▏      | 640/2000 [2:50:34<6:47:15, 17.97s/it] 32%|███▏      | 641/2000 [2:50:51<6:39:15, 17.63s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.025615184016326998, 'learning_rate': 3.972736462662836e-07, 'completion_length': 142.7916717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.76171875, 'epoch': 0.45}
 32%|███▏      | 641/2000 [2:50:51<6:39:15, 17.63s/it] 32%|███▏      | 642/2000 [2:51:09<6:44:16, 17.86s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.018012440099816708, 'learning_rate': 3.9694631307311825e-07, 'completion_length': 149.1666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.67578125, 'epoch': 0.45}
 32%|███▏      | 642/2000 [2:51:09<6:44:16, 17.86s/it] 32%|███▏      | 643/2000 [2:51:27<6:46:12, 17.96s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01428515425881858, 'learning_rate': 3.966185945303777e-07, 'completion_length': 176.1666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.640625, 'epoch': 0.46}
 32%|███▏      | 643/2000 [2:51:27<6:46:12, 17.96s/it] 32%|███▏      | 644/2000 [2:51:46<6:48:58, 18.10s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.014627588898918836, 'learning_rate': 3.9629049149746556e-07, 'completion_length': 136.6666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.640625, 'epoch': 0.46}
 32%|███▏      | 644/2000 [2:51:46<6:48:58, 18.10s/it] 32%|███▏      | 645/2000 [2:52:05<6:55:46, 18.41s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.014394591225530886, 'learning_rate': 3.959620048347938e-07, 'completion_length': 198.45834350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.55859375, 'epoch': 0.46}
 32%|███▏      | 645/2000 [2:52:05<6:55:46, 18.41s/it] 32%|███▏      | 646/2000 [2:52:26<7:13:01, 19.19s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.02150427918944622, 'learning_rate': 3.956331354037805e-07, 'completion_length': 213.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.5546875, 'epoch': 0.46}
 32%|███▏      | 646/2000 [2:52:26<7:13:01, 19.19s/it] 32%|███▏      | 647/2000 [2:52:46<7:20:45, 19.55s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.016579480908906534, 'learning_rate': 3.953038840668473e-07, 'completion_length': 184.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.68359375, 'epoch': 0.46}
 32%|███▏      | 647/2000 [2:52:46<7:20:45, 19.55s/it] 32%|███▏      | 648/2000 [2:53:07<7:28:40, 19.91s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.04279686334977555, 'learning_rate': 3.949742516874175e-07, 'completion_length': 162.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.69140625, 'epoch': 0.46}
 32%|███▏      | 648/2000 [2:53:07<7:28:40, 19.91s/it] 32%|███▏      | 649/2000 [2:53:28<7:33:44, 20.15s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.016133915267493935, 'learning_rate': 3.9464423912991354e-07, 'completion_length': 233.27084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.59765625, 'epoch': 0.46}
 32%|███▏      | 649/2000 [2:53:28<7:33:44, 20.15s/it] 32%|███▎      | 650/2000 [2:53:49<7:40:39, 20.47s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.016526555015373017, 'learning_rate': 3.9431384725975485e-07, 'completion_length': 290.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.53515625, 'epoch': 0.46}
 32%|███▎      | 650/2000 [2:53:49<7:40:39, 20.47s/it] 33%|███▎      | 651/2000 [2:54:10<7:44:43, 20.67s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01702693464924949, 'learning_rate': 3.9398307694335576e-07, 'completion_length': 238.83334350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.58984375, 'epoch': 0.46}
 33%|███▎      | 651/2000 [2:54:10<7:44:43, 20.67s/it] 33%|███▎      | 652/2000 [2:54:32<7:50:17, 20.93s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01625932812936743, 'learning_rate': 3.9365192904812263e-07, 'completion_length': 216.02084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.61328125, 'epoch': 0.46}
 33%|███▎      | 652/2000 [2:54:32<7:50:17, 20.93s/it] 33%|███▎      | 653/2000 [2:54:51<7:37:26, 20.38s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.018844729121386544, 'learning_rate': 3.933204044424524e-07, 'completion_length': 171.52084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.5703125, 'epoch': 0.46}
 33%|███▎      | 653/2000 [2:54:51<7:37:26, 20.38s/it] 33%|███▎      | 654/2000 [2:55:08<7:13:37, 19.33s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.017729063539675904, 'learning_rate': 3.929885039957296e-07, 'completion_length': 127.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.51953125, 'epoch': 0.46}
 33%|███▎      | 654/2000 [2:55:08<7:13:37, 19.33s/it] 33%|███▎      | 655/2000 [2:55:26<7:07:12, 19.06s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.016051269865442933, 'learning_rate': 3.9265622857832455e-07, 'completion_length': 191.9791717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.51953125, 'epoch': 0.46}
 33%|███▎      | 655/2000 [2:55:26<7:07:12, 19.06s/it] 33%|███▎      | 656/2000 [2:55:50<7:37:02, 20.40s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.01937013966950357, 'learning_rate': 3.9232357906159065e-07, 'completion_length': 209.5416717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.52734375, 'epoch': 0.46}
 33%|███▎      | 656/2000 [2:55:50<7:37:02, 20.40s/it] 33%|███▎      | 657/2000 [2:56:09<7:29:41, 20.09s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.020121722503987628, 'learning_rate': 3.919905563178627e-07, 'completion_length': 257.0833435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.42578125, 'epoch': 0.46}
 33%|███▎      | 657/2000 [2:56:09<7:29:41, 20.09s/it] 33%|███▎      | 658/2000 [2:56:31<7:44:29, 20.77s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.021227819354860594, 'learning_rate': 3.9165716122045374e-07, 'completion_length': 217.77084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.515625, 'epoch': 0.47}
 33%|███▎      | 658/2000 [2:56:31<7:44:29, 20.77s/it] 33%|███▎      | 659/2000 [2:56:53<7:49:30, 21.01s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.04215910267370366, 'learning_rate': 3.9132339464365374e-07, 'completion_length': 228.83334350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.53515625, 'epoch': 0.47}
 33%|███▎      | 659/2000 [2:56:53<7:49:30, 21.01s/it] 33%|███▎      | 660/2000 [2:57:12<7:36:25, 20.44s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.07987536848373294, 'learning_rate': 3.909892574627266e-07, 'completion_length': 191.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.5546875, 'epoch': 0.47}
 33%|███▎      | 660/2000 [2:57:12<7:36:25, 20.44s/it] 33%|███▎      | 661/2000 [2:57:35<7:50:27, 21.08s/it]                                                      {'loss': 0.0005, 'grad_norm': 1.753611813999606, 'learning_rate': 3.9065475055390814e-07, 'completion_length': 276.4583435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.47265625, 'epoch': 0.47}
 33%|███▎      | 661/2000 [2:57:35<7:50:27, 21.08s/it] 33%|███▎      | 662/2000 [2:57:58<8:07:07, 21.84s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.0205386689393411, 'learning_rate': 3.9031987479440365e-07, 'completion_length': 260.3958435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.49609375, 'epoch': 0.47}
 33%|███▎      | 662/2000 [2:57:58<8:07:07, 21.84s/it] 33%|███▎      | 663/2000 [2:58:18<7:52:17, 21.20s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.016287161391633997, 'learning_rate': 3.899846310623859e-07, 'completion_length': 218.2291717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.3984375, 'epoch': 0.47}
 33%|███▎      | 663/2000 [2:58:18<7:52:17, 21.20s/it] 33%|███▎      | 664/2000 [2:58:37<7:35:17, 20.45s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.021669467238539453, 'learning_rate': 3.8964902023699234e-07, 'completion_length': 217.33334350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.4375, 'epoch': 0.47}
 33%|███▎      | 664/2000 [2:58:37<7:35:17, 20.45s/it] 33%|███▎      | 665/2000 [2:59:01<8:01:59, 21.66s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.020041888083125223, 'learning_rate': 3.8931304319832335e-07, 'completion_length': 238.3541717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.38671875, 'epoch': 0.47}
 33%|███▎      | 665/2000 [2:59:01<8:01:59, 21.66s/it] 33%|███▎      | 666/2000 [2:59:22<7:58:02, 21.50s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.17679762425992254, 'learning_rate': 3.889767008274395e-07, 'completion_length': 242.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.46484375, 'epoch': 0.47}
 33%|███▎      | 666/2000 [2:59:22<7:58:02, 21.50s/it] 33%|███▎      | 667/2000 [2:59:41<7:39:31, 20.68s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.022940523020426606, 'learning_rate': 3.886399940063595e-07, 'completion_length': 182.02084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.5078125, 'epoch': 0.47}
 33%|███▎      | 667/2000 [2:59:41<7:39:31, 20.68s/it] 33%|███▎      | 668/2000 [3:00:06<8:11:45, 22.15s/it]                                                      {'loss': 0.0004, 'grad_norm': 3.054763719352003, 'learning_rate': 3.8830292361805767e-07, 'completion_length': 281.5208435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8541666865348816, 'reward': 1.8541667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.421875, 'epoch': 0.47}
 33%|███▎      | 668/2000 [3:00:06<8:11:45, 22.15s/it] 33%|███▎      | 669/2000 [3:00:27<8:01:43, 21.72s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.023819259565336173, 'learning_rate': 3.879654905464618e-07, 'completion_length': 228.4791717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.46484375, 'epoch': 0.47}
 33%|███▎      | 669/2000 [3:00:27<8:01:43, 21.72s/it] 34%|███▎      | 670/2000 [3:00:49<8:02:31, 21.77s/it]                                                      {'loss': 0.0005, 'grad_norm': 3.2144933634760995, 'learning_rate': 3.876276956764509e-07, 'completion_length': 217.52084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.466796875, 'epoch': 0.47}
 34%|███▎      | 670/2000 [3:00:49<8:02:31, 21.77s/it] 34%|███▎      | 671/2000 [3:01:21<9:08:26, 24.76s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.018255181358541157, 'learning_rate': 3.8728953989385247e-07, 'completion_length': 334.0208435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.38671875, 'epoch': 0.47}
 34%|███▎      | 671/2000 [3:01:21<9:08:26, 24.76s/it] 34%|███▎      | 672/2000 [3:01:43<8:51:31, 24.01s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.018691540233611185, 'learning_rate': 3.869510240854407e-07, 'completion_length': 277.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.333984375, 'epoch': 0.48}
 34%|███▎      | 672/2000 [3:01:43<8:51:31, 24.01s/it] 34%|███▎      | 673/2000 [3:02:06<8:45:00, 23.74s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.021494373489929056, 'learning_rate': 3.866121491389339e-07, 'completion_length': 192.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.490234375, 'epoch': 0.48}
 34%|███▎      | 673/2000 [3:02:06<8:45:00, 23.74s/it] 34%|███▎      | 674/2000 [3:02:26<8:19:22, 22.60s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.02908529431108034, 'learning_rate': 3.8627291594299206e-07, 'completion_length': 188.9166717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.5703125, 'epoch': 0.48}
 34%|███▎      | 674/2000 [3:02:26<8:19:22, 22.60s/it] 34%|███▍      | 675/2000 [3:02:49<8:21:31, 22.71s/it]                                                      {'loss': 0.0005, 'grad_norm': 2.6868296210026346, 'learning_rate': 3.859333253872146e-07, 'completion_length': 257.8333435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.466796875, 'epoch': 0.48}
 34%|███▍      | 675/2000 [3:02:49<8:21:31, 22.71s/it] 34%|███▍      | 676/2000 [3:03:12<8:20:42, 22.69s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.02061790235470456, 'learning_rate': 3.855933783621383e-07, 'completion_length': 252.4166717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.44921875, 'epoch': 0.48}
 34%|███▍      | 676/2000 [3:03:12<8:20:42, 22.69s/it] 34%|███▍      | 677/2000 [3:03:32<8:01:46, 21.85s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.0490358068966675, 'learning_rate': 3.852530757592346e-07, 'completion_length': 203.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.5546875, 'epoch': 0.48}
 34%|███▍      | 677/2000 [3:03:32<8:01:46, 21.85s/it] 34%|███▍      | 678/2000 [3:03:55<8:13:00, 22.38s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.021133280417051672, 'learning_rate': 3.849124184709073e-07, 'completion_length': 198.27084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6015625, 'epoch': 0.48}
 34%|███▍      | 678/2000 [3:03:55<8:13:00, 22.38s/it] 34%|███▍      | 679/2000 [3:04:18<8:14:01, 22.44s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.020632470214331344, 'learning_rate': 3.845714073904905e-07, 'completion_length': 207.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.6796875, 'epoch': 0.48}
 34%|███▍      | 679/2000 [3:04:18<8:14:01, 22.44s/it] 34%|███▍      | 680/2000 [3:04:37<7:55:04, 21.59s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.023565000006525238, 'learning_rate': 3.8423004341224595e-07, 'completion_length': 176.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.578125, 'epoch': 0.48}
 34%|███▍      | 680/2000 [3:04:37<7:55:04, 21.59s/it] 34%|███▍      | 681/2000 [3:05:00<7:58:18, 21.76s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.02651851173039415, 'learning_rate': 3.838883274313609e-07, 'completion_length': 284.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.51953125, 'epoch': 0.48}
 34%|███▍      | 681/2000 [3:05:00<7:58:18, 21.76s/it] 34%|███▍      | 682/2000 [3:05:18<7:36:34, 20.79s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.05093063719667713, 'learning_rate': 3.835462603439458e-07, 'completion_length': 188.1041717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.5234375, 'epoch': 0.48}
 34%|███▍      | 682/2000 [3:05:18<7:36:34, 20.79s/it] 34%|███▍      | 683/2000 [3:05:37<7:25:38, 20.30s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.033342138483104605, 'learning_rate': 3.8320384304703146e-07, 'completion_length': 137.4166717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.62890625, 'epoch': 0.48}
 34%|███▍      | 683/2000 [3:05:37<7:25:38, 20.30s/it] 34%|███▍      | 684/2000 [3:05:59<7:36:23, 20.81s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01839667198259102, 'learning_rate': 3.828610764385676e-07, 'completion_length': 219.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.58203125, 'epoch': 0.48}
 34%|███▍      | 684/2000 [3:05:59<7:36:23, 20.81s/it] 34%|███▍      | 685/2000 [3:06:19<7:29:48, 20.52s/it]                                                      {'loss': 0.0006, 'grad_norm': 6.084322461779353, 'learning_rate': 3.8251796141741945e-07, 'completion_length': 205.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9583333730697632, 'reward': 1.9583333730697632, 'reward_std': 0.1178511306643486, 'kl': 0.5703125, 'epoch': 0.48}
 34%|███▍      | 685/2000 [3:06:19<7:29:48, 20.52s/it] 34%|███▍      | 686/2000 [3:06:40<7:31:32, 20.62s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.03082166297760964, 'learning_rate': 3.8217449888336626e-07, 'completion_length': 174.95834350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.66015625, 'epoch': 0.49}
 34%|███▍      | 686/2000 [3:06:40<7:31:32, 20.62s/it] 34%|███▍      | 687/2000 [3:07:02<7:40:27, 21.04s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.024504844037754735, 'learning_rate': 3.818306897370986e-07, 'completion_length': 274.2083435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.478515625, 'epoch': 0.49}
 34%|███▍      | 687/2000 [3:07:02<7:40:27, 21.04s/it] 34%|███▍      | 688/2000 [3:07:21<7:27:06, 20.45s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.022575793422579045, 'learning_rate': 3.8148653488021566e-07, 'completion_length': 215.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.5625, 'epoch': 0.49}
 34%|███▍      | 688/2000 [3:07:21<7:27:06, 20.45s/it] 34%|███▍      | 689/2000 [3:07:42<7:31:06, 20.65s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01713397883674573, 'learning_rate': 3.811420352152236e-07, 'completion_length': 220.1666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.5703125, 'epoch': 0.49}
 34%|███▍      | 689/2000 [3:07:42<7:31:06, 20.65s/it] 34%|███▍      | 690/2000 [3:08:03<7:34:21, 20.81s/it]                                                      {'loss': 0.0005, 'grad_norm': 2.5484673779812073, 'learning_rate': 3.807971916455325e-07, 'completion_length': 302.22918701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8125, 'reward': 1.8125, 'reward_std': 0.0589255653321743, 'kl': 0.51171875, 'epoch': 0.49}
 34%|███▍      | 690/2000 [3:08:03<7:34:21, 20.81s/it] 35%|███▍      | 691/2000 [3:08:24<7:30:36, 20.65s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01614403590364191, 'learning_rate': 3.804520050754545e-07, 'completion_length': 174.9791717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.625, 'epoch': 0.49}
 35%|███▍      | 691/2000 [3:08:24<7:30:36, 20.65s/it] 35%|███▍      | 692/2000 [3:08:46<7:41:05, 21.15s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.016605079875941287, 'learning_rate': 3.801064764102011e-07, 'completion_length': 272.22918701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.48046875, 'epoch': 0.49}
 35%|███▍      | 692/2000 [3:08:46<7:41:05, 21.15s/it] 35%|███▍      | 693/2000 [3:09:06<7:32:12, 20.76s/it]                                                      {'loss': 0.001, 'grad_norm': 2.094767341586241, 'learning_rate': 3.7976060655588097e-07, 'completion_length': 156.9166717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 1.015625, 'epoch': 0.49}
 35%|███▍      | 693/2000 [3:09:06<7:32:12, 20.76s/it] 35%|███▍      | 694/2000 [3:09:27<7:35:38, 20.93s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.028574475830273085, 'learning_rate': 3.7941439641949756e-07, 'completion_length': 236.52084350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.60546875, 'epoch': 0.49}
 35%|███▍      | 694/2000 [3:09:27<7:35:38, 20.93s/it] 35%|███▍      | 695/2000 [3:09:44<7:11:03, 19.82s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.017365070757211304, 'learning_rate': 3.7906784690894644e-07, 'completion_length': 120.83333587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6875, 'epoch': 0.49}
 35%|███▍      | 695/2000 [3:09:44<7:11:03, 19.82s/it] 35%|███▍      | 696/2000 [3:10:04<7:10:18, 19.80s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.014298900786829764, 'learning_rate': 3.787209589330134e-07, 'completion_length': 181.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.61328125, 'epoch': 0.49}
 35%|███▍      | 696/2000 [3:10:04<7:10:18, 19.80s/it] 35%|███▍      | 697/2000 [3:10:25<7:20:11, 20.27s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.04171923715235213, 'learning_rate': 3.783737334013716e-07, 'completion_length': 179.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.69140625, 'epoch': 0.49}
 35%|███▍      | 697/2000 [3:10:25<7:20:11, 20.27s/it] 35%|███▍      | 698/2000 [3:10:49<7:38:42, 21.14s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01726242428098273, 'learning_rate': 3.780261712245797e-07, 'completion_length': 157.6666717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7734375, 'epoch': 0.49}
 35%|███▍      | 698/2000 [3:10:49<7:38:42, 21.14s/it] 35%|███▍      | 699/2000 [3:11:09<7:32:08, 20.85s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01585837763000738, 'learning_rate': 3.7767827331407877e-07, 'completion_length': 127.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7734375, 'epoch': 0.49}
 35%|███▍      | 699/2000 [3:11:09<7:32:08, 20.85s/it] 35%|███▌      | 700/2000 [3:11:33<7:54:45, 21.91s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.021181387757186906, 'learning_rate': 3.773300405821908e-07, 'completion_length': 226.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.64453125, 'epoch': 0.5}
 35%|███▌      | 700/2000 [3:11:33<7:54:45, 21.91s/it] 35%|███▌      | 701/2000 [3:11:58<8:10:07, 22.64s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.0280741330734327, 'learning_rate': 3.7698147394211523e-07, 'completion_length': 171.39584350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.6796875, 'epoch': 0.5}
 35%|███▌      | 701/2000 [3:11:58<8:10:07, 22.64s/it] 35%|███▌      | 702/2000 [3:12:18<7:56:26, 22.02s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.027908042429311414, 'learning_rate': 3.766325743079277e-07, 'completion_length': 152.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6796875, 'epoch': 0.5}
 35%|███▌      | 702/2000 [3:12:18<7:56:26, 22.02s/it] 35%|███▌      | 703/2000 [3:12:33<7:11:03, 19.94s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.014328724677628777, 'learning_rate': 3.7628334259457666e-07, 'completion_length': 85.27083587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6875, 'epoch': 0.5}
 35%|███▌      | 703/2000 [3:12:33<7:11:03, 19.94s/it] 35%|███▌      | 704/2000 [3:12:53<7:09:31, 19.89s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.14010896709047452, 'learning_rate': 3.759337797178816e-07, 'completion_length': 127.20833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.828125, 'epoch': 0.5}
 35%|███▌      | 704/2000 [3:12:53<7:09:31, 19.89s/it] 35%|███▌      | 705/2000 [3:13:12<7:05:25, 19.71s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.058862105009707955, 'learning_rate': 3.755838865945305e-07, 'completion_length': 105.77083587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7265625, 'epoch': 0.5}
 35%|███▌      | 705/2000 [3:13:12<7:05:25, 19.71s/it] 35%|███▌      | 706/2000 [3:13:33<7:10:21, 19.96s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.016053467157580593, 'learning_rate': 3.7523366414207713e-07, 'completion_length': 182.20834350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.70703125, 'epoch': 0.5}
 35%|███▌      | 706/2000 [3:13:33<7:10:21, 19.96s/it] 35%|███▌      | 707/2000 [3:13:50<6:54:43, 19.24s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.017007781822866715, 'learning_rate': 3.7488311327893917e-07, 'completion_length': 67.95833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.71875, 'epoch': 0.5}
 35%|███▌      | 707/2000 [3:13:50<6:54:43, 19.24s/it] 35%|███▌      | 708/2000 [3:14:12<7:10:35, 20.00s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.0287334461778022, 'learning_rate': 3.745322349243954e-07, 'completion_length': 221.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.72265625, 'epoch': 0.5}
 35%|███▌      | 708/2000 [3:14:12<7:10:35, 20.00s/it] 35%|███▌      | 709/2000 [3:14:36<7:33:46, 21.09s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.016711957579197318, 'learning_rate': 3.7418102999858324e-07, 'completion_length': 201.1041717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6796875, 'epoch': 0.5}
 35%|███▌      | 709/2000 [3:14:36<7:33:46, 21.09s/it] 36%|███▌      | 710/2000 [3:14:56<7:29:18, 20.90s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01751357636947001, 'learning_rate': 3.738294994224969e-07, 'completion_length': 129.2291717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7578125, 'epoch': 0.5}
 36%|███▌      | 710/2000 [3:14:56<7:29:18, 20.90s/it] 36%|███▌      | 711/2000 [3:15:12<6:52:50, 19.22s/it]                                                      {'loss': 0.0008, 'grad_norm': 0.01641797895125528, 'learning_rate': 3.734776441179842e-07, 'completion_length': 110.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.78515625, 'epoch': 0.5}
 36%|███▌      | 711/2000 [3:15:12<6:52:50, 19.22s/it] 36%|███▌      | 712/2000 [3:15:36<7:27:19, 20.84s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.01638672626493079, 'learning_rate': 3.7312546500774455e-07, 'completion_length': 226.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6640625, 'epoch': 0.5}
 36%|███▌      | 712/2000 [3:15:36<7:27:19, 20.84s/it] 36%|███▌      | 713/2000 [3:15:54<7:10:37, 20.08s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.024974846717028643, 'learning_rate': 3.7277296301532677e-07, 'completion_length': 114.66667175292969, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7421875, 'epoch': 0.5}
 36%|███▌      | 713/2000 [3:15:54<7:10:37, 20.08s/it] 36%|███▌      | 714/2000 [3:16:14<7:04:56, 19.83s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.02141592583680484, 'learning_rate': 3.7242013906512627e-07, 'completion_length': 135.875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.74609375, 'epoch': 0.51}
 36%|███▌      | 714/2000 [3:16:14<7:04:56, 19.83s/it] 36%|███▌      | 715/2000 [3:16:35<7:12:09, 20.18s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.07515897539261553, 'learning_rate': 3.720669940823826e-07, 'completion_length': 237.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.60546875, 'epoch': 0.51}
 36%|███▌      | 715/2000 [3:16:35<7:12:09, 20.18s/it] 36%|███▌      | 716/2000 [3:16:54<7:04:16, 19.83s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.01960872700325981, 'learning_rate': 3.717135289931774e-07, 'completion_length': 123.20833587646484, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.7109375, 'epoch': 0.51}
 36%|███▌      | 716/2000 [3:16:54<7:04:16, 19.83s/it] 36%|███▌      | 717/2000 [3:17:17<7:23:07, 20.72s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.025956316418038396, 'learning_rate': 3.713597447244316e-07, 'completion_length': 215.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.6171875, 'epoch': 0.51}
 36%|███▌      | 717/2000 [3:17:17<7:23:07, 20.72s/it] 36%|███▌      | 718/2000 [3:17:35<7:10:48, 20.16s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01712494147865297, 'learning_rate': 3.7100564220390323e-07, 'completion_length': 239.2916717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.58203125, 'epoch': 0.51}
 36%|███▌      | 718/2000 [3:17:35<7:10:48, 20.16s/it] 36%|███▌      | 719/2000 [3:17:55<7:09:55, 20.14s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.018909209169401812, 'learning_rate': 3.7065122236018487e-07, 'completion_length': 194.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.48828125, 'epoch': 0.51}
 36%|███▌      | 719/2000 [3:17:55<7:09:55, 20.14s/it] 36%|███▌      | 720/2000 [3:18:17<7:16:13, 20.45s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.01671135986461393, 'learning_rate': 3.7029648612270123e-07, 'completion_length': 214.2291717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.6328125, 'epoch': 0.51}
 36%|███▌      | 720/2000 [3:18:17<7:16:13, 20.45s/it] 36%|███▌      | 721/2000 [3:18:36<7:11:52, 20.26s/it]                                                      {'loss': 0.0007, 'grad_norm': 0.0183556654924203, 'learning_rate': 3.699414344217068e-07, 'completion_length': 146.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.671875, 'epoch': 0.51}
 36%|███▌      | 721/2000 [3:18:36<7:11:52, 20.26s/it] 36%|███▌      | 722/2000 [3:18:59<7:27:17, 21.00s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.025877828902518878, 'learning_rate': 3.6958606818828314e-07, 'completion_length': 218.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.57421875, 'epoch': 0.51}
 36%|███▌      | 722/2000 [3:18:59<7:27:17, 21.00s/it] 36%|███▌      | 723/2000 [3:19:23<7:43:48, 21.79s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.016112165294068063, 'learning_rate': 3.6923038835433687e-07, 'completion_length': 284.91668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.47265625, 'epoch': 0.51}
 36%|███▌      | 723/2000 [3:19:23<7:43:48, 21.79s/it] 36%|███▌      | 724/2000 [3:19:40<7:13:18, 20.37s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.017017908412849767, 'learning_rate': 3.688743958525969e-07, 'completion_length': 140.2916717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.54296875, 'epoch': 0.51}
 36%|███▌      | 724/2000 [3:19:40<7:13:18, 20.37s/it] 36%|███▋      | 725/2000 [3:20:03<7:33:26, 21.34s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.01911070666055081, 'learning_rate': 3.68518091616612e-07, 'completion_length': 240.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.49609375, 'epoch': 0.51}
 36%|███▋      | 725/2000 [3:20:03<7:33:26, 21.34s/it] 36%|███▋      | 726/2000 [3:20:27<7:46:53, 21.99s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.021791321766196928, 'learning_rate': 3.681614765807486e-07, 'completion_length': 258.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.53125, 'epoch': 0.51}
 36%|███▋      | 726/2000 [3:20:27<7:46:53, 21.99s/it] 36%|███▋      | 727/2000 [3:20:49<7:48:36, 22.09s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.027403011484416644, 'learning_rate': 3.678045516801879e-07, 'completion_length': 277.04168701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.54296875, 'epoch': 0.51}
 36%|███▋      | 727/2000 [3:20:49<7:48:36, 22.09s/it] 36%|███▋      | 728/2000 [3:21:09<7:33:20, 21.38s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.02398734461533818, 'learning_rate': 3.6744731785092393e-07, 'completion_length': 323.3333435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.42578125, 'epoch': 0.52}
 36%|███▋      | 728/2000 [3:21:09<7:33:20, 21.38s/it] 36%|███▋      | 729/2000 [3:21:30<7:28:35, 21.18s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.02606384386224462, 'learning_rate': 3.670897760297608e-07, 'completion_length': 243.0416717529297, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.55859375, 'epoch': 0.52}
 36%|███▋      | 729/2000 [3:21:30<7:28:35, 21.18s/it] 36%|███▋      | 730/2000 [3:21:54<7:50:40, 22.24s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.12299805731229933, 'learning_rate': 3.6673192715431014e-07, 'completion_length': 297.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.5, 'reward': 1.5, 'reward_std': 0.0, 'kl': 0.48828125, 'epoch': 0.52}
 36%|███▋      | 730/2000 [3:21:54<7:50:40, 22.24s/it] 37%|███▋      | 731/2000 [3:22:16<7:48:36, 22.16s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.016615118593622455, 'learning_rate': 3.6637377216298903e-07, 'completion_length': 290.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.42578125, 'epoch': 0.52}
 37%|███▋      | 731/2000 [3:22:16<7:48:36, 22.16s/it] 37%|███▋      | 732/2000 [3:22:36<7:31:36, 21.37s/it]                                                      {'loss': 0.0006, 'grad_norm': 0.02959114006949068, 'learning_rate': 3.660153119950171e-07, 'completion_length': 234.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.57421875, 'epoch': 0.52}
 37%|███▋      | 732/2000 [3:22:36<7:31:36, 21.37s/it] 37%|███▋      | 733/2000 [3:23:00<7:45:27, 22.04s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.0952557491439967, 'learning_rate': 3.6565654759041444e-07, 'completion_length': 395.97918701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.40625, 'epoch': 0.52}
 37%|███▋      | 733/2000 [3:23:00<7:45:27, 22.04s/it] 37%|███▋      | 734/2000 [3:23:27<8:19:23, 23.67s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.023648173679739676, 'learning_rate': 3.652974798899988e-07, 'completion_length': 351.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.40625, 'epoch': 0.52}
 37%|███▋      | 734/2000 [3:23:27<8:19:23, 23.67s/it] 37%|███▋      | 735/2000 [3:23:48<8:02:44, 22.90s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.023570973211444073, 'learning_rate': 3.649381098353834e-07, 'completion_length': 341.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.36328125, 'epoch': 0.52}
 37%|███▋      | 735/2000 [3:23:48<8:02:44, 22.90s/it] 37%|███▋      | 736/2000 [3:24:08<7:45:02, 22.07s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.02090139096615132, 'learning_rate': 3.6457843836897417e-07, 'completion_length': 336.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.34375, 'epoch': 0.52}
 37%|███▋      | 736/2000 [3:24:08<7:45:02, 22.07s/it] 37%|███▋      | 737/2000 [3:24:32<7:57:03, 22.66s/it]                                                      {'loss': 0.0004, 'grad_norm': 3.888288247228795, 'learning_rate': 3.642184664339678e-07, 'completion_length': 405.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.375, 'epoch': 0.52}
 37%|███▋      | 737/2000 [3:24:32<7:57:03, 22.66s/it] 37%|███▋      | 738/2000 [3:24:56<8:03:25, 22.98s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.044566880500426294, 'learning_rate': 3.638581949743487e-07, 'completion_length': 387.625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.4296875, 'epoch': 0.52}
 37%|███▋      | 738/2000 [3:24:56<8:03:25, 22.98s/it] 37%|███▋      | 739/2000 [3:25:17<7:49:16, 22.33s/it]                                                      {'loss': 0.0005, 'grad_norm': 0.024633039897573674, 'learning_rate': 3.634976249348867e-07, 'completion_length': 269.5208435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.470703125, 'epoch': 0.52}
 37%|███▋      | 739/2000 [3:25:17<7:49:16, 22.33s/it] 37%|███▋      | 740/2000 [3:25:40<7:56:31, 22.69s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.017244674681792756, 'learning_rate': 3.6313675726113475e-07, 'completion_length': 406.91668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.30078125, 'epoch': 0.52}
 37%|███▋      | 740/2000 [3:25:40<7:56:31, 22.69s/it] 37%|███▋      | 741/2000 [3:26:05<8:06:04, 23.16s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.0350377595269325, 'learning_rate': 3.6277559289942614e-07, 'completion_length': 471.1458435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.283203125, 'epoch': 0.52}
 37%|███▋      | 741/2000 [3:26:05<8:06:04, 23.16s/it] 37%|███▋      | 742/2000 [3:26:36<8:59:32, 25.73s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.08783090921620704, 'learning_rate': 3.624141327968725e-07, 'completion_length': 482.3958435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.30859375, 'epoch': 0.53}
 37%|███▋      | 742/2000 [3:26:36<8:59:32, 25.73s/it] 37%|███▋      | 743/2000 [3:27:03<9:03:42, 25.95s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.06369432985555169, 'learning_rate': 3.620523779013605e-07, 'completion_length': 361.7083435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.318359375, 'epoch': 0.53}
 37%|███▋      | 743/2000 [3:27:03<9:03:42, 25.95s/it] 37%|███▋      | 744/2000 [3:27:26<8:43:34, 25.01s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.025173244417993252, 'learning_rate': 3.6169032916155055e-07, 'completion_length': 442.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.28125, 'epoch': 0.53}
 37%|███▋      | 744/2000 [3:27:26<8:43:34, 25.01s/it] 37%|███▋      | 745/2000 [3:27:47<8:18:42, 23.84s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.032023477943193705, 'learning_rate': 3.6132798752687305e-07, 'completion_length': 421.75, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.29296875, 'epoch': 0.53}
 37%|███▋      | 745/2000 [3:27:47<8:18:42, 23.84s/it] 37%|███▋      | 746/2000 [3:28:09<8:07:43, 23.34s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.07123011523677525, 'learning_rate': 3.6096535394752675e-07, 'completion_length': 337.97918701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.392578125, 'epoch': 0.53}
 37%|███▋      | 746/2000 [3:28:09<8:07:43, 23.34s/it] 37%|███▋      | 747/2000 [3:28:30<7:55:29, 22.77s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.017566713080403213, 'learning_rate': 3.6060242937447587e-07, 'completion_length': 395.91668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.248046875, 'epoch': 0.53}
 37%|███▋      | 747/2000 [3:28:30<7:55:29, 22.77s/it] 37%|███▋      | 748/2000 [3:28:56<8:11:32, 23.56s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.1390600085601089, 'learning_rate': 3.602392147594479e-07, 'completion_length': 440.6458435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.357421875, 'epoch': 0.53}
 37%|███▋      | 748/2000 [3:28:56<8:11:32, 23.56s/it] 37%|███▋      | 749/2000 [3:29:24<8:41:00, 24.99s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.025742890572526305, 'learning_rate': 3.5987571105493074e-07, 'completion_length': 355.2708435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.30078125, 'epoch': 0.53}
 37%|███▋      | 749/2000 [3:29:24<8:41:00, 24.99s/it] 38%|███▊      | 750/2000 [3:29:50<8:43:21, 25.12s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.1375726548896839, 'learning_rate': 3.595119192141706e-07, 'completion_length': 356.7708435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.408203125, 'epoch': 0.53}
 38%|███▊      | 750/2000 [3:29:50<8:43:21, 25.12s/it] 38%|███▊      | 751/2000 [3:30:11<8:22:00, 24.12s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.020226357593974377, 'learning_rate': 3.59147840191169e-07, 'completion_length': 370.125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.388671875, 'epoch': 0.53}
 38%|███▊      | 751/2000 [3:30:11<8:22:00, 24.12s/it] 38%|███▊      | 752/2000 [3:30:31<7:55:58, 22.88s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.024456721586871993, 'learning_rate': 3.587834749406808e-07, 'completion_length': 217.45834350585938, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.326171875, 'epoch': 0.53}
 38%|███▊      | 752/2000 [3:30:31<7:55:58, 22.88s/it] 38%|███▊      | 753/2000 [3:30:55<7:58:15, 23.01s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.015444049037664075, 'learning_rate': 3.584188244182115e-07, 'completion_length': 475.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.275390625, 'epoch': 0.53}
 38%|███▊      | 753/2000 [3:30:55<7:58:15, 23.01s/it] 38%|███▊      | 754/2000 [3:31:23<8:33:42, 24.74s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.04587180294966712, 'learning_rate': 3.5805388958001437e-07, 'completion_length': 453.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.2734375, 'epoch': 0.53}
 38%|███▊      | 754/2000 [3:31:23<8:33:42, 24.74s/it] 38%|███▊      | 755/2000 [3:31:47<8:26:38, 24.42s/it]                                                      {'loss': 0.0004, 'grad_norm': 0.5437990906351828, 'learning_rate': 3.5768867138308867e-07, 'completion_length': 451.8333435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.365234375, 'epoch': 0.53}
 38%|███▊      | 755/2000 [3:31:47<8:26:38, 24.42s/it] 38%|███▊      | 756/2000 [3:32:13<8:34:35, 24.82s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.025791693442736668, 'learning_rate': 3.573231707851765e-07, 'completion_length': 370.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.341796875, 'epoch': 0.54}
 38%|███▊      | 756/2000 [3:32:13<8:34:35, 24.82s/it] 38%|███▊      | 757/2000 [3:32:39<8:40:29, 25.12s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.0281512704672028, 'learning_rate': 3.5695738874476043e-07, 'completion_length': 392.6875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.306640625, 'epoch': 0.54}
 38%|███▊      | 757/2000 [3:32:39<8:40:29, 25.12s/it] 38%|███▊      | 758/2000 [3:33:02<8:26:12, 24.45s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.013939496607254557, 'learning_rate': 3.5659132622106145e-07, 'completion_length': 542.1458740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.1923828125, 'epoch': 0.54}
 38%|███▊      | 758/2000 [3:33:02<8:26:12, 24.45s/it] 38%|███▊      | 759/2000 [3:33:25<8:17:43, 24.06s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.03126160645108561, 'learning_rate': 3.562249841740357e-07, 'completion_length': 389.3958435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.3125, 'epoch': 0.54}
 38%|███▊      | 759/2000 [3:33:25<8:17:43, 24.06s/it] 38%|███▊      | 760/2000 [3:33:53<8:41:58, 25.26s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.6559593820324142, 'learning_rate': 3.558583635643726e-07, 'completion_length': 570.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.25, 'epoch': 0.54}
 38%|███▊      | 760/2000 [3:33:53<8:41:58, 25.26s/it] 38%|███▊      | 761/2000 [3:34:18<8:42:47, 25.32s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.015158420603630549, 'learning_rate': 3.5549146535349177e-07, 'completion_length': 530.3333740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.19140625, 'epoch': 0.54}
 38%|███▊      | 761/2000 [3:34:18<8:42:47, 25.32s/it] 38%|███▊      | 762/2000 [3:34:44<8:48:38, 25.62s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.07248651694179083, 'learning_rate': 3.5512429050354115e-07, 'completion_length': 532.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.2158203125, 'epoch': 0.54}
 38%|███▊      | 762/2000 [3:34:44<8:48:38, 25.62s/it] 38%|███▊      | 763/2000 [3:35:12<9:01:13, 26.25s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.017160652691512557, 'learning_rate': 3.5475683997739397e-07, 'completion_length': 501.41668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.26171875, 'epoch': 0.54}
 38%|███▊      | 763/2000 [3:35:12<9:01:13, 26.25s/it] 38%|███▊      | 764/2000 [3:35:35<8:38:53, 25.19s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.015107290006164573, 'learning_rate': 3.543891147386463e-07, 'completion_length': 549.6041870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.16015625, 'epoch': 0.54}
 38%|███▊      | 764/2000 [3:35:35<8:38:53, 25.19s/it] 38%|███▊      | 765/2000 [3:36:02<8:48:02, 25.65s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.015293197284970262, 'learning_rate': 3.5402111575161486e-07, 'completion_length': 440.0625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.21484375, 'epoch': 0.54}
 38%|███▊      | 765/2000 [3:36:02<8:48:02, 25.65s/it] 38%|███▊      | 766/2000 [3:36:30<9:04:52, 26.49s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.013739136763706411, 'learning_rate': 3.53652843981334e-07, 'completion_length': 499.3125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.20703125, 'epoch': 0.54}
 38%|███▊      | 766/2000 [3:36:30<9:04:52, 26.49s/it] 38%|███▊      | 767/2000 [3:36:54<8:47:57, 25.69s/it]                                                      {'loss': 0.0001, 'grad_norm': 1.0373672415365724, 'learning_rate': 3.532843003935535e-07, 'completion_length': 561.4583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.1474609375, 'epoch': 0.54}
 38%|███▊      | 767/2000 [3:36:54<8:47:57, 25.69s/it] 38%|███▊      | 768/2000 [3:37:17<8:31:54, 24.93s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.01989275901317027, 'learning_rate': 3.52915485954736e-07, 'completion_length': 504.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.23046875, 'epoch': 0.54}
 38%|███▊      | 768/2000 [3:37:17<8:31:54, 24.93s/it] 38%|███▊      | 769/2000 [3:37:41<8:26:09, 24.67s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.015828149586577685, 'learning_rate': 3.525464016320543e-07, 'completion_length': 429.0208435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.18359375, 'epoch': 0.54}
 38%|███▊      | 769/2000 [3:37:41<8:26:09, 24.67s/it] 38%|███▊      | 770/2000 [3:38:10<8:52:21, 25.97s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.012273646538288347, 'learning_rate': 3.5217704839338905e-07, 'completion_length': 474.5, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.1767578125, 'epoch': 0.54}
 38%|███▊      | 770/2000 [3:38:10<8:52:21, 25.97s/it] 39%|███▊      | 771/2000 [3:38:34<8:40:36, 25.42s/it]                                                      {'loss': 0.0016, 'grad_norm': 3.602219573668687, 'learning_rate': 3.5180742720732604e-07, 'completion_length': 537.8125, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 1.640625, 'epoch': 0.55}
 39%|███▊      | 771/2000 [3:38:34<8:40:36, 25.42s/it] 39%|███▊      | 772/2000 [3:39:01<8:51:14, 25.96s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.013978454354641904, 'learning_rate': 3.514375390431539e-07, 'completion_length': 577.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.13671875, 'epoch': 0.55}
 39%|███▊      | 772/2000 [3:39:01<8:51:14, 25.96s/it] 39%|███▊      | 773/2000 [3:39:27<8:47:02, 25.77s/it]                                                      {'loss': 0.0002, 'grad_norm': 1.3252481215792913, 'learning_rate': 3.5106738487086085e-07, 'completion_length': 496.66668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.1845703125, 'epoch': 0.55}
 39%|███▊      | 773/2000 [3:39:27<8:47:02, 25.77s/it] 39%|███▊      | 774/2000 [3:39:55<9:01:47, 26.52s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.019308489786748043, 'learning_rate': 3.5069696566113345e-07, 'completion_length': 481.29168701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.1552734375, 'epoch': 0.55}
 39%|███▊      | 774/2000 [3:39:55<9:01:47, 26.52s/it] 39%|███▉      | 775/2000 [3:40:19<8:47:52, 25.86s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.02192563703401858, 'learning_rate': 3.5032628238535266e-07, 'completion_length': 522.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.1640625, 'epoch': 0.55}
 39%|███▉      | 775/2000 [3:40:19<8:47:52, 25.86s/it] 39%|███▉      | 776/2000 [3:40:42<8:29:26, 24.97s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.017262337427238577, 'learning_rate': 3.4995533601559225e-07, 'completion_length': 431.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.2099609375, 'epoch': 0.55}
 39%|███▉      | 776/2000 [3:40:42<8:29:26, 24.97s/it] 39%|███▉      | 777/2000 [3:41:03<8:00:37, 23.58s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.050346126689381265, 'learning_rate': 3.495841275246158e-07, 'completion_length': 373.0, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.279296875, 'epoch': 0.55}
 39%|███▉      | 777/2000 [3:41:03<8:00:37, 23.58s/it] 39%|███▉      | 778/2000 [3:41:30<8:22:28, 24.67s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.017561243831235644, 'learning_rate': 3.4921265788587427e-07, 'completion_length': 476.04168701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.2890625, 'epoch': 0.55}
 39%|███▉      | 778/2000 [3:41:30<8:22:28, 24.67s/it] 39%|███▉      | 779/2000 [3:41:56<8:31:22, 25.13s/it]                                                      {'loss': 0.0003, 'grad_norm': 6.0178932229183815, 'learning_rate': 3.4884092807350364e-07, 'completion_length': 470.3333435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.9791666865348816, 'reward': 1.9791667461395264, 'reward_std': 0.0589255653321743, 'kl': 0.28125, 'epoch': 0.55}
 39%|███▉      | 779/2000 [3:41:56<8:31:22, 25.13s/it] 39%|███▉      | 780/2000 [3:42:19<8:14:33, 24.32s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.01704584513589952, 'learning_rate': 3.484689390623218e-07, 'completion_length': 415.1875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.25390625, 'epoch': 0.55}
 39%|███▉      | 780/2000 [3:42:19<8:14:33, 24.32s/it] 39%|███▉      | 781/2000 [3:42:44<8:20:22, 24.63s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.012371407219900382, 'learning_rate': 3.4809669182782665e-07, 'completion_length': 498.91668701171875, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.1767578125, 'epoch': 0.55}
 39%|███▉      | 781/2000 [3:42:44<8:20:22, 24.63s/it] 39%|███▉      | 782/2000 [3:43:10<8:28:55, 25.07s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.013677314064497396, 'learning_rate': 3.477241873461932e-07, 'completion_length': 520.0833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.154296875, 'epoch': 0.55}
 39%|███▉      | 782/2000 [3:43:10<8:28:55, 25.07s/it] 39%|███▉      | 783/2000 [3:43:34<8:22:51, 24.79s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.011497670034965702, 'learning_rate': 3.47351426594271e-07, 'completion_length': 528.9583740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.1513671875, 'epoch': 0.55}
 39%|███▉      | 783/2000 [3:43:34<8:22:51, 24.79s/it] 39%|███▉      | 784/2000 [3:43:56<8:07:51, 24.07s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.01455493909811747, 'learning_rate': 3.469784105495816e-07, 'completion_length': 440.9375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.6666666865348816, 'reward': 1.6666667461395264, 'reward_std': 0.0, 'kl': 0.220703125, 'epoch': 0.55}
 39%|███▉      | 784/2000 [3:43:56<8:07:51, 24.07s/it] 39%|███▉      | 785/2000 [3:44:20<8:05:57, 24.00s/it]                                                      {'loss': 0.0003, 'grad_norm': 0.01879281814639431, 'learning_rate': 3.466051401903162e-07, 'completion_length': 397.7083435058594, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.265625, 'epoch': 0.56}
 39%|███▉      | 785/2000 [3:44:20<8:05:57, 24.00s/it] 39%|███▉      | 786/2000 [3:44:46<8:16:12, 24.52s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.01166199233651425, 'learning_rate': 3.462316164953328e-07, 'completion_length': 574.0416870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.11572265625, 'epoch': 0.56}
 39%|███▉      | 786/2000 [3:44:46<8:16:12, 24.52s/it] 39%|███▉      | 787/2000 [3:45:18<8:57:52, 26.61s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.012221746042003583, 'learning_rate': 3.4585784044415364e-07, 'completion_length': 576.0208740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.1533203125, 'epoch': 0.56}
 39%|███▉      | 787/2000 [3:45:18<8:57:52, 26.61s/it] 39%|███▉      | 788/2000 [3:45:44<8:54:32, 26.46s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.0497138417079016, 'learning_rate': 3.4548381301696295e-07, 'completion_length': 584.5833740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.16015625, 'epoch': 0.56}
 39%|███▉      | 788/2000 [3:45:44<8:54:32, 26.46s/it] 39%|███▉      | 789/2000 [3:46:55<13:26:32, 39.96s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.06853452938504279, 'learning_rate': 3.4510953519460397e-07, 'completion_length': 613.7916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.1396484375, 'epoch': 0.56}
 39%|███▉      | 789/2000 [3:46:55<13:26:32, 39.96s/it] 40%|███▉      | 790/2000 [3:47:22<12:05:59, 36.00s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016886556766925163, 'learning_rate': 3.447350079585767e-07, 'completion_length': 621.5625, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.08984375, 'epoch': 0.56}
 40%|███▉      | 790/2000 [3:47:22<12:05:59, 36.00s/it] 40%|███▉      | 791/2000 [3:47:48<11:07:21, 33.12s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.016417534465441076, 'learning_rate': 3.443602322910351e-07, 'completion_length': 566.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0966796875, 'epoch': 0.56}
 40%|███▉      | 791/2000 [3:47:48<11:07:21, 33.12s/it] 40%|███▉      | 792/2000 [3:48:14<10:23:52, 30.99s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.011286915814013015, 'learning_rate': 3.4398520917478476e-07, 'completion_length': 607.25, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.08935546875, 'epoch': 0.56}
 40%|███▉      | 792/2000 [3:48:14<10:23:52, 30.99s/it] 40%|███▉      | 793/2000 [3:48:38<9:39:22, 28.80s/it]                                                       {'loss': 0.0001, 'grad_norm': 0.02587661130096031, 'learning_rate': 3.4360993959328007e-07, 'completion_length': 558.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 0.8333333730697632, 'reward': 1.8333333730697632, 'reward_std': 0.0, 'kl': 0.140625, 'epoch': 0.56}
 40%|███▉      | 793/2000 [3:48:38<9:39:22, 28.80s/it] 40%|███▉      | 794/2000 [3:49:06<9:34:04, 28.56s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.015718135108234655, 'learning_rate': 3.4323442453062166e-07, 'completion_length': 603.2708740234375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.0927734375, 'epoch': 0.56}
 40%|███▉      | 794/2000 [3:49:06<9:34:04, 28.56s/it] 40%|███▉      | 795/2000 [3:49:31<9:10:52, 27.43s/it]                                                      {'loss': 0.0002, 'grad_norm': 0.052279313486165865, 'learning_rate': 3.4285866497155416e-07, 'completion_length': 508.4375, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.154296875, 'epoch': 0.56}
 40%|███▉      | 795/2000 [3:49:31<9:10:52, 27.43s/it] 40%|███▉      | 796/2000 [3:49:56<8:57:04, 26.76s/it]                                                      {'loss': 0.0001, 'grad_norm': 0.026497228765876013, 'learning_rate': 3.42482661901463e-07, 'completion_length': 622.2916870117188, 'rewards/format_reward_func': 1.0, 'rewards/acc_reward_func': 1.0, 'reward': 2.0, 'reward_std': 0.0, 'kl': 0.130859375, 'epoch': 0.56}
 40%|███▉      | 796/2000 [3:49:56<8:57:04, 26.76s/it][1m[34mswanlab[0m[0m: Error happened while training
[1m[34mswanlab[0m[0m: 🌟 Run `[1mswanlab watch /data/youxiang/repos/RiskReasoner/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: 🏠 View project at [34m[4mhttps://api.swanlab.cn/@Youxiang/RiskReasoner-grpo[0m[0m
[1m[34mswanlab[0m[0m: 🚀 View run at [34m[4mhttps://api.swanlab.cn/@Youxiang/RiskReasoner-grpo/runs/ifg6tr1cfp7mx0tdu7bi7[0m[0m
[1m[34mswanlab[0m[0m: \ Waiting for uploading complete                                                                                                    [1m[34mswanlab[0m[0m: \ Updating experiment status...                                                                                                      File "/data/youxiang/repos/RiskReasoner/training/rl/r1/train_grpo.py", line 337, in <module>
    main()
  File "/data/youxiang/repos/RiskReasoner/training/rl/r1/train_grpo.py", line 334, in main
    grpo_function(model_args, dataset_args, training_args, callbacks=callbacks)
  File "/data/youxiang/repos/RiskReasoner/training/rl/r1/train_grpo.py", line 282, in grpo_function
    train_result = trainer.train(resume_from_checkpoint=last_checkpoint)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/transformers/trainer.py", line 2171, in train
    return inner_training_loop(
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/transformers/trainer.py", line 2531, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/transformers/trainer.py", line 3675, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 448, in compute_loss
    ref_per_token_logps = get_per_token_logps(self.ref_model, prompt_completion_ids, num_logits_to_keep)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 432, in get_per_token_logps
    logits = model(input_ids, num_logits_to_keep=num_logits_to_keep + 1).logits  # (B, L, V)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 850, in forward
    logits = self.lm_head(hidden_states[:, -num_logits_to_keep:, :])
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1844, in _call_impl
    return inner()
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1790, in inner
    result = forward_call(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py", line 116, in zero3_linear_wrap
    return LinearFunctionForZeroStage3.apply(input, weight)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 465, in decorate_fwd
    return fwd(*args, **kwargs)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py", line 64, in forward
    output = input.matmul(weight.t())
CUDA out of memory. Tried to allocate 7.83 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.68 GiB is free. Including non-PyTorch memory, this process has 72.46 GiB memory in use. Of the allocated memory 60.63 GiB is allocated by PyTorch, and 9.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
 40%|███▉      | 796/2000 [3:51:09<5:49:39, 17.42s/it]
W0216 15:36:11.286000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 105563 closing signal SIGTERM
W0216 15:36:11.288000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 105564 closing signal SIGTERM
W0216 15:36:11.291000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 105565 closing signal SIGTERM
W0216 15:36:11.293000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 105566 closing signal SIGTERM
W0216 15:36:11.294000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 105567 closing signal SIGTERM
E0216 15:36:12.563000 104530 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 105562) of binary: /home/brain/anaconda3/envs/alignment/bin/python
Traceback (most recent call last):
  File "/home/brain/anaconda3/envs/alignment/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1159, in launch_command
    deepspeed_launcher(args)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/accelerate/commands/launch.py", line 852, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/brain/anaconda3/envs/alignment/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
training/rl/r1/train_grpo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-16_15:36:11
  host      : gpu-a100-0010.host.hh-d.brainpp.cn
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 105562)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
