"""
The script ``select.py`` processes data generated by ``run_omegaPRM.py`` in three main steps:

1. Data Loading:
    - Input: A folder containing the output of ``run_omegaPRM.py``, typically organized into subfolders.
    - Each subfolder (e.g., ``omegaPRM_v2_part{i}``) contains a ``risk_reasoner.jsonl`` file generated during multi-GPU processing.
    - This script reads and merges these JSONL files into a single dataset.

2. Data Selection:
    - Filters reasoning rationales into correct and incorrect categories based on Monte Carlo (MC) values:
        - Negative samples: MC value â‰¤ ``INCORRECT_MC_BOUNDARY`` (incorrect reasoning steps).
        - Positive samples: MC value = ``CORRECT_MC_BOUNDARY`` (correct reasoning steps).
    - Constructs selected entries with associated reasoning steps and labels.

3. Data Balancing:
    - Produces a balanced dataset with a fixed target size by:
        - Separating the data into positive and negative samples.
        - Randomly sampling sufficient positive samples to complement all negative samples.
        - Merging sampled positives and all negatives into the final dataset.

The processed and balanced dataset is saved as ``risk_reasoner_v2.jsonl``.
"""


import json
from pathlib import Path
from tqdm import tqdm
import random
from utils.constants import STEP_TAG

# Constants for loading data
DATA_FOLDER = Path("datasets/omegaPRM_v2/")
DATA_SUB_FOLDER = [DATA_FOLDER/f"omegaPRM_v2_part{i}" for i in range(1, 5)]

# Constants for selecting data
INCORRECT_MC_BOUNDARY = 0.125
CORRECT_MC_BOUNDARY = 1.0

# Constants for balancing
random.seed(42)
TARGET_SIZE = 100_000


# Function to load data from multiple .jsonl files
def load_data_from_folders(folders):
    data_all = []
    for folder in folders:
        file_path = folder / "risk_reasoner.jsonl"
        with open(file_path, 'r') as f:
            # Read each line and parse it as a JSON object
            data = [json.loads(line.strip()) for line in f]
            data_all.extend(data)
    return data_all

# Function to process data and generate the selected data
def process_data(data_all):
    data_selected = []
    for data in tqdm(data_all, desc="Processing data..."):
        for reasoning in data['reasoning_steps_text']:
            # Determine if the reasoning is incorrect or correct
            incorrect_flag = reasoning["mc_value"] <= INCORRECT_MC_BOUNDARY
            correct_flag = reasoning["mc_value"] >= CORRECT_MC_BOUNDARY
            
            if incorrect_flag or correct_flag:
                # Prepare the question and reasoning steps
                question = data["question"] + STEP_TAG
                reasoning_steps = reasoning["solution_prefix"].replace(question, "")
                
                # Create labels based on reasoning steps
                labels = [1] * len(reasoning_steps.split(STEP_TAG))
                labels[-1] = 0 if incorrect_flag else 1
                
                # Create selected data entry
                selected = {
                    "question": question,
                    "reasoning_steps": (
                        reasoning_steps+STEP_TAG 
                        if not reasoning_steps.endswith(STEP_TAG)  # we need this tag to create label while training the PRM
                        else reasoning_steps
                        ),
                    "label": labels,
                    "mc_value": reasoning["mc_value"]
                }
                data_selected.append(selected)
    
    return data_selected

# Function to save data as a .jsonl file
def save_as_jsonl(data, file_path):
    with open(file_path, 'w') as f:
        for item in data:
            f.write(json.dumps(item) + '\n')


def create_balanced_dataset(selected_data, target_size):    
    # Separate data into positive and negative groups
    positive_samples = [record for record in selected_data if record["mc_value"] == 1.0]
    negative_samples = [record for record in selected_data if record["mc_value"] != 1.0]
    
    # Calculate the number of negative samples and sample positive data to balance
    num_negative_samples = len(negative_samples)
    num_positive_samples_needed = target_size - num_negative_samples
    sampled_positive_samples = random.sample(positive_samples, num_positive_samples_needed)
    
    # Combine negative samples and sampled positive samples to form the target dataset
    balanced_dataset = negative_samples + sampled_positive_samples

    return balanced_dataset

# Main script
def main():
    # Load data from .jsonl files
    print("Loading and merging data from subfolders.")
    data_all = load_data_from_folders(DATA_SUB_FOLDER)
    
    # Process data to select relevant items
    data_selected = process_data(data_all)
    
    # Balance the dataset
    data_balanced = create_balanced_dataset(data_selected, target_size=TARGET_SIZE)
    
    # Save the final selected data to a .jsonl file
    save_as_jsonl(data_balanced, DATA_FOLDER/"risk_reasoner_v2.jsonl")

if __name__ == "__main__":
    main()
